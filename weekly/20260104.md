# [‰∫îÊù°1209] ‰ªéÊ®°Á≥äÂà∞Á≤æÂáÜÔºöËÆ©AIËØªÊáÇ‰Ω†ÁöÑËÆæËÆ°ËØ≠Ë®Ä
ÂèëÂ∏ÉÊó•ÊúüÔºö2025/12/05

 Summary: Create better AI-prototyping designs by using precise visual keywords, references, analysis, as well as mock data and code snippets.

The rise of GenAI tools has introduced a new paradigm for design work ‚Äî rather than crafting interfaces by [directly manipulating](https://www.nngroup.com/articles/direct-manipulation/) elements in design tools, designers can prompt AI-prototyping tools to generate designs.

When you‚Äôre working with AI, the output quality will be largely dependent on the specificity of the prompt. This article discusses common issues with vague text prompts and offers recommendations on how to achieve better results from AI-prototyping tools without undertaking the bulk of the design work yourself.

## Research Recap

When we [asked AI-prototyping tools to generate a live-training profile page for NN/G course attendees](https://www.nngroup.com/articles/ai-prototyping/), a detailed prompt yielded quality results resembling what a human designer created, whereas a vague prompt generated inconsistent and unpredictable outcomes across the board. (For more information about the prompts and tools we used, [see our description of the study methodology](https://www.nngroup.com/articles/testing-ai-methodology/).)

A skilled human designer can take a broad design statement (such as ‚Äúdesign a profile page that allows course attendees to do XYZ‚Äù), identify and prioritize the information users need to see on the page, choose the design patterns that support users in accomplishing their goals, and arrange elements in a logical layout that is easy to navigate. In contrast, AI struggles with ambiguity and is unable to deliver thoughtful results within a broad context.

While open-ended prompts may be fine for exploring diverse ideas in the early design phase, they fail to produce the precise outputs needed for all other design work.

However, writing long, detailed text prompts is rarely the default strategy in practice because **providing comprehensive detail takes time** and many **turn to AI precisely to reduce work.** To get the most value from AI prototyping tools, designers need to understand how prompt specificity affects the AI‚Äôs output and tailor their prompting strategy to fit the task.

## Problems with Generic Prompts in Design Work

One of the most prominent patterns we saw across prototypes generated with broad prompts is the **Frankenstein layout** ‚Äî designs that feel **randomly pieced together** instead of thoughtfully structured.

AI-prototyping tools demonstrate a surface-level understanding of individual UI components (e.g., [progress bars](https://www.nngroup.com/articles/progress-indicators/), [list view](https://www.nngroup.com/videos/card-view-vs-list-view/)s). But when these elements are combined to create a page, the layouts often lack hierarchy, displaying a few common characteristics:

* Unnecessary visual clutter
* Repeated design elements
* Counterintuitive content flow
* Visually prominent containers with low information density

### Unnecessary Visual Clutter

AI prototyping tools often **generate more elements than necessary in response to broadly scoped prompts.** It‚Äôs like an inefficient navigation system that _can_ get you to the destination but always takes a convoluted route.

Cluttered designs hurt everyone: users‚Äô [cognitive load](https://www.nngroup.com/articles/minimize-cognitive-load/) and [interaction cost](https://www.nngroup.com/articles/interaction-cost-definition/) increase, important content risks being buried, and the system becomes more cumbersome, resulting in slower load times and more complex code for developers to manage.

![](https://media.nngroup.com/media/editor/2025/11/16/1-replit-annotation.jpg)

Annotated screenshot showing that the AI-generated dashboard repeats profile elements, duplicates certification-progress components, and scatters course content across multiple sections, resulting in poor hierarchy and organization.

### Repeated Design Elements

In our testing, there were several instances where **the same element or information was displayed multiple times.** In contrast, in a real design, screen real estate is precious and user attention is scarce, so design teams rarely tolerate this redundancy. Repetition without purpose only [adds noise](https://www.nngroup.com/articles/signal-noise-ratio/) to the interface and distracts users from the key content.

![](https://media.nngroup.com/media/editor/2025/11/16/2-loveable.jpg)

Lovable AI-generated mockup of a learning progress dashboard. There are two sections with duplicate progress bars.

![](https://media.nngroup.com/media/editor/2025/11/16/3-bolt.jpg)

In both interfaces generated by AI (Lovable & Bolt), the certification progress bars are duplicated within the same interface. While the certification process is presented in a slightly different way, the information is redundant.

### Counterintuitive Content Flow

Users expect information to follow a logical, intuitive sequence ‚Äî typically moving from general to specific, with related items grouped together. This structure helps users build [mental models](https://www.nngroup.com/articles/mental-models/) and reduces the effort needed to parse through and understand content, and reduces the effort needed to parse through and understand content.

Multiple **AI-generated designs presented content in an illogical sequence.** These disruptions, compounded by poor visual hierarchy, created disjointed layouts with no clear focus or sense of progression.

![](https://media.nngroup.com/media/editor/2025/11/16/4-claude-annotation.jpg)

Annotated dashboard layout showing a linear sequence of learning sections interrupted by a user-profile widget placed mid-page, highlighting a break in hierarchy and flow.

### Visually Prominent Containers with Low Information Density

[Visual hierarchy](https://www.nngroup.com/search/?q=visual+hierarchy) guides users to the most important elements on the page. The larger, more colorful, or more prominent an element, the greater its perceived importance relative to other items.

When **hierarchy contradicts content priority,** users may feel confused or distracted from completing the main tasks. This is a common flaw of AI-generated interfaces, which often place visual emphasis on the wrong element, as the model doesn‚Äôt have a contextual understanding of what is essential for the goal.

![](https://media.nngroup.com/media/editor/2025/11/16/5-zoomed-in-replit.jpg)

Dashboard layout where a large certification-progress ring dominates the page, visually outweighing course information despite its lower priority.

Another pattern that we noticed in the AI-generated designs was **the unnecessary use of prominent containers displaying a single piece of numerical information.** These containers tended to occupy a large amount of space but communicated little information; moreover, this information was secondary to the main user task.

![](https://media.nngroup.com/media/editor/2025/11/16/6-number-blocks-annotation.jpg)

Three AI-generated dashboards that place large single-number summary boxes at the top, occupying substantial space while providing minimal actionable insight.

## 5 Prompting Strategies for AI Prototyping

In this section, we discuss 5 ways of improving the output of a vague text prompt without needing to design in Figma first or write extensive prompts. These strategies can be combined or used separately to **increase your input specificity.**

### Use Precise Visual Keywords

When crafting prompts**, clarity and specificity** matter more than sheer length. Many frontier AI models like ChatGPT5 are designed to follow instructions with laser focus. _**Verbosity without precision**_**hurts clarity** _‚Äî_ a concise, well-chosen keyword can often produce better results than a long but vague description.

When using AI-assisted design or coding tools, describe your intent by pointing to established design styles or frameworks instead of using generic visual descriptions like _simple_, _clean_, and _modern_. Referencing a recognizable visual design style ‚Äî like _[skeuomorphism](https://www.nngroup.com/articles/skeuomorphism/), [flat design](https://www.nngroup.com/articles/flat-design/), [glassmorphism](https://www.nngroup.com/articles/glassmorphism/),_ or _retro / Y2K_ ‚Äî helps the model interpret your visual intent. This is where a good understanding of design vocabulary and of [visual-design fundamentals](https://www.nngroup.com/courses/visual-design/) becomes essential.

For example _(_assuming [_neobrutalism_](https://www.nngroup.com/articles/neobrutalism/) is the target visual style_)_:

* **‚ùå** **Poor:** ‚ÄúDesign a trendy conference landing page.‚Äù
* **‚úÖ** **Acceptable:** ‚ÄúDesign a conference landing page with high contrast, blocky layouts, and bold colors.‚Äù
* **üëè** **Better:** ‚ÄúDesign a conference landing page in a _neobrutalist_ style.‚Äù

![](https://media.nngroup.com/media/editor/2025/12/01/neobrutalism.jpg)

Explicitly naming the neobrutalist style in the prompt produced the best result.

The same principle applies when prompting AI for code generation. Developers often include **specific frameworks and component libraries** (e.g., _React_, _Next.js_, or _Tailwind CSS_) early in their prompts to shape the structure and logic of the generated code.

Designers can also reference a famous design system or brand style by its name. That said, avoid asking AI to imitate a specific brand. While it‚Äôs tempting to request ‚Äúdesign like Apple‚Äù or ‚Äúin Airbnb‚Äôs style,‚Äù copying an existing brand‚Äôs visual identity is not a sustainable strategy. **Famous brands don‚Äôt guarantee good design.** A design that works for a billion-dollar company might fail in your context due to different goals, audiences, or constraints.

### Attach Lightweight Visual References

High-fidelity mockups are effective for communicating your design vision to AI-prototyping tools, but they take time to create ‚Äî often more than writing a detailed prompt. When you‚Äôre still early in the design process or lack the resources to produce polished assets, use **lightweight visual references** instead, such [moodboards](https://www.nngroup.com/articles/mood-boards/), inspiration images, or screenshots of your [design system](https://www.nngroup.com/articles/design-systems-101/).

![](https://media.nngroup.com/media/editor/2025/11/16/8-moodboard.jpg)

When a screenshot of a Pinterest board was provided alongside a broad text prompt (Prompt 1), Figma Make generated a design that visually resembled the board‚Äôs design style.

Do manage your expectations with this approach. Even though image references are a big step up from text-based descriptions, it‚Äôs unlikely for AI to achieve pixel-perfect precision.

![](https://media.nngroup.com/media/editor/2025/11/16/9-ds.jpg)

When given a screenshot of the Material Design 3 system, Figma Make produced a design with a similar tone, but with more saturated colors than the reference.

When visual precision is essential, connect AI tools directly to your design source. Some tools have built-in features that can retrieve the visual spec and design tokens directly from a Figma frame. Developers can also leverage [Figma MCP](https://help.figma.com/hc/en-us/articles/32132100833559-Guide-to-the-Figma-MCP-server) to pull in design details like design frames, variables, components, and layout data directly into their IDEs. These methods will achieve higher precision than image uploads.

Finally, **don‚Äôt confuse visual fidelity with design quality.** A visually polished AI-generated mockup that aligns with your design system can still be a poor design if the accompanying prompt is vague or underspecified. Evaluate the outcome for usability and clarity ‚Äî not just for visual polish.

![](https://media.nngroup.com/media/editor/2025/11/16/10-ds-bad_FrP0BUj.jpg)

Annotated dashboard generated with a Material Design‚Äìstyle kit, highlighting issues such as an overly long stacked layout, an oversized progress bar, wide gaps separating related course details, and a hard-to-read label.

### Conduct a Visual Analysis with AI to Formulate the Prompt

While most AI-prototyping tools support image uploads in addition to text prompting, not all do ‚Äî and some limit image uploads to paid plans. An alternative is to **use a general-purpose chatbot to analyze the visual style or layout of a page in natural language**, then convert that description into a design prompt. This text-based approach can also be combined with an image attachment to further reinforce the intended visual direction.

![](https://media.nngroup.com/media/editor/2025/12/01/screenshot-2025-11-27-at-25501pm.jpg)

_In this example,_ [NNG‚Äôs Live Training overview page](https://www.nngroup.com/training/live-courses/) _served as the visual reference for generating the_ Course Profile _page. When prompted to conduct a visual analysis, ChatGPT produced a detailed list of design characteristics and stylistic elements. These AI-generated descriptions can then be refined into prompts or used to extract relevant keywords and phrases for new ones._

![](https://media.nngroup.com/media/editor/2025/11/16/12-design.jpg)

The visual description serves as supplemental design context alongside the generic text prompt (Prompt 1). Using this approach, the generated design reproduces the visual style of the

### Generate Mock Data

Crafting prompts for AI-prototyping tools is a lot like creating [design specs](https://www.nngroup.com/articles/creating-design-specs-for-development/) for handoffs. In both cases, designers need to define not only visual and layout details but also interaction flows, content, and accessibility.

We often recommend [a _content-focused_ design approach](https://www.nngroup.com/videos/content-frames/) ‚Äî that is, **working with realistic data so that visual design supports the key content** rather than the other way around. The same principle applies when using AI-prototyping tools: providing sample content or data guides the AI to generate better designs.

Designers should collaborate with developers and content teams to obtain the data displayed in the interface. When real data isn‚Äôt available early in the process, designers can use AI [to generate mock data first](https://www.nngroup.com/articles/ai-data-prototype-testing/), then refine the content and iterate on the design based on that data.

![](https://media.nngroup.com/media/editor/2025/11/16/13-mockdata.jpg)

ChatGPT generated the mock data in JSON format, which was then used as content in Figma Make to create the profile page. Information is better grouped and displayed with this approach.

### Attach Code Snippets

When AI interprets images or documents instead of receiving direct input, some contextual details can get lost in translation. Therefore, the more direct the context you provide, the less interpretation the system needs to make ‚Äî and the higher the accuracy of the output. One of the most direct forms of context you can provide to an AI-prototyping tool is code snippets.

Designers can source code snippets in several ways:

* **From your codebase:** Collaborate with developers to access relevant components or layout structures.
* **From open-source design systems or code repositories:** Many public design systems (e.g., Material Design, Carbon) and platforms like [21st.dev](https://21st.dev/community/components) or GitHub offer reusable component code that can be incorporated directly into prompts.
* **From live websites:** Use browser-inspection tools or plugins to extract the underlying code of a page or component.

When using external sources, **keep in mind that visible code isn‚Äôt always free to reuse** ‚Äî always check the licensing or permissions. Stick to code from your own product, shared design-system libraries, or open-source components.

![](https://media.nngroup.com/media/editor/2025/11/16/14-code_1.jpg)

The course-listing table is generated by referencing the Table component from the Shopify Polaris design system and attaching the corresponding code snippets.

While this method yields the most precise results in AI-prototyping tools, it comes with tradeoffs. Long code snippets can overload the model‚Äôs context window, leading to performance issues. Moreover, this approach requires designers to understand basic code structure and assess the quality of the snippet before using it.

## Iterate and Critique Your Prompt with AI

Besides prompting AI to generate designs, you can also use it as a creative partner to enhance your prompts. You can use a general-purpose chatbot to:

* **Create a text prompt** from scratch, based on provided context
* **Organize design requirements** into a clear, structured prompt
* **Ask guiding questions** that help you think through requirements and refine ideas
* **Critique existing prompts,** identify missing context, and suggest improvements
* **Brainstorm and ideate** design variations in text form
* **Generate code snippets** for design components

## Good Design Decisions Can‚Äôt be Automated

At the end of the day, there is no shortcut to solving complex design problems. While strategies discussed in this article can help you improve your prompt specificity and get higher-quality output, **they can‚Äôt replace the hard work that goes into thinking through design requirements, weighing tradeoffs, and making informed design decisions**.

hidden text to trigger resize events if fonts change

---

# [‰∫îÊù°1212] Áî®AIÁºñÁ†ÅÔºåËÆæËÆ°Â∏à‰πüËÉΩÊûÑÂª∫ÁúüÂÆû‰∫ßÂìÅ
ÂèëÂ∏ÉÊó•ÊúüÔºö2025/12/10

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/1*iKZi1S4e49osr-hGUIZDDw.png)

Illustration of two overlapping circles representing ‚ÄúDesign‚Äù and ‚ÄúEngineering,‚Äù with the overlap shaded to show the shared space between the disciplines.

Over the past few months, I have noticed a quiet shift in how we build products. You start noticing design and engineering overlapping at scale much earlier, pretty much as soon as a feature moves from research into the ideation stage.

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:1000/1*OyLE3y-V5eOwrJ6zIPGfEw.gif)

I built this AI-powered prototype for a feature with Claude Code

This is one of the recent features where I built the entire flow end-to-end with a different workflow. I designed the experience, developed the UI with ShadCN components, built the interaction patterns, and connected it to real logic in the background. The prototype pulled data through Supabase MCP calls and interacted with OpenAI APIs to generate adaptive UI components, so the whole thing behaved close to the final product experience rather than a typical mock or demo.

This shift in how I solve problems pushed me beyond prototyping. I started productionizing my work inside the codebase, learning engineering patterns every day, and developing a clearer sense of how the product should function from end to end across the entire system.

> It moved me from being a designer to becoming a maker, and it is now shaping me into a **context-aware builder**.

This article is a reflection of that journey, how it improved the velocity, the challenges I encountered, and what we should anticipate, that could define the next chapter of product design development.

## The Problem I Kept Running Into

When the [vibe coding culture](https://spin.atomicobject.com/designers-vibe-coding/) started appearing everywhere, I saw significant people from the design community building retro games, dashboards, weather widgets, note apps, and many experiments powered by AI-generated code. It was encouraging to see designers making ideas work, but it reminded me of the famous [Dribbble](https://dribbble.com/) phase where everything looked beautiful but very little made it into real products.

I kept asking myself:

> Is this just another playground? Or can this way of working eventually influence production software?

The understanding of what sits under the hood among the community was still early, and most prototypes focused more on exploration than real functionality. It felt like the community is just beginning to scratch the surface of what is possible.

The bigger issue was not the experiments themselves. It was that designers still did not have a functional layer to work in. This gap between design and development has been [well-documented](https://webdesignerdepot.com/the-designer-developer-handoff-is-still-broken-why/), with many teams struggling to move from static mockups to functional products. Figma, the most common tool designers use, sits in an isolated space. Even with custom plugins, Code Connect, and dev mode, the influence on the codebase is minimal. Most of it feels like a workaround. The design mocks rarely have the ability to test with real or dynamic data.

The other challenge is **feature fragmentation**.

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/1*dzXHJTKOo0BIsQkJrOcUpg.png)

Figma project view showing a grid of separate design files, illustrating how individual features are organized into their own design files.

In Figma, each feature is usually worked on in a separate file. It gives clarity for design, but it does not reflect how a real product works. In an actual product, features live together, share context, depend on each other, and behave as a single system. Moving across flows should feel natural and connected, not scattered across isolated files.

If you look at the distribution, the user interacts with the final product. Testers have staging and UAT environments. Developers have a full git workflow with branches and review layers. **Designers do not have anything equivalent.** There is no layer that lets us build with a real functional context.

## Where I Started: Two Paths

My initial integration of AI into my workflow was actually quite practical. I was trying to optimize some design operations and design system workflows, and I did not have enough bandwidth to fit all of it into my routine. There was no AI integration inside IDEs at that time. Everything was manual, disconnected, and very experimental. So used AI generated scripts for these automations.

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:1000/0*Dbrv3k8YWwdNbM9Y)

Side-by-side graphic showing an early AI-assisted workflow. On the left is a JavaScript script used to classify and extract color formats from CSS. On the right is a spreadsheet containing hundreds of color definitions generated from that script.

Seeing the potential, I wanted to understand the full range of AI API offerings beyond prompt-based code generation. During the same timeline, I was exploring prototyping with Origami and wanted to see if I could bring AI capability directly into the prototype. I experimented with building an Origami prototype that used the OpenAI API for chat completion requests and audio-to-text conversion

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/1*0yMZrq2MCBYpNd-BHvKbYg.gif)

Whisper API from Open AI for converting song audio into lyrics

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/1*yN9Rq_VuJ_x3V_iEgKrYkQ.gif)

Color picker through camera to get description about the color

This exploration revealed two paths:

1. **Using AI to build the prototype itself**
2. **Enabling the prototype with AI features**

This distinction between using AI as a tool to build versus integrating AI into features aligns with what [Wyatt Kay describes](https://medium.com/design-bootcamp/vibe-coding-as-a-designer-what-ive-learned-so-far-029c1cc4636d) as the dual nature of AI-powered design work where the technology serves both as creation medium and feature component. Understanding this separation became an important part of how I now approach prototyping ideas.

## Finding the Right Tools

As I started building more rigorously, I needed to settle on tools that matched my workflow. I explored several options including [v0](https://v0.app/) for quick layouts and [Cursor](https://cursor.com/) for its smooth IDE experience, but token exhaustion rate became a practical constraint.

[Claude Code](https://claude.com/product/claude-code) stood out for its efficiency. Using the same Sonnet model across different tools, Claude Code handled tokens far better and stayed lightweight for repeated everyday use. It began as a simple terminal interface but quickly became my primary tool because it fit the way I build products every day.

The rise of MCPs (Model Context Protocol) also meant that most missing features could be achieved across different AI-powered IDEs anyway. What mattered more was finding a tool that matched my cost and workflow needs for sustained use.

## Where I Arrived: The Shadow Repo Approach

I came across a [tweet](https://x.com/nayakkayak/status/1958677324863328643?s=20) by Aatish Nayak, VP product at Harvey, about building an entire frontend using vibe coding. He called it a **shadow repo**, and the idea made immediate sense. The concept addresses what [Dan Mall and Brad Frost call the ‚ÄòHot Potato Process‚Äô](https://smart-interface-design-patterns.com/articles/design-handoff/), rapid iteration between designers and developers that eliminates traditional handoff friction.

Think of it like this: if staging/UAT is where testers validate features, a shadow repo is where designers validate functionality. This approach creates breathing room to experiment with full product context and less risk.

A real git branch carries engineering expectations, reviews, and risk. A shadow repo removes that pressure. You can try ideas, break things, and test with real or mock data without touching the product codebase.

Here is how I shaped workflow with this shadow repo:

* Build a repo that mirrors the real app structure
* Follow production component patterns
* Use Figma for skeleton and visual direction
* Translate with Figma MCP, applying coded design system rules
* Refine through manual edits and prompting
* Use Notion MCP for handoff review notes
* Port to production with developer review and proper API wiring

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/1*edDAUJWubwolp4UKfolOGg.png)

Flow diagram showing how design and code inputs feed into a shadow repository. A ‚ÄúDesign File‚Äù flows into the shadow repo through Figma MCP, and a ‚ÄúComponent Library‚Äù flows in through ShadCN MCP. Both inputs merge into the ‚ÄúShadow Repo Codebase,‚Äù which then connects to Notion MCP, producing a final ‚ÄúHandoff Spec‚Äù for developer review.

## Solving the Data Problem

Early shadow repo prototypes relied on local storage, placeholder JSONs, and fake values. This breaks down when replicating a full product experience.

I created a shadow backend using Supabase. Supabase‚Äôs free tier plus [Supabase MCP tools ](https://supabase.com/docs/guides/getting-started/mcp)were perfect for this: quick tables, simple edge functions, instant data edits, predictable structure. This made the shadow repo feel complete.

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/1*7QVOgioibRVv58O_6ZbcTQ.png)

Flow diagram showing how three inputs feed into a shadow repo workflow. A ‚ÄúDesign File‚Äù flows into the system through Figma MCP, a ‚ÄúData Layer‚Äù flows in through Supabase MCP, and a ‚ÄúComponent Library‚Äù flows in through ShadCN MCP. All three converge into the ‚ÄúShadow Repo Codebase,‚Äù which then connects to Notion MCP to generate the final ‚ÄúHandoff Spec.‚Äù

Why not use the actual API of the product?

* Unmoderated calls are expensive
* Prototypes trigger unpredictable requests
* And I did not want to risk touching production backend systems at this point.

Once the data layer was in place, I could explore the second path: enabling prototypes with AI features themselves.

At Dynamo AI, our tools rely heavily on AI systems. My prototypes needed to behave like AI-powered products. I integrated lightweight OpenAI API calls to replicate real-world feature responses.

Supabase made this efficient. I could store conversation history, manage state, and handle AI responses without complex backend logic. MCP tools connected everything seamlessly for defining actual API calls, response processing, and dynamic interface updates.

And for inspecting within the browser by the agent during active development, the [Chrome Dev Tools MCP](https://developer.chrome.com/blog/chrome-devtools-mcp) solves it with my Claude setup.

## What I Gained from Building Functionally

This approach doesn‚Äôt require designers to become full engineers, a [decades-old debate](https://www.toptal.com/designers/ux/designers-coding) that often misses the point. As [Cap Watkins argues](https://capwatkins.com/blog/why-designers-really-should-learn-to-code), learning to code isn‚Äôt about independence but about deepening collaboration and shared understanding.

With this setup, I was able to prototype working features and ship much faster. In one instance, the developers reviewed the prototype code and had the production version ready for testing in a single evening. That was the moment I realized this workflow is quite practical, scalable and increase the velocity to a greater extent. I was no longer handing off design files. I was handing off a working prototype with a higher probability of accurately representing the idea into production quickly.

![](https://miro.medium.com/v2/resize:fit:500/0*69dzyRxN3kU5bKMx.gif)

Animated neon illustration of two outlined human heads facing each other, with glowing brains connected by looping, pulsating energy bands.

These are some of the shifts I noticed in my approach:

**Better fine-tuning of UI component architecture:** Seeing components run with real variants, props, and constraints helped me refine the architecture upfront and create cleaner, more scalable patterns.

**Handling Edge Cases Early:** AI made it easier to surface edge cases and logical gaps early, long before engineering touched them.

**Thinking Through the Data Layer:** Working with real-like data broadened my thinking on structuring payloads and designing interface for efficient API usage and holistic thinking of how data flows through the entire system functionally.

**Enabling AI Features to Augment Capabilities:** Integrating actual AI behavior into prototypes changed how I think about product features. Instead of designing around static functionality, I started considering how AI could augment existing capabilities.

## How This Changed My Role in Problem Solving

This entire experiment changed my perspective on what it means to be a designer.

When you understand how data flows, how components are structured, what triggers API calls, and what engineers worry about, your design decisions become grounded in reality.

> You stop thinking like someone who ‚Äúhands off‚Äù and start thinking like someone who builds.

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/0*Wt8AEi9FyLKbiqZY.gif)

Animated gif of minimalist illustration of an open hand holding a simple outlined 3D house shape resting on a flat platform

AI coding tools are powerful, but they also come with real headaches:

**The rabbit-hole edits:** AI produces the first version well, but small edits sometimes break the entire flow and get you into an unnecessary loop of issues.

**Pattern-level mistakes:** With React components, I have faced unnecessary hooks, redundant functions, nested components, strange abstractions, and recursive API calls.

**AI fingerprints:** AI often generates the same UI patterns for the same problem and ignores existing components.

**Overbuilding:** It is easy to drift into solving engineering problems and lose sight of the actual user problem.

However, these challenges eventually can be addressed by defining rules that you can mention in your AI tool. In Claude, this is supported by [Claude.md](https://www.anthropic.com/engineering/claude-code-best-practices) and [Claude Skills](https://www.claude.com/blog/skills), which are project-agnostic and allow you to define explicit conditions and rules that guide how the AI should approach your programming tasks.

## What This Means Going Forward

The way we build products is shifting steadily. AI coding tools are changing the relationship between design and engineering. Shadow repos and vibe-coded prototypes let designers get much closer to reality. Complexity becomes easier to reason about. Ideas get validated faster.

> Teams spend less time interpreting and more time building.

We are moving from designer to maker to builder through changes in capability.

This mirrors what [Jakob Nielsen describes as ‚Äòvibe design‚Äô](https://www.uxtigers.com/post/vibe-coding-vibe-design), where AI enables rapid prototyping and designers work more iteratively with functional interfaces rather than static deliverables.

The shadow repo approach might not be a permanent solution. It is a good transitional framework that works while the industry figures out what the next generation of product-building tools should be. Right now, this framework works well for our team to build functionally without the constraints of traditional tools or the risks of production systems.

The industry is figuring this out together. If you are exploring similar territory or approaching these problems differently, let‚Äôs connect and learn from each other.

_If you are curious to see more of my work, check out my_ [_portfolio_](https://www.pratheep.design) _where I have documented some of these experiments._

hidden text to trigger resize events if fonts change

---

# [‰∫îÊù°1218] Pinterest 2026 Ë∂ãÂäøÔºö‰∏ã‰∏Ä‰∏™ÁàÜÊ¨æÁÅµÊÑüÂ∫ì
ÂèëÂ∏ÉÊó•ÊúüÔºö2025/12/18

[](https://business.pinterest.com/en-gb/pdf/pinterest-predicts/2026-trend-report/)

[](https://business.pinterest.com/en-gb/pinterest-predicts/about/)

[](https://business.pinterest.com/en-gb/pinterest-predicts/for-businesses/)

[](https://business.pinterest.com/en-gb/pdf/pinterest-predicts/2026-trend-report/)

![](https://images.ctfassets.net/h67z7i6sbjau/oP2ubnRiHiKxuk7YoNF0n/39979d0d22d6402f7d4456d254cc86be/Hero_Image_1.jpg?fm=webp&q=85)

![](https://images.ctfassets.net/h67z7i6sbjau/Kxa7j4zy7LWZawGsocELd/3daf57bf78f602264dc5e3c539dff32d/Masked_Pindow_Image_1A-hover.png?fm=webp&q=85)

![](https://images.ctfassets.net/h67z7i6sbjau/4v0i3d5Yj0mazCIVUMmyJ2/57d0360d8fb74affbaeb69649d154377/Masked_Pindow_1A.png?fm=webp&q=85)

Pin window 1

![](https://images.ctfassets.net/h67z7i6sbjau/1d1aLmrqH4bz7a5DhcYcbF/ced0f4153c6f02146015d3a403928673/Masked_Pindow_Image_1B-hover.png?fm=webp&q=85)

![](https://images.ctfassets.net/h67z7i6sbjau/65P05qGZ59nSrO7vSPzSIV/bf3612185d3255849df48bc52dc133cc/Masked_Pindow_1B.png?fm=webp&q=85)

Pin window 1

![](https://images.ctfassets.net/h67z7i6sbjau/4ql2WF3u2Yf5OKlsjYyp2m/b17746627ce932a7161757aa5cf08572/Masked_Pindow_Image_1C-hover.png?fm=webp&q=85)

![](https://images.ctfassets.net/h67z7i6sbjau/22b5DnF6L0oz8qlEu4QVW9/d02c0ca142f8a3d6735bb48d110b3230/Masked_Pindow_1C.png?fm=webp&q=85)

Pin window 1

![](https://images.ctfassets.net/h67z7i6sbjau/1ljh9khIhqZHXfuUQPWKFt/9c51c5a889a93b6a33478954808a560b/Hero_Image_2.jpg?fm=webp&q=85)

![](https://images.ctfassets.net/h67z7i6sbjau/rutnj1iqfyGx6m1ZmYcyG/63268d1e198bd2f82a491157c13378c3/Masked_Pindow_Image_2A-hover.png?fm=webp&q=85)

![](https://images.ctfassets.net/h67z7i6sbjau/1XzZsd4VvlVDMxTfSg4UlB/a448978f6af30b1d2e66482b180bc762/Masked_Pindow_2A.png?fm=webp&q=85)

Pin window 1

![](https://images.ctfassets.net/h67z7i6sbjau/5vSijUrptDQorar6IoGUaH/d973377ad7b81305de88ceb593eabbb5/Masked_Pindow_Image_2B-hover.png?fm=webp&q=85)

![](https://images.ctfassets.net/h67z7i6sbjau/6dJibXHcMzOhoIsCKxtm7E/1af3382eacddd7d341b2367008c25a28/Masked_Pindow_2B.png?fm=webp&q=85)

Pin window 1

![](https://images.ctfassets.net/h67z7i6sbjau/5twAOikHBgZ9kvVOByVs8x/b686349c1c8e57b131cbb1f1a20e3a28/Masked_Pindow_Image_2C-hover.png?fm=webp&q=85)

![](https://images.ctfassets.net/h67z7i6sbjau/4R3ND0iTLguRaJXMS8e9Wf/5d5273f6acb3f0b0af7a309c615b6de2/Masked_Pindow_2C.png?fm=webp&q=85)

Pin window 1

![](https://images.ctfassets.net/h67z7i6sbjau/2cm4EySoSyUyOU50aQNQLr/99412fbab27e7bbbf239e33c3d99f14b/Hero_Image_3__2_.jpg?fm=webp&q=85)

![](https://images.ctfassets.net/h67z7i6sbjau/520G7jtfSrJ4Nauk1OFQ9p/85de9e6258a82856730cb659563f583c/Masked_Pindow_3A.png?fm=webp&q=85)

![](https://images.ctfassets.net/h67z7i6sbjau/4aQVH3qy1HicoBFzxx1oHR/055e7d5a3c2c6715465e7bb9e45ef6af/Masked_Pindow_Image_3A-hover.png?fm=webp&q=85)

Pin window 1

![](https://images.ctfassets.net/h67z7i6sbjau/1GKgxhr6qlD74nWS6lrwhl/bd9a62b568fad44f750555e0ee270b90/Masked_Pindow_3B.png?fm=webp&q=85)

![](https://images.ctfassets.net/h67z7i6sbjau/CvqAyYmJZEWsLF9uPyiu0/45e7cb7e0c92930629fdc608d740efbb/Masked_Pindow_Image_3B-hover.png?fm=webp&q=85)

Pin window 1

![](https://images.ctfassets.net/h67z7i6sbjau/7tS7apFpYCB9l4R2KLKX2G/e08d26f2f3e15fb9726a5603fc09a176/Masked_Pindow_3C.png?fm=webp&q=85)

![](https://images.ctfassets.net/h67z7i6sbjau/5hHb4vsNoJP90CvhduI0q3/90979be02b7a581f26c010d368bc0b97/Masked_Pindow_Image_3C-hover.png?fm=webp&q=85)

Pin window 1

![](https://images.ctfassets.net/h67z7i6sbjau/5UuJkdoq5aaVPuwmSuKkfs/4650f6e310ceb13ed5146a7ee920d5bc/GimmeGummy-wordmark.png?fm=webp&q=85)

The words ‚ÄòGIMME GUMMY‚Äô in a bold, black, squiggly font with the ‚ÄòI‚Äô shaped like a gummy bear.

![](https://images.ctfassets.net/h67z7i6sbjau/5PzsgjolHRw2x40l26javi/43e4d872ca515c0803b703d27cd889f7/3_4_GimmeGummy_hero.jpg?fm=webp&q=85)

A young woman with pink pigtails wears bright, chunky accessories and has nails with plastic gummy bears stuck on them.

![](https://images.ctfassets.net/h67z7i6sbjau/3o6Sq9fCnVEdQrA5yi2QV9/ee82ebe3573b29604eef3bb9cedf1faf/Trend_Key_Viz_2X.png?fm=webp&q=85)

Gummy bears dangling off of a hair tie and a wrist wearing colourful, chunky plastic bracelets.

In 2026, we‚Äôre going full-on gummy. Gen Z and Millennials are behind this ASMR overload‚Äîpicture bendy phone cases, elastic cheek tints and probiotic treats that have that spring-back bite. Expect rubberized nail art and 3D jewellery to become your new tactile obsession.

Gimme Gummy: New Pinterest Predicts‚Ñ¢ trend for 2026

![](https://images.ctfassets.net/h67z7i6sbjau/1h7vLvWtJFT1eoVAgqQpcc/1ed3635e5bd57d88872b6ca869e37a3a/GimmeGummy-1.jpg?fm=webp&q=85)

A hand holds a purple phone case with bubbly hearts. The person is wearing gummy-bear nails and colourful clothes and accessories.

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

The decade of decadence is back in style‚Äîand honestly, it‚Äôs about time. Tailored suits with sculpted shoulders will grow three sizes. Funnel necks will be the base of every outfit. And jewellery? Well, that‚Äôll get chunkier, bolder and golder. Gen Z and Millennials are driving this maximalist aesthetic.

Glamoratti: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

Aspiring authors, take note. In 2026, Gen Z and Millennials will channel their inner wordsmiths with oversized turtlenecks, vintage blazers and messenger bags. Oh, and don‚Äôt forget the fountain pen.

Poetcore: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

The Art Deco trend is getting a modern twist: shiny, sleek and tuned to 2026\. After years of heavy minimalism, this retro aesthetic is back with crisp chevrons, fan arches and other geometric hits, all edged in chrome or brass. Bold, glam‚Äîand just a touch eccentric.

Neo Deco: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

Shake up your signature scent. Gen Z and Millennials are ditching one-and-done scents for bespoke notes, blending oils and perfumes to craft their very own fragrance formulas. Expect luxury to linger in layers next year.

Scent Stacking: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

There‚Äôs a new way to wear your heart on your sleeve. Or tie. Or socks. In 2026, Boomer and Millennial men will punctuate their ‚Äôfits with vintage pins, crystal clip-ons and heirloom brooches. It‚Äôs part tribute, part reinvention. If your gran wouldn‚Äôt wear it, is it even the vibe?

Brooched: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+). Please note that Pinterest‚Äôs Advertising Guidelines prohibit targeting of any audience based on gender identity, race, ethnicity or religious beliefs, among other things. For more information, please see our Advertising Guidelines.

Big top, bigger personality. In 2026, circus-inspired home d√©cor will be on the rise: think bold stripes, sculptural silhouettes and just a wink of clownish charm. The trick is balance. Pair punch-line patterns with pared-back palettes so the space feels elevated, but oh, so out there.

FunHaus: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

Lace sets the pace in 2026, bringing unexpected elegance to absolutely everything. Expect bomber jackets with lacy collars, softly stitched bandanas‚Äîeven crocheted phone cases. This trend is a gentle reminder that more is more: especially when it‚Äôs this gorgeous.

Laced Up: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

Your inbox is about to get jealous of your letter box. Expect a letter-writing renaissance in 2026, as Gen Z and Millennials turn snail mail into authored art. Think elaborate envelopes, special stationery and so. many. stamps. DMs, you‚Äôre dust.

Pen Pals: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

Beauty bites back with this 2026 trend. Millennials and Gen Z will go all in on after-dark aesthetics, embracing jet black nails, romantic goth hairstyles and a smudged smokey eye‚Äîall with a touch of glossy glamour. Who says you can‚Äôt be haunting and heartbreaking?

Vamp Romantic: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

Meet the shade that refuses to warm up to anyone. Gen Z and Millennials are bringing a subzero sophistication to absolutely everything in 2026‚Äîthink cool-toned coats, glacier-inspired accessories and the frostiest of cocktails. It‚Äôs the temp drop we‚Äôve all been waiting for.

Cool Blue: New Pinterest Predicts‚Ñ¢ Trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

2026 will bring a fusion of African and bohemian styles, thanks to Boomers and Gen X. Searches for ‚Äòafrican boho living room‚Äô and ‚Äòafro chic home decor‚Äô are trending up on Pinterest, taking home spaces to Dakar and beyond. Expect colourful Nigerian textiles and Ethiopian wall art alongside handwoven baskets and natural fibre rugs.

Afrohemian Decor: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+). Please note that Pinterest‚Äôs Advertising Guidelines prohibit targeting of any audience based on gender identity, race, ethnicity or religious beliefs, among other things. For more information, please see our Advertising Guidelines.

Fairytale meets fever dream in 2026‚Äôs biggest travel trend. Millennials and Boomers will seek out whimsical and mystical destinations: distant ruins swallowed by mist, naturally-occurring spirals and moody, enchanting forests. You may find you come back with more questions than answers.

Mystic Outlands: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

The perfect winged liner? She doesn‚Äôt go here. This year, beauty is missing the mark‚Äîon purpose. Gen Z and Millennials will rock mismatched manicures, dual-toned lipstick and bright eyeshadow in two-toned hues. So long, symmetry.

Glitchy Glam: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

Dig into fashion‚Äôs newest find. This year, Gen Z and Millennials will embrace a new aesthetic inspired by wanderers of the world. Think khaki bermuda shorts, adventure-ready streetwear and pockets upon pockets. If your look can survive actual desert conditions, you‚Äôre doing it right.

Khaki Coded: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

The motto for 2026? Live, laugh, leaf! In the year ahead, Boomers and Gen X will say goodbye to their cauliflower obsession and crown cabbage the new kitchen champ. Think blistered-edge ‚Äústeaks‚Äù, kimchi cocktails and even crispier taco wraps. It‚Äôs crunch time, baby.

Cabbage Crush: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

In 2026, Gen Z and Millennials are going intergalactic. Think holographic home accents, opalescent eyeshadow that looks like moon dust, and cosmic silhouettes straight out of a sci-fi film. The aliens have landed‚Äîand they have fabulous taste.

Extra Celestial: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

A trend that whispers instead of roars. In 2026, Gen Z and Boomers will go all in on animal aesthetics‚Äîbut with a delicate touch. Think soft fawn freckles, butterfly wing nail art and fox-inspired outfits that hint at forest magic.

Wilderkind: New Pinterest Predicts‚Ñ¢ trend for 2026

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

![](https://images.ctfassets.net/h67z7i6sbjau/6FfAUmvjrIMeS1iuWUhs68/e0d449c2e00978986737197e46f0c866/ThrowbackKid-wordmark.png?fm=webp&q=85)

The words ‚Äòthrowback kid‚Äô in navy, blocky font.

![](https://images.ctfassets.net/h67z7i6sbjau/5TLXD1a8kzs2isvOlYqwn6/c393af267750dff492921aa7c62f57c1/3_4_ThrowbackKid_hero.jpg?fm=webp&q=85)

Three children are in a room playing with toys on a table, surrounded by streamers and a shelf full of books and toys.

![](https://images.ctfassets.net/h67z7i6sbjau/4Oy9pS7JMAQmgcVb1XedOq/09adea3864366c0c73045eb97f2f046a/Trend_Key_Viz_2X.png?fm=webp&q=85)

A green jumper with a racing car on it, a blue wall clock and a toy robot.

In 2026, childhood gets a throwback twist with vintage-inspired outfits, classic toys from the ‚Äô60s and upcycled baby looks. Crocheted play mats will bring cosy vibes to any nursery, while Baby Boomers and Gen X will thrift mini ‚Äôfits. Let‚Äôs go back in (play)time.

Throwback Kid: New Pinterest Predicts‚Ñ¢ trend for 2026

![](https://images.ctfassets.net/h67z7i6sbjau/18jhWOmCSpAiLC8PmQ1COu/ffba0f910e7f190138801e05de177060/ThrowbackKid-1.jpg?fm=webp&q=85)

A child in a colourful orange-striped dress looks at a pony on the other side of a fence.

![](https://images.ctfassets.net/h67z7i6sbjau/4y7wCEYr9QS2X2qO2Ppyy7/2103053e84266f679149031b570a2076/ThrowbackKid-2.jpg?fm=webp&q=85)

A vintage-esque colourful jumper with a tractor, sun and clouds on it. 

![](https://images.ctfassets.net/h67z7i6sbjau/6KPWVhRMZf0GMWPvgzDQsZ/d5e3134c4b926af9b4ae939dad66df4e/ThrowbackKid-3.jpg?fm=webp&q=85)

A wooden clock shaped like a rocket ship. 

![](https://images.ctfassets.net/h67z7i6sbjau/6W5SxWWnP163yAfdfxU0Le/8912945d670b0849b4d13f23b28cdb58/ThrowbackKid_FakePin_enGB.png?fm=webp&q=85)

An example ad with a Pinterest Predicts trend badge shows an ad from Katie‚Äôs Kitchen with breakfast food and the copy ‚ÄòNostalgia never tasted so good.‚Äô A label nearby indicates increasing Pinterest saves. 

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

![](https://images.ctfassets.net/h67z7i6sbjau/3WQNnelUCj3AwDPfZEcQhK/2fc7b8a2da337f270a349240fb9f5f10/Darecations-wordmark.png?fm=webp&q=85)

The word ‚ÄòDARECATIONS‚Äô in a bold, dark-blue font with spiky text.

![](https://images.ctfassets.net/h67z7i6sbjau/29fuAKSKbyZVPxXmvECCvd/92e619ae93b2a9e520915ffc77f16d2e/3_4_Darecations_hero.jpg?fm=webp&q=85)

Close-up shot of a man in a yellow shirt and goggles reflecting a view of cars on a racetrack.

![](https://images.ctfassets.net/h67z7i6sbjau/2FoDuYzJy2ONx8VqKXqo9D/5a49c7b7a11b62bf91789685a776d30f/Trend_Key_Viz_2X.png?fm=webp&q=85)

Goggles reflecting a person snowboarding and a dirt bike going through mud.

Sitting on the beach? Snooze. In 2026, we‚Äôre travelling for the thrill of it. Gen Z and Millennials will seek out full-throttle, adrenaline-inspired tourism‚Äîthink river rafting through class 5 rapids, rappelling waterfalls on canyoneering routes or timing trips around global sporting events. What‚Äôs a comfort zone?

Darecations: New Pinterest Predicts‚Ñ¢ trend for 2026

![](https://images.ctfassets.net/h67z7i6sbjau/7aZWxpHuw7YDvDy9qGtoHH/f2ab14589cc15e1af8ab8c26791fec91/Darecations-1.jpg?fm=webp&q=85)

Overhead view of an airport security tray filled with a climbing rope, a camera, a yellow hat, blue headphones, a toiletries bag and a blue passport holder.

![](https://images.ctfassets.net/h67z7i6sbjau/2y6o8ygPHqcmNY8exysdlH/d5696b7a5c8b8a517d1c5fe8bb96a5f3/Darecations-2.jpg?fm=webp&q=85)

A person with a prosthetic leg hangs from a climbing rope on a mountainside, with trees, distant peaks and a golden sky in the background.

![](https://images.ctfassets.net/h67z7i6sbjau/7Bh83yon2Yygn5gqUJibzT/5c76f5bb12f3ed37695944709403052a/Darecations-3.jpg?fm=webp&q=85)

Icebergs jut out of a blue ocean, seen from an orange raft. 

![](https://images.ctfassets.net/h67z7i6sbjau/7lvLNcW31pHLXXGQaiqB6X/b4961a09487978e7eb9df9885b5c8620/Darecations_FakePin_enGB.png?fm=webp&q=85)

An ad for GOEDEREIS reads ‚ÄòDare-ready gear‚Äô and shows a person skiing down a mountain. ‚ÄòPinterest Predicts 2026 Trend Darecations‚Äô appears at the top of the ad. 

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

![](https://images.ctfassets.net/h67z7i6sbjau/5YQrTMDeDXeIB9YJZUfuyB/aba7e5cdd396ebd37babc1a51d8a5a50/OperaAesthetic-wordmark.png?fm=webp&q=85)

The words ‚ÄòOPERA AESTHETIC‚Äô in a thin font with swoops.

![](https://images.ctfassets.net/h67z7i6sbjau/w61yKJqvwKdHICsBQVJj9/4a90a02810ae79fe4885fed8276f43d1/3_4_OperaAesthetic_hero.jpg?fm=webp&q=85)

An older woman in a sparkly blue gown holds a coupe glass in front of a dark-red curtain backdrop. There is a champagne fountain and chandeliers on tables behind her.

![](https://images.ctfassets.net/h67z7i6sbjau/3HtUcLsC50CklEq0c5vqEO/f3a1e7787e3c5d32930be31628638d74/Trend_Key_Viz_2X.png?fm=webp&q=85)

A martini glass, a bouquet of roses and a table with a pink cloth and champagne glasses on it.

Picture this: dramatic drapery, red roses and a string quartet playing dark cabaret. In 2026, parties will become more opulent than ever as Millennials and Gen Z bring the vintage theatre aesthetic to every one of their gatherings. Cue the curtain‚Äîevery detail is ready to perform.

Opera Aesthetic: New Pinterest Predicts‚Ñ¢ trend for 2026

![](https://images.ctfassets.net/h67z7i6sbjau/52pRffTnzzOyBekTONRu8z/9100362b6cf181ec57b8154f8c185e69/OperaAesthetic-1.jpg?fm=webp&q=85)

A two-tier cake with white fondant next to a champagne glass.

![](https://images.ctfassets.net/h67z7i6sbjau/4qavtMybOfBZCgFfTc8UIv/e019836529eb59cdc67e20703a643a36/OperaAesthetic-2.jpg?fm=webp&q=85)

A hand holds a vase that has a dramatic red-and-green bouquet. 

![](https://images.ctfassets.net/h67z7i6sbjau/3CREzmq6Cby9EEipNDTiG2/9372fcbd0ec57e206c62437cd7947229/OperaAesthetic-3.jpg?fm=webp&q=85)

A hand holds opera glasses. 

![](https://images.ctfassets.net/h67z7i6sbjau/1HupU0dGAJFEMIg8XHVfo3/609110d6d17aa4583a329f7d635e711f/OperaAesthetic_FakePin_enGB.png?fm=webp&q=85)

An example ad shows a theatre with the copy ‚ÄòWhich famous opera house should you visit first?‚Äô and a button encouraging people to take a quiz. It has a Pinterest Predicts trend badge and shows increasing saves.

1. Sourcing: Pinterest internal data, English language search data, global, analysis period September 2023 to August 2025\. Unless otherwise noted, changes are calculated using normalised searches during September 2024 to August 2025 compared to normalised searches during September 2023 to August 2024\. Early adopters highlights the top generations that are contributing to search growth relative to average generational activity between September 2024 and August 2025\. Demographic generations defined as Gen Z (18‚Äì27), Millennials (28‚Äì43), Gen X (44‚Äì59) and Baby Boomer (60+).

![](https://images.ctfassets.net/h67z7i6sbjau/6wtz1dHYurOAFQOIby4LVX/9bc80e9adaf54c7b3b4d3f0d7a6be437/1_1_GimmeGummy.jpg?fm=webp&q=85)

hidden text to trigger resize events if fonts change

---

# [‰∫îÊù°1219] AI ‰∫ßÂìÅÁöÑ‚ÄúËÆ∞ÂøÜ‚ÄùËÆæËÆ°Ôºö‰∏Ä‰∏™‰∏âÂ±ÇÊ°ÜÊû∂
ÂèëÂ∏ÉÊó•ÊúüÔºö2025/12/18

## A UX framework for managing library, conversation, and memory in LLM interfaces

![](https://miro.medium.com/v2/resize:fit:1400/1*AC5KhEsCkrjnz5-MEBMlJg.png)

AI context as a reflection of human memory

To make a large language model (LLM) truly useful, everything begins with context management.

Context is more than a single prompt, it is the entire accumulation of conversation series. Every user input, combined with every AI response, forms the evolving environment in which meaning is created.

In practice, context behaves a lot like memory. Just as human memory is organized, the context of an AI system can also be understood as a layered structure.

![](https://miro.medium.com/v2/resize:fit:2000/1*cQUs2btriDxwtPehCYn4IA.png)

Human memory is often described in three parts:

* **Semantic memory:** long-term knowledge, concepts, and facts ‚Äî what I know.
* **Working memory:** temporary information needed for the current task ‚Äî what I am processing right now.
* **Long-term memory:** accumulated experiences, preferences, and patterns ‚Äî what I tend to do.

![](https://miro.medium.com/v2/resize:fit:2000/1*ALnkFzPxHwronO5qI9zCNg.png)

AI systems mirror this architecture and its context can also be divided into three layers:

* **Library:** user-provided materials such as files, webpages, and excerpts.
* **Conversation:** the active dialogue, grounded in the current topic.
* **Memory:** accumulated information across sessions, specific to the same user.

Each layer plays a different role, and each demands a different design strategy.

![](https://miro.medium.com/v2/resize:fit:2000/1*meoUHzI7OxjJIiXnH7zHAQ.png)

> Establish a reliable knowledge base by enabling users to curate and structure their own materials. These resources serve as the system‚Äôs fixed semantic assets, grounding the model‚Äôs understanding in specific, user-defined contexts.

The value of this layer lies not in storage, but in how external knowledge is constructed and invoked.

Users need explicit, controllable access to these sources. Information must be **_readable_** to the model, **_discoverable_** to the user, and **_transparent_** in its invocation.

### Key Feature

* **Multimodal parser:** Accepts documents, web links, cloud files, and videos. Automatically converts them into structured, indexable content with keywords and metadata.
* **Context invoker:** Allows users to choose specific sources during a conversation. Context appears as visible chips, making the invocation scope clear and controllable.

### Use case

![](https://miro.medium.com/v2/resize:fit:2000/1*le0DWYlNDPLow8iCBglC3g.png)

[NotebookLM](https://notebooklm.google.com) and [Flowith](https://flowith.io) both support uploading multi-format files and external links. Flowith further analyzes and categorizes these materials, turning them into content seeds with associated keywords, making retrieval easier.

![](https://miro.medium.com/v2/resize:fit:2000/1*xOmbBIu0s2iZoHYpLwuvng.png)

Most products surrender the entire knowledge base to the AI once it‚Äôs uploaded. Users can‚Äôt control which part is being used. Tools like [YouMind](https://youmind.com) and [Notion AI](https://www.notion.com/product/ai) take a different approach: users can manually specify source files via @mentions, and context chips make these references explicit.

![](https://miro.medium.com/v2/resize:fit:2000/1*lCi_Ezjp4a86RN9U9mCRyQ.png)

> Use semantic organization and content extraction to maintain a coherent conversational environment. This keeps the dialogue focused while allowing key ideas to be captured and reused.

The challenge here is managing the vertical sprawl of long chat threads.

Instead of letting conversations stretch endlessly downward, the system should compress and surface meaning, helping users stay anchored in the current topic while carrying important information forward.

### Key feature

* **Semantic aggregator:** Automatically identifies thematic segments in long conversations and presents them in collapsible topic sections, expanding only what‚Äôs relevant.
* **Content notebook:** Allows users to extract AI outputs into an independent workspace for refinement, reducing the friction of scrolling, copying, and tracking.

### Use case

![](https://miro.medium.com/v2/resize:fit:2000/1*1XFM4r9M7UAMkGUwQjNIUg.png)

[Ask LukeW,](https://ask.lukew.com/chat) the assistant on [Luke Wroblewski](https://www.lukew.com)‚Äôs website, groups conversations into thematic clusters. Only the active theme is expanded, with others neatly folded away. This preserves spatial clarity and keeps users oriented.

![](https://miro.medium.com/v2/resize:fit:2000/1*bKD9rPhZV0IKWwTTZhd8iA.png)

Flowith‚Äôs Composer allows users to select AI outputs and send them directly into a dedicated workspace. This bridges the gap between conversation and downstream work, turning chat into a productive workflow rather than a transient thread.

![](https://miro.medium.com/v2/resize:fit:2000/1*y7BqigZ5dZoceMaw4fYrew.png)

> By accumulating and recalling memory across sessions, the system builds a continuous personalized context for interaction, allowing generated responses to better reflect the user‚Äôs experiences and preferences.

Memory must balance two goals: **personalization** and **user control.**

The system should remember a user‚Äôs preferences, routines, and domain knowledge, but must do so transparently, allowing the user to manage what is stored, recalled, or forgotten.

![](https://miro.medium.com/v2/resize:fit:1400/1*yHgNVJ1LC5Ci3OebVFtg1w.png)

You can search and delete saved memories in ChatGPT

### Key feature

![](https://miro.medium.com/v2/resize:fit:1400/1*sqWyQvXeRPv17SSq2b9IhQ.png)

* **Memory visualization:** AI responses display the memory elements they rely on, helping users understand why personalization occurs.
* **Memory management:** Users can enable or disable memory in each conversation, and view, edit, or block specific stored items.

### Prototype

![](https://miro.medium.com/v2/resize:fit:2000/1*PCRckFTVbRIj9YLyV6Zc3w.png)

I designed a set of memory controls for ChatGPT to make personalization more visible and negotiable.

Whenever the system draws on a stored memory, it surfaces as a small memory chip in the interface. This makes the moment of personalization explicit rather than hidden in the background.

From there, users can choose to keep, edit, or remove the memory fragment. The goal is not to collect more data, but to let users actively shape how the system remembers them over time.

## Context is the king ‚Äî but how?

![](https://miro.medium.com/v2/resize:fit:2000/1*h-I0xqq92qNHJcRUkvnsvA.png)

If context is king, its power comes from how carefully we design the layers that support it.

Library, conversation, and memory are not separate modules. They are three ways of structuring intelligence. They shape how knowledge is organized, how interaction happens, and how humans and AI come to understand each other over time.

Context is not just the background of interaction. It is the structure that allows meaning to emerge at all.

## üìñ Further reading

* [Effective context engineering for AI agents ](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)‚Äî Anthropic
* [Context Management UI in AI Products](https://lukew.com/ff/entry.asp?2110=) ‚Äî Luke Wroblewski
* [More on Context Management in AI Products](https://lukew.com/ff/entry.asp?2138=) ‚Äî Luke Wroblewski

**_Interested in how AI is reshaping interface design?_** 
[**_Join my newsletter_**](https://aiinterface.substack.com/) **_for insights, case studies, and the latest experiments._**

hidden text to trigger resize events if fonts change

---

# [‰∫îÊù°1222] LinearÂàõÂßã‰∫∫ÔºöËÆæËÆ°Ëøú‰∏çÊ≠¢ÊòØ‰ª£Á†Å
ÂèëÂ∏ÉÊó•ÊúüÔºö2025/12/21

[See all posts](https://baoyu.io/translations)

ÂÖ≥‰∫é‚ÄúÁî®‰ª£Á†ÅÂÅöËÆæËÆ°‚ÄùÁöÑ‰∫âËÆ∫Áî±Êù•Â∑≤‰πÖÔºåÊúÄËøëÂèàÂêµÁøªÂ§©‰∫Ü„ÄÇËøôÂ∑≤ÁªèÊòØÊàëÁ¨¨‰∏âÊ¨°ÂÜôËøô‰∏™ËØùÈ¢ò‰∫Ü„ÄÇÊàë‰πãÂâçÂÜôËøá [‚ÄúËÆæËÆ°ÊòØ‰∏ÄÁßçÊé¢Á¥¢ÔºåËÄåÈùûÊµÅÊ∞¥Á∫ø‚Äù](https://x.com/karrisaarinen/status/1999730838280503775)Ôºõ‰πüËÆ®ËÆ∫Ëøá [‚ÄúÂ∑•ÂÖ∑Êú¨Ë∫´Â∏¶ÊúâËßÇÁÇπ‚Äù](https://x.com/karrisaarinen/status/2000451411696603437)ÔºåËøô‰∫õËßÇÁÇπ‰ºöÊΩúÁßªÈªòÂåñÂú∞Â°ëÈÄ†Êàë‰ª¨ËÆ§‰∏∫Âì™‰∫õÂ∞ùËØïÊòØ‚ÄúÂêàÁêÜ‚ÄùÁöÑÔºõÊàëËøòË∞àÂà∞‰∫Ü‰∏∫‰ªÄ‰πàËøáÊó©ÂºïÂÖ•ÈôêÂà∂‰ºöÊâºÊùÄÂ∞öÊú™Ë¢´ÂèëÁé∞ÁöÑÂèØËÉΩÊÄß„ÄÇ

Âù¶ÁôΩËØ¥ÔºåÊàëÂØπË°å‰∏öÈáåËøôÁßçËøΩÊ±Ç‚ÄúÂ§ß‰∏ÄÁªü‚ÄùÁöÑË∂ãÂäøÊåÅÊÄÄÁñëÊÄÅÂ∫¶‚Äî‚ÄîËØïÂõæÊää‰∏Ä‰∏™ÂÖÖÊª°ÁªÜÂæÆÂ∑ÆÂà´ÁöÑËøáÁ®ãÂÖ®ÈÉ®ÂùçÁº©Êàê‰ª£Á†ÅÔºåÂπ∂Áß∞‰πã‰∏∫‚ÄúËøõÊ≠•‚Äù„ÄÇ

ÊúÄËøëÁöÑËÆ®ËÆ∫ÁÑ¶ÁÇπ‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÔºöËÆæËÆ°Â∏àÂà∞Â∫ïËØ•‰∏çËØ•ÂÜô‰ª£Á†ÅÔºü‰ª£Á†ÅÊòØ‰∏çÊòØËÆæËÆ°ÁöÑÊ≠£Á°ÆÂ™í‰ªãÔºü‰ª£Á†ÅÊòØÂê¶ÂëàÁé∞‰∫ÜËÆæËÆ°ÁöÑ‚ÄúÁúüÁõ∏‚ÄùÔºüÁ≠âÁ≠â„ÄÇ‰ΩÜÊàëËÆ§‰∏∫ÔºåÊääËæ©ËÆ∫ÁöÑ‰∏≠ÂøÉ‰ªÖ‰ªÖÊîæÂú®‰ª£Á†ÅÂíåÂ∑•ÂÖ∑‰∏äÔºåÊòØÊääË∑ØËµ∞Á™Ñ‰∫ÜÔºàReductiveÔºâ„ÄÇ

ÂØπÊàëÊù•ËØ¥ÔºåÊõ¥Â§ßÁöÑÈóÆÈ¢òÂú®‰∫éÔºöÂú®Êú™Êù•ÔºåÂ∞§ÂÖ∂ÊòØÂΩì AI ÂíåÊñ∞‰∏Ä‰ª£Â∑•ÂÖ∑ÊôÆÂèäÂêéÔºåÊàë‰ª¨Â¶Ç‰ΩïÁúãÂæÖËÆæËÆ°Â∏àÁöÑË¥°ÁåÆÔºüËßíËâ≤Â∞ÜÂ¶Ç‰ΩïÊºîÂèòÔºüÊàë‰ª¨ÂØπÂΩºÊ≠§ÁöÑÊúüÊúõÂèà‰ºöÊúâ‰ªÄ‰πàÂèòÂåñÔºü

ËÆæËÆ°Â∏àÁé∞Âú®ÁÆóÊòØÂ∑•Á®ãÂ∏à‰∫ÜÂêóÔºüËÉåË¥üÁùÄÂêåÊ†∑ÁöÑÊúüÊúõÔºüÂ∑•Á®ãÂ∏à‰ºöÂºÄÂßãÂØπËÆæËÆ°Â∏àÊúâÂêåÊ†∑ÁöÑË¶ÅÊ±ÇÂêóÔºüÊú™Êù•Êàë‰ª¨Ëøò‰ºöÊúâ‚ÄúÂ∑•Á®ãË¥üË¥£‰∫∫‚ÄùÂíå‚ÄúËÆæËÆ°Ë¥üË¥£‰∫∫‚ÄùÂêóÔºåËøòÊòØ‰ºöÂèòÊàê‰∏Ä‰∏™Áªü‰∏ÄÁöÑ‚ÄúÂå†ÂøÉË¥üË¥£‰∫∫‚ÄùÔºàHead of CraftÔºâÔºüÂ§¥Ë°îÊú¨Ë∫´Âπ∂‰∏çÈáçË¶ÅÔºå‰ΩÜËøôËÉåÂêéÁöÑÈóÆÈ¢òÂæàÊúâ‰ª∑ÂÄºÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Êè≠Á§∫‰∫ÜÊàë‰ª¨ÁúüÊ≠£ÁúãÈáç‰ªÄ‰πàÔºå‰ª•ÂèäÊàë‰ª¨Ë¶ÅÂ¶Ç‰ΩïÊääÂ∑•‰ΩúÂÅöÂ•Ω„ÄÇ

ËøôÂ∞±ÂºïÂá∫‰∫Ü‰∏Ä‰∏™ÂÆûÈôÖÈóÆÈ¢òÔºöÂ¶ÇÊûúËÆæËÆ°Â∏àË¢´Êé®ÂêëÂ∑•Á®ãÈ¢ÜÂüüÔºåÁõ¥Êé•Áî®‰ª£Á†ÅËøõË°åËÆæËÆ°ÔºåËøôÁúüÁöÑÊòØ‰∏™Â•ΩÊñπÂêëÂêóÔºüÊàë‰ª¨‰ºöÂõ†Ê≠§Â§±Âéª‰ªÄ‰πàÔºåÂèàÂæóÂà∞‰ªÄ‰πàÔºü

ËøôÂú∫ËÆ®ËÆ∫‰πãÊâÄ‰ª•ÂÆπÊòìÂèòÂæóÊ∑∑‰π±ÔºåÈÉ®ÂàÜÂéüÂõ†Âú®‰∫é‚ÄúËÆæËÆ°‚ÄùËøô‰∏™ËØçÂØπ‰∏çÂêåÁöÑ‰∫∫ÊÑèÂë≥ÁùÄÂÆåÂÖ®‰∏çÂêåÁöÑ‰∏úË•ø„ÄÇ‰Ω†ÁöÑÁúãÊ≥ïÂèñÂÜ≥‰∫é‰Ω†‰ªé‰∫ãÂì™ÁßçËÆæËÆ°Ôºå‰ª•Âèä‰Ω†Â¶Ç‰ΩïÁêÜËß£ËÆæËÆ°ËøôÈ°πÂÆûË∑µ„ÄÇ

ÊàëÁõ∏‰ø°ËÆæËÆ°ÊúâÂ§öÁßçÈ£éÂë≥„ÄÇÂÆÉÂèó‰∏™‰∫∫„ÄÅÈ¢ÜÂüü„ÄÅÂ∏ÇÂú∫ÂíåÂÆ¢Êà∑ÁöÑÂΩ±Âìç„ÄÇÂú®Ê∂àË¥πÁ∫ß‰∫ßÂìÅÔºàCÁ´ØÔºâ‰∏≠Ôºå‰Ω†ÂèØËÉΩÈúÄË¶ÅÂø´ÈÄüÊµãËØïÊÉ≥Ê≥ïÔºåÂõ†‰∏∫Áî®Êà∑ÁöÑÂä®Êú∫ÂæàÈöæÈ¢ÑÊµãÔºõÂú®‰ºÅ‰∏öÁ∫ßÊúçÂä°ÔºàB2BÔºâ‰∏≠Ôºå‰Ω†ÈÄöÂ∏∏Êã•ÊúâÊõ¥Â§öÁöÑ‰∏ä‰∏ãÊñáËÉåÊôØÔºåÂèØ‰ª•ÊçÆÊ≠§ËøõË°åËÆæËÆ°„ÄÇÊúâ‰∫õË°å‰∏öÈúÄË¶ÅÊûÅËá¥ÁöÑÂèØÈù†ÊÄßÂíåÊ∏ÖÊô∞Â∫¶„ÄÇÁéØÂ¢É‰πüÂæàÈáçË¶ÅÔºöÂà©ÁõäÁõ∏ÂÖ≥ËÄÖ„ÄÅÂÆ¢Êà∑„ÄÅÂÖ¨Âè∏ÊñáÂåñÔºå‰ª•Âèä‰Ω†‰Ωú‰∏∫ËÆæËÆ°Â∏àÁöÑÊäÄËÉΩ„ÄÇÂ¶ÇÊûú‰Ω†ÊìÖÈïøËßÜËßâÔºå‰Ω†‰ºö‰ª•ËßÜËßâ‰∏∫‰∏ªÂØºÔºõÂ¶ÇÊûú‰Ω†‰ª£Á†ÅËÉΩÂäõÂº∫Ôºå‰Ω†ÂèØËÉΩ‰ºöÊõ¥Êó©Âú∞‰ΩøÁî®‰ª£Á†Å„ÄÇ

ËÄåÂØπÂè¶‰∏Ä‰∫õ‰∫∫Êù•ËØ¥ÔºåËÆæËÆ°Êó†ÈùûÂ∞±ÊòØÊääÊåâÈíÆÁîªÂà∞Â±èÂπï‰∏äÔºåÁÑ∂ÂêéÂÆå‰∫ã„ÄÇ

ÊâÄ‰ª•ÔºåËΩØ‰ª∂ËÆæËÆ°ÊòØ‰∏Ä‰∏™ÂπøÈòîÁöÑÈ¢ÜÂüüÔºåÈáåÈù¢ÂåÖÂê´‰∫ÜÂêÑÁßçÂêÑÊ†∑ÁöÑÂ∑•ÂÖ∑ÂíåÊñπÊ≥ï„ÄÇ‚Äú‰ª£Á†Å vs Êó†‰ª£Á†Å‚ÄùÁöÑ‰∫âËÆ∫ÂæÄÂæÄÊêûÈîô‰∫ÜÈáçÁÇπÔºåÂèçËÄåÊàê‰∫Ü‰∏ÄÁßçÂà∂ÈÄ†ÂØπÁ´ãÁöÑÂäõÈáè„ÄÇ

ÊàëÊÉ≥Ë°®ËææÁöÑÊòØÔºåÊàëÊÉ≥ÊääËøôÂú∫ËÆ®ËÆ∫ÊèêÂçáÂà∞Â∑•ÂÖ∑‰πã‰∏äÔºåÁ°Æ‰øùÂ∑•ÂÖ∑‰∏ç‰ºöÂèçÂÆ¢‰∏∫‰∏ªÔºåÊé•ÁÆ°ËÆæËÆ°ÁöÑÊú™Êù•„ÄÇÊàë‰∏çÂ∏åÊúõÊàë‰ª¨‰ªÖ‰ªÖÂõ†‰∏∫Êñ∞Â∑•ÂÖ∑ËÆ©‚ÄúÊâßË°å‚ÄùÂèòÂæóÊõ¥ÂÆπÊòìÔºåÂ∞±ÊØ´Êó†ÂøÖË¶ÅÂú∞Ë¥¨‰Ωé‚ÄúÊ¶ÇÂøµÊÄßÊÄùÁª¥‚ÄùÂíå‚ÄúÂèëÊï£ÊÄßÊÄùÁª¥‚ÄùÁöÑ‰ª∑ÂÄº„ÄÇ

Âç≥‰ΩøÊòØÊï¥Â§©‰∏é‰ª£Á†ÅÊâì‰∫§ÈÅìÁöÑÂ∑•Á®ãÂ∏àÔºå‰πü‰ºöÊó∂‰∏çÊó∂‰ªé‰ª£Á†Å‰∏≠ÊäΩË∫´Âá∫Êù•„ÄÇ‰ªñ‰ª¨‰ºöÁîªÊû∂ÊûÑÂõæ„ÄÅËßÑÂàíÁ≥ªÁªü„ÄÅÊé®ÊºîÊùÉË°°„ÄÇËôΩÁÑ∂‰ª£Á†ÅÊòØËΩØ‰ª∂Ê†ñÊÅØÁöÑÂú∞ÊñπÔºå‰ΩÜÂÆÉÂπ∂‰∏çÊÄªÊòØÂÅöÂá∫ÊâÄÊúâÂÜ≥Á≠ñÁöÑÊúÄ‰Ω≥Âú∫ÊâÄ„ÄÇ

‰∏∫‰∫ÜËß£ÈáäÊàëÁöÑÊÑèÊÄùÔºåÊàëÂøÖÈ°ª‰ªéÊàëÂ¶Ç‰ΩïÁêÜËß£ËÆæËÆ°‰ª•ÂèäÊàëÂ¶Ç‰ΩïÂÆûË∑µËÆæËÆ°ÂºÄÂßãËØ¥Ëµ∑„ÄÇ

È¶ñÂÖàÔºåÊàë‰∏çÊòØÁßëÁè≠Âá∫Ë∫´ÁöÑËÆæËÆ°Â∏à„ÄÇËøáÂéª‰∫åÂçÅÂπ¥ÈáåÔºåÊàëÈÄöËøáÊï∞Áôæ‰∏™ËÆæËÆ°È°πÁõÆËá™Â≠¶ÊàêÊâç„ÄÇÊâÄ‰ª•Êàë‰∏çÊòØÂú®Êêû‚ÄúÁúãÈó®‰∫∫‚ÄùÈÇ£‰∏ÄÂ•óÔºàGatekeepingÔºåÊåáËÆæÁ´ãÈó®ÊßõÊéíÊñ•‰ªñ‰∫∫ÔºâÔºå‰πü‰∏çÊòØÂú®ÈºìÂêπÊüêÁßçÂîØ‰∏ÄÁöÑ‚ÄúÊ≠£Á°Æ‚ÄùËÆæËÆ°ÊñπÂºè„ÄÇ‰ΩÜÊàëÁ°ÆÂÆûËÆ§‰∏∫ÔºåËÆæËÆ°ÂæàÂ∞ëÊòØÁ∫øÊÄßÁöÑ„ÄÇ‰Ω†ÈúÄË¶ÅÂú®‰∏çÂêåÁöÑÊäΩË±°Â±ÇÁ∫ß‰∏äÂ∑•‰ΩúÔºåÂπ∂Âú®ÂÆÉ‰ª¨‰πãÈó¥Êù•ÂõûÂàáÊç¢„ÄÇËôΩÁÑ∂ÁªìÊûúÊòØÊúÄÁªàÁõÆÊ†áÔºå‰ΩÜÂú®ËøáÁ®ã‰∏≠Ëä±Ë¥πÁöÑÊó∂Èó¥ÂæÄÂæÄËÉΩËÆ©ÁªìÊûúÂèòÂæóÊõ¥Â•Ω„ÄÇ

ÈÄöËøáËøô‰∫õÂ∑•‰ΩúÔºåÊàëÂ≠¶‰ºö‰∫Ü‰∏Ä‰ª∂‰∫ãÔºö**È¶ñÂÖàË¥®ÁñëÈóÆÈ¢òÊú¨Ë∫´ÔºåËÄå‰∏çÊòØÊääÂÆÉÂΩì‰ΩúÊó¢ÂÆöÂÅáËÆæ„ÄÇ** Â¶ÇÊûúÊúâ‰∫∫ËÆ©ÊàëÂÅö‰∏Ä‰∏™‰∏úË•øÔºåÊàë‰ºöÂÖàÈóÆÔºöËøôÊòØ‰∏Ä‰∏™ÁúüÈóÆÈ¢òÂêóÔºüÂ¶ÇÊûúÊàë‰ª¨‰∏çÂÅöËøô‰∏™‰ºöÊÄéÊ†∑ÔºüÊòØË∞ÅÂÆö‰πâ‰∫ÜËøô‰∏™ÈóÆÈ¢òÔºü

ËøôÂê¨Ëµ∑Êù•ÊúâÁÇπÂì≤Â≠¶Ôºå‰ΩÜÊàëÂèëÁé∞ÔºåËÆæËÆ°È°πÁõÆÊãñÂª∂ÊàñÂ§±Ë¥•ÁöÑÊúÄÂ∏∏ËßÅÂéüÂõ†ÔºåÂ∞±ÊòØÈóÆÈ¢òÊú¨Ë∫´Ê≤°ÊêûÊ∏ÖÊ•ö„ÄÇ‰∫∫‰ª¨Êó†Ê≥ïÂú®Ëß£ÂÜ≥ÊñπÊ°à‰∏äËææÊàê‰∏ÄËá¥ÔºåÊòØÂõ†‰∏∫‰ªñ‰ª¨ËÑëÂ≠êÈáåÊÉ≥Ëß£ÂÜ≥ÁöÑÈóÆÈ¢òÊ†πÊú¨Â∞±‰∏çÊòØÂêå‰∏Ä‰∏™„ÄÇ‰∫éÊòØÔºåËß£ÂÜ≥ÊñπÊ°àÂèòÊàê‰∫ÜÈíàÂØπËÆ∏Â§ö‰∏çÂêåÈóÆÈ¢òÁöÑÂ¶•Âçè‰∫ßÁâ©ÔºåËÄå‰∏çÊòØÈíàÂØπ‰∏Ä‰∏™Ê†∏ÂøÉÈóÆÈ¢òÁöÑÂπ≤ÂáÄÂà©ËêΩÁöÑËß£Ê≥ï„ÄÇÂΩìÂà©ÁõäÁõ∏ÂÖ≥ËÄÖÔºàStakeholdersÔºâÂ§™Â§öÊó∂ÔºåËøôÁßçÊÉÖÂÜµ‰ºöÊõ¥Âä†ÊÅ∂Âåñ„ÄÇ

‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ºöÂÅö‰∏§‰ª∂‰∫ã„ÄÇÁ¨¨‰∏ÄÔºåÊåâÁÖßÊàëÁöÑÁêÜËß£ÊääÈóÆÈ¢òÂÜô‰∏ãÊù•ÔºåÂπ∂ËØ¢ÈóÆË∞ÅÊòØÂà©ÁõäÁõ∏ÂÖ≥ËÄÖ„ÄÇÁ¨¨‰∫åÔºåÂΩìÂêëËøô‰∫õÂà©ÁõäÁõ∏ÂÖ≥ËÄÖÂ±ïÁ§∫ÊñπÊ°àÊó∂ÔºåÊàë‰ºöÈáçÁî≥Ëøô‰∏™ÈóÆÈ¢òÔºåÁúãÁúãÊòØÂê¶‰ºöÂºïËµ∑ÂèçÂ∫î„ÄÇÂ¶ÇÊûúÊúâÂºÇËÆÆÔºåÊàë‰ºöÂÅú‰∏ãÊù•ÔºåÂÖàËÆ©ÂÖ®Â±ãÂ≠êÁöÑ‰∫∫Âú®‚ÄúÈóÆÈ¢ò‚Äù‰∏äËææÊàê‰∏ÄËá¥„ÄÇ‰Ω†ÂèØËÉΩ‰ºöÈóÆÔºåËøôË∑üËÆæËÆ°Êúâ‰ªÄ‰πàÂÖ≥Á≥ªÔºüËøôÂê¨Ëµ∑Êù•ÂæàÂÉèÂÖ¨Âè∏ÁÆ°ÁêÜÈÇ£‰∏ÄÂ•ó„ÄÇ

‰ΩÜ‰Ω†ÊÄªÊòØ‰ºöÊúâÂà©ÁõäÁõ∏ÂÖ≥ËÄÖÁöÑÔºåÂ¶ÇÊûú‰∏çÊòØÂêå‰∫ãÔºåÈÇ£Â∞±ÊòØÂÆ¢Êà∑„ÄÇ‰Ω†ÂøÖÈ°ªÊêûÊ∏ÖÊ•öÔºåÊî∂Âà∞ÁöÑÂèçÈ¶àÊòØÂõ†‰∏∫‰Ω†ÁöÑÊñπÊ°à‰∏çÂ§üÂ•ΩÔºåËøòÊòØÂõ†‰∏∫Â§ßÂÆ∂ÂØπ‚ÄúÈóÆÈ¢òÊòØ‰ªÄ‰πà‚ÄùÊ≤°ËææÊàêÂÖ±ËØÜ„ÄÇÊúâÊó∂ÂÄôÔºå‰Ω†ÊòØÂú®‰∏∫‰∏Ä‰∏™ÈîôËØØÁöÑÈóÆÈ¢òÂÅöËÆæËÆ°„ÄÇ‚ÄúÈóÆÈ¢ò‚ÄùÊòØÁ≠âÂºèÁöÑÁ¨¨‰∏ÄÈÉ®ÂàÜÔºåÂÆÉÊòØ‰Ω†ËÆæËÆ°ÂíåÊûÑÂª∫‰∏ÄÂàáÁöÑÂü∫Á°Ä„ÄÇ

Âú® LinearÔºåÊàë‰ª¨ÂæàÂø´Â∞±ÊÑèËØÜÂà∞ÂÖ¨Âè∏ÈúÄË¶Å‚ÄúÈ°πÁõÆ‚ÄùÔºàProjectsÔºâËøô‰∏™ÂäüËÉΩ„ÄÇË∑Ø‰π¶‰∏äÂÜôÁùÄ‚ÄúÊûÑÂª∫È°πÁõÆÂäüËÉΩ‚ÄùÔºåÊØè‰∏™‰∫∫ÈÉΩÂêåÊÑèËøôÊòØÂøÖÈ°ªÁöÑ„ÄÇ‰ΩÜÂ¶ÇÊûú‰Ω†ÂÜçÊ∑±ÊÉ≥‰∏ÄÂ±ÇÔºö‰∏∫‰ªÄ‰πàÂÖ¨Âè∏Ë¶ÅÈÄöËøá‚ÄúÈ°πÁõÆ‚ÄùÊù•ÁªÑÁªáÂ∑•‰ΩúÔºü‰∏∫‰ªÄ‰πà‰∏çÁõ¥Êé•ÂÅö‰∏Ä‰∏™Êé•‰∏Ä‰∏™ÁöÑ‰ªªÂä°ÔºüÂ¶ÇÊûú‰ªñ‰ª¨Ê≤°Êúâ‚ÄúÈ°πÁõÆ‚Äù‰ºöÂèëÁîü‰ªÄ‰πàÔºü

‰Ω†ÂèØ‰ª•Ê∑±ÂÖ•Á†îÁ©∂È°πÁõÆÁÆ°ÁêÜ„ÄÇËøôËÉåÂêéÊúâ‰∏ÄÊï¥Â•óÂ≠¶ÁßëÔºå‰ª•ÂèäÂêÑÁßçÂêÑÊ†∑ÁöÑÊñπÊ≥ïËÆ∫„ÄÇ‰ΩÜÂ¶ÇÊûú‰Ω†ÁöÑÊÑøÊôØÊòØ‰∏∫ËΩØ‰ª∂ÂÖ¨Âè∏ÊûÑÂª∫‰∏Ä‰∏™‰∏ìÁî®Â∑•ÂÖ∑Ôºå‰Ω†Â∞±ÂæóÂºÄÂßãÂÅöÂáèÊ≥ï„ÄÇ‰ªñ‰ª¨ÁúüÊ≠£ÂÖ≥ÂøÉÁöÑÊòØ‰ªÄ‰πàÔºü

ÁÆÄÂçïÊù•ËØ¥Ôºå‚ÄúÈ°πÁõÆ‚ÄùÊòØÂÖ¨Âè∏ÁÆ°ÁêÜÂ∑•‰ΩúÊµÅÁöÑ‰∏ÄÁßçËá™ÁÑ∂**ÊäΩË±°** **ÔºàAbstractionÔºåÊåáÂú®ËΩØ‰ª∂Â∑•Á®ã‰∏≠Â∞ÜÂ§çÊùÇÁ≥ªÁªüÁÆÄÂåñ‰∏∫Êõ¥ÊòìÁÆ°ÁêÜÁöÑÊ¶ÇÂøµÔºâ**„ÄÇÂÆÉ‰ª¨ÊúâÂä©‰∫éÊùÉË¥£ÂàÜÊòé„ÄÅÂΩíÂ±ûÊÑü„ÄÅË∑®Âõ¢ÈòüÂçè‰Ωú„ÄÅÂèØÈ¢ÑÊµãÊÄßÂíåÂèØËßÅÊÄß„ÄÇ

Áé∞Âú®‰Ω†ÂèØËÉΩ‰ºöÈóÆÔºå‰∏∫‰ªÄ‰πàË¶ÅÁ†îÁ©∂Ëøô‰πàÂü∫Á°ÄÊàñ‰ºóÊâÄÂë®Áü•ÁöÑ‰∏úË•øÔºüÊúâÊó∂ÂÄô‰Ω†Á°ÆÂÆû‰∏çÈúÄË¶Å„ÄÇ‰ΩÜ‰∫ÜËß£Êï¥‰∏™ÁâàÂõæÂíåÂéÜÂè≤ËÉΩÁªô‰Ω†ÂÆö‰Ωç„ÄÇ‰Ω†‰ºöÂèëÁé∞Âì™‰∫õÂÅáËÆæÊòØÂèØ‰ª•ÊåëÊàòÁöÑÔºåÊàñËÄÖÂÜ≥ÂÆöÈÅµÂæ™Âì™‰∫õ‰º†Áªü„ÄÇ

ÊúÄÈáçË¶ÅÁöÑÊòØÔºåÂÖàÊêûÊáÇÈóÆÈ¢òÊúâÂä©‰∫é‰Ω†ÂÜ≥ÂÆöË¶ÅÊÄé‰πàÂ§ÑÁêÜÂÆÉ„ÄÇ‰∫ßÂìÅÊÑøÊôØÊää‰Ω†ÊãâÂêëÂì™‰∏™ÊñπÂêëÔºü‰Ω†ÊÉ≥‰ºòÂåñÂíåÂΩ±Âìç‰ªÄ‰πàÔºü

Âú® LinearÔºåÊàë‰ª¨Ë¶Å‰πà‰∏çÂÅöÔºåË¶ÅÂÅöÂ∞±ÂèëÁé∞‚ÄúÈ°πÁõÆ‚ÄùÂèØËÉΩÊòØÊúÄÈáçË¶ÅÁöÑÂ∑•‰ΩúÂçï‰Ωç„ÄÇ‰∫ßÂìÅÊòØÁî±È°πÁõÆÁªÑÊàêÁöÑÔºåÁªÑÁªáÊòØÂõ¥ÁªïÈ°πÁõÆËøêËΩ¨ÁöÑÔºåÂΩì‰∏Ä‰∏™È°πÁõÆÂèëÂ∏ÉÊó∂Ôºå‰Ω†‰ª¨‰ºöÂ∫ÜÁ•ù„ÄÇËøôÁßçÁêÜËß£‰∏∫Êàë‰ª¨ËØïÂõæËß£ÂÜ≥ÁöÑÈóÆÈ¢òÊåáÊòé‰∫ÜÊñπÂêë„ÄÇ

ÊàëÊääËÆæËÆ°Ëß£ÂÜ≥ÊñπÊ°àÁöÑËøáÁ®ãÂàÜ‰∏∫‰∏§‰∏™Èò∂ÊÆµÔºö**Ê¶ÇÂøµÈò∂ÊÆµ**ÔºàThe conceptual stageÔºâÂíå **ÊâßË°åÈò∂ÊÆµ**ÔºàThe execution stageÔºâ„ÄÇ

* **Ê¶ÇÂøµÈò∂ÊÆµ** ÊòØÂØªÊâæËÆæËÆ°Â∞ÜÂëàÁé∞ÁöÑÊï¥‰ΩìÂΩ¢ÊÄÅ„ÄÇ
* **ÊâßË°åÈò∂ÊÆµ** ÊòØÂ∞ÜÂÖ∂ÊûÑÂª∫Âá∫Êù•Âπ∂ÂëàÁé∞Âú®Â±èÂπï‰∏ä„ÄÇ

‰ª•ÈóÆÈ¢òËøΩË∏™Â∑•ÂÖ∑‰∏≠ÁöÑ‚ÄúÈ°πÁõÆ‚Äù‰∏∫‰æãÔºå‰Ω†ÂèØ‰ª•ÊääÂÆÉÂ§ÑÁêÜÊàê‰∏Ä‰∏™Â∏¶ÊúâÂ≠êÈóÆÈ¢òÁöÑÂ§ßÂè∑ÈóÆÈ¢òÔºàIssueÔºâÔºåÊàñËÄÖ‰∏Ä‰∏™Êñá‰ª∂Â§π/Ê†áÁ≠æÔºåÊàñËÄÖ‰∏Ä‰∏™ËøûÊé•Âà∞ÈóÆÈ¢òÁöÑÁã¨Á´ãÂÆû‰Ωì„ÄÇËøô‰∫õÈÉΩÊòØ‰Ω†‰∏çÈúÄË¶ÅÂú®Â±èÂπï‰∏äÁîª‰ªª‰Ωï‰∏úË•øÂ∞±ÂèØ‰ª•ÊÄùËÄÉÁöÑÊ¶ÇÂøµÊÄßÊÉ≥Ê≥ï„ÄÇÂÜ≥Á≠ñÂèñÂÜ≥‰∫é‰Ω†ÂØπÁî®Êà∑„ÄÅÂÖ¨Âè∏Âíå‰Ω†ÊÉ≥Ë¶ÅËææÂà∞ÁöÑÊÑøÊôØÁöÑÁêÜËß£„ÄÇÊâÄÊúâËøô‰∫õÊ¶ÇÂøµÈÉΩË°åÂæóÈÄöÔºå‰Ω†ÂèØ‰ª•Âú®Áé∞ÂÆû‰∫ßÂìÅ‰∏≠ÊâæÂà∞ÂÆÉ‰ª¨ÁöÑÂΩ±Â≠ê„ÄÇ

Âõ†‰∏∫Êàë‰ª¨ËÆ§‰∏∫‚ÄúÈ°πÁõÆ‚ÄùÂæàÈáçË¶ÅÔºå‰∏î‰∏çÂêå‰∫é‚ÄúÈóÆÈ¢ò‚ÄùÔºåÊâÄ‰ª•ÂÆÉ‰ª¨ÈúÄË¶ÅÊàê‰∏∫‰∏Ä‰∏™Áã¨Á´ãÁöÑÂÆû‰ΩìÔºåÊã•ÊúâËá™Â∑±ÁöÑÂΩ¢Áä∂„ÄÇ‰∏Ä‰∏™È°πÁõÆÂ∫îËØ•ÊúâÂèØËØÜÂà´ÁöÑÂΩ¢ÂºèÂíåÂäüËÉΩÔºåËÉΩÂ§ü‰º†ËææÁä∂ÊÄÅ„ÄÅÁêÜÁî±„ÄÅÁî®Êà∑ÂèçÈ¶à„ÄÅ‰ºòÂÖàÁ∫ß„ÄÅÊó∂Èó¥ÂÆâÊéíÔºå‰ª•Âèä‰∏éÊõ¥Â§ßËÆ°ÂàíÁöÑËÅîÁ≥ª„ÄÇÊää‚ÄúÈ°πÁõÆ‚ÄùÈôçÁ∫ß‰∏∫‰∏Ä‰∏™Ê†áÁ≠æÊàñ‰∏ÄÂ†ÜÊùæÊï£ÁöÑÈóÆÈ¢òÈõÜÂêàÔºåÊÑüËßâÊòØ‰∏çÂØπÁöÑ„ÄÇ

Ëøô‰∏™Ê¶ÇÂøµÈò∂ÊÆµÂèØ‰ª•Áî®ÊñáÂ≠ó„ÄÅÁ∫∏Á¨î„ÄÅËÆæËÆ°Â∑•ÂÖ∑Êàñ‰ª£Á†ÅÊù•ÂÆåÊàê„ÄÇÂÖ≥ÈîÆÂú®‰∫éËµã‰∫àËøô‰∫õÊÉ≥Ê≥ï‰∏Ä‰∏™ÂΩ¢Áä∂ÔºåÂ∞ùËØï‰∏çÂêåÁöÑÊñπÂêëÔºåÊúÄÁªàÈÄâÊã©ÈÇ£‰∏™ÊúÄËÉΩÊúçÂä°‰∫éÈóÆÈ¢òÂíå‰∫ßÂìÅÊÑøÊôØÁöÑÊñπÂêë„ÄÇ

‰∏ÄÊó¶ÊàëÊúâ‰∫Ü‰∏Ä‰∏™ÊàëÁõ∏‰ø°ÁöÑÊñπÂêëÔºåÂ∞±ÂáÜÂ§áÂ•ΩÊé•ÂèóÊõ¥ÂπøÊ≥õÁöÑÂèçÈ¶à‰∫Ü„ÄÇ‰Ω†‰ºöÈÄöËøáÊûÑÂª∫ÂÆÉÊù•ÊµãËØïËøô‰∏™Ê¶ÇÂøµ„ÄÇ

ËøôÊòØÊúÄÊé•ËøëÊúÄÁªà‰∫ßÂá∫ÁöÑÈÉ®ÂàÜ„ÄÇ‰Ω†ËÆ©ËÆæËÆ°Ê¶ÇÂøµÁúüÊ≠£Ë∑ëËµ∑Êù•ÔºåÊääÂÆÉÂ°ëÈÄ†ÊàêÁúüÂÆûÁöÑ‰∏úË•ø„ÄÇ‰ª£Á†ÅÔºåÊàñËÄÖËØ¥‰∏é‚ÄúÊùêÊñô‚ÄùÁõ¥Êé•Êâì‰∫§ÈÅìÔºåÂú®Ëøô‰∏ÄÊ≠•Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÊúâ‰∫õÊó∂ÂÄôÔºå‰Ω†‰ºöËé∑ÂæóÊñ∞ÁöÑÊ¥ûÂØüÔºå‰∏çÂæó‰∏çÂõûËøáÂ§¥ÂéªÈáçÊñ∞ÂÆ°ËßÜÈóÆÈ¢òÊàñÊ¶ÇÂøµ„ÄÇ

Âú®Ëøô‰∏™Èò∂ÊÆµ‰ΩøÁî®‰ª£Á†ÅÊúâ‰∏çÂêåÁöÑÊñπÂºè„ÄÇ‰Ω†ÂèØ‰ª•ÊûÑÂª∫Â∑•ÂÖ∑ÔºåÊàñËÄÖÁî®‚ÄúÁî®ÂÆåÂç≥ÂºÉÁöÑ‰ª£Á†Å‚ÄùÔºàthrowaway codeÔºâËøõË°å‚ÄúËçâÁªò‚Äù„ÄÇËøôÊ∂àÈô§‰∫Ü‰∏Ä‰∫õÁîü‰∫ßÁéØÂ¢É‰ª£Á†ÅÁöÑÈôêÂà∂Ôºå‰ΩøËøáÁ®ãÊõ¥ÂÖ∑Êé¢Á¥¢ÊÄß„ÄÇÊàëÊÉ≥ËØ¥ÁöÑÊòØÔºåËôΩÁÑ∂‰Ω†ÂèØËÉΩËÆ§‰∏∫ÊâßË°åÈò∂ÊÆµÊâçÊòØËÆæËÆ°ÁöÑ‚ÄúÊú¨‰Ωì‚ÄùÔºå‰ΩÜÂÖ∂ÂÆû‰Ω†Â∑≤ÁªèÂª∫Á´ã‰∫Ü‰∏Ä‰∏™ÂåÖÂê´‰∏ä‰∏ãÊñáÂíå‰ø°ÂøÉÁöÑÂü∫Á°Ä„ÄÇÂΩì‚ÄúÊùêÊñô‚ÄùÂºÄÂßãÂèçÂáªÊó∂ÔºàÊÑèÊåáÂú®ÁºñÁ†ÅËøáÁ®ã‰∏≠ÈÅáÂà∞Áé∞ÂÆûÁöÑÈôêÂà∂ÊàñÂõ∞ÈöæÔºâÔºå‰Ω†ÊòØÂ∏¶ÁùÄÈÇ£‰ªΩ‰ø°ÂøÉÂú®Êé®ËøõÁöÑ„ÄÇ

**Êàë‰ª¨ÂèØ‰ª•Áî®Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÈÄªËæëÊù•Á±ªÊØîÔºö**

‰Ω†‰πãÂâçÂÅöÁöÑÊâÄÊúâËÆæËÆ°Â∑•‰ΩúÔºàÁêÜËß£ÈóÆÈ¢ò„ÄÅÁ°ÆÂÆöÊ¶ÇÂøµÔºâÔºåÂ∞±ÂÉèÊòØ‰Ω†‰∏∫‰∫ÜËÆ© **AI Êô∫ËÉΩ‰ΩìÔºàAI AgentÔºâ** Ëß£ÂÜ≥ÈóÆÈ¢òËÄåÊûÑÂª∫ÁöÑ **ÁõÆÊ†áÔºàGoalÔºâ„ÄÅ‰∏ä‰∏ãÊñáÔºàContextÔºâÂíåÊèêÁ§∫ËØçÔºàPromptÔºâ**„ÄÇËÄåÊâßË°åÂ∑•‰ΩúÔºåÂàôÊòØ‰Ω†Âú®ÂºïÂØºÊô∫ËÉΩ‰ΩìÂÅöÂá∫‰∏Ä‰∏™‰∏™ÂÖ∑‰ΩìÁöÑÂÜ≥ÂÆö„ÄÇ

ËØªÂÆåËøô‰∫õÔºå‰Ω†ÂèØËÉΩ‰ºöÊÉ≥ÔºöË∞ÅÊúâÊó∂Èó¥ÊêûËøô‰∫õÔºüÊàë‰ª¨ÈúÄË¶ÅÂèëÂ∏É‰∫ßÂìÅÂïäÔºÅ‰∏∫‰ªÄ‰πà‰∏çÁõ¥Êé•ÂºÄÂπ≤ÔºåËæπÂÅöËæπÊÉ≥ÔºüÊàë‰∏çËÆ§‰∏∫ËøôÊòØÊó∂Èó¥ÈóÆÈ¢ò„ÄÇÊàëÁöÑËß£ÈáäÂèØËÉΩÂæàÈïøÔºå‰ΩÜËøô‰∏™ËøáÁ®ãÊú¨Ë∫´ÂèØ‰ª•ÂæàÂø´„ÄÇ‰Ω†Âè™ÊòØËä±‰∫ÜÂøÖË¶ÅÁöÑÊó∂Èó¥ËÄåÂ∑≤„ÄÇ

ÊàëÁöÑÊÑüËßâÊòØÔºåÂ¶ÇÊûúÊ≤°ÊúâÂÜÖÁΩÆÈÇ£‰∫õ‰∏ä‰∏ãÊñáÂíåÁõÆÊ†áÔºå‰Ω†ÂèØËÉΩÁ°ÆÂÆûÂú®ÊúùÁùÄÊüê‰∏™ÊñπÂêëËø≠‰ª£Ôºå‰ΩÜÈÇ£‰∏çÊòØ‰∏Ä‰∏™ÁªèËøáÊ∑±ÊÄùÁÜüËôëÂêéÈÄâÊã©ÁöÑÊñπÂêë„ÄÇ

ËøôËÆ©ÊàëÂõûÂà∞‰∫ÜÊñáÁ´†ÂºÄÂ§¥„ÄÇÊàë‰ª¨ÁöÑË°å‰∏öÈùûÂ∏∏Áº∫‰πèËÄêÂøÉÔºå‰∏ÄÊó¶‰Ω†ÂºÄÂßãÈªòËÆ§Áõ¥Êé•ÊääËÆæËÆ°ÊûÑÂª∫Âà∞Áîü‰∫ßÁéØÂ¢É‰∏≠ÔºåÈÇ£‰∫õÂéªÊÄùËÄÉÈóÆÈ¢ò„ÄÅÊ¶ÇÂøµÂíåÊÑèÂõæÁöÑÊñáÂåñ‰∏éÁªÑÁªáÁêÜÁî±Â∞±ÂºÄÂßãËí∏Âèë‰∫Ü„ÄÇÊàë‰ª¨ÂºÄÂßã‰∏∫‰∫Ü‰∫ßÂá∫ËÄåË¥¨‰ΩéËÆæËÆ°ËÉåÂêéÁöÑ‚Äú‰∏∫‰ªÄ‰πà‚Äù„ÄÇ

ÊàëÊãÖÂøÉÁöÑ‰∏çÊòØ‰ª£Á†ÅÊàñÂ∑•ÂÖ∑Êú¨Ë∫´„ÄÇÊàëÊãÖÂøÉÁöÑÊòØÊ∑±ÊÄùÁÜüËôëÔºàConsiderationÔºâÁöÑË°∞ÈÄÄÔºåÈöè‰πãËÄåÊù•ÁöÑÊòØÁã¨Áâπ„ÄÅËÆæËÆ°Á≤æËâØÁöÑ‰∫ßÂìÅÁöÑË°∞ÈÄÄ„ÄÇÈóÆÈ¢òÂú®‰∫éÔºåÈöèÁùÄÊñ∞Â∑•ÂÖ∑ÂíåÊäÄÊúØÁöÑÂá∫Áé∞ÔºåÊàë‰ª¨Â¶Ç‰Ωï‰øùÊåÅËøô‰ªΩÂå†ÂøÉÔºü

ÂØπÊàëÊù•ËØ¥ÔºåËÆæËÆ°‰ªéÊù•‰∏çÊòØÂÖ≥‰∫éÊåâÈíÆÈïø‰ªÄ‰πàÊ†∑ÊàñÂÆÉÊòØÂπ≤ÂòõÁöÑÔºå‰πü‰∏çÊòØÂÖ≥‰∫é‰Ω†Áî®‰ªÄ‰πàÂ™í‰ªãÂ∑•‰Ωú„ÄÇÂÆÉËøáÂéªÊòØÔºåÁé∞Âú®‰æùÁÑ∂ÊòØ‚Äî‚Äî**ÊâæÂà∞Ê≠£Á°ÆÁöÑÈóÆÈ¢ò„ÄÅÊ≠£Á°ÆÁöÑÊÑèÂõæ„ÄÅÊ≠£Á°ÆÁöÑÊÑøÊôØ„ÄÇ** ‰Ω†‰ªäÂ§©ËÆæËÆ°ÂíåÊûÑÂª∫ÁöÑÂäüËÉΩÔºåÂ∫îËØ•ÊòØÈÄöÂæÄÈÇ£‰∏™ÊÑøÊôØÁöÑ„ÄÅÁªèËøáÊ∑±ÊÄùÁÜüËôëÁöÑ‰∏ÄÊ≠•„ÄÇ

**ÊÑüË∞¢ Charlie Aufmann, Tuhin Kumar, Ramon Marc, Conor Muirhead, Gavin Nelson, Raphael Schaad, Jeff Smith, Âíå Soleio ÂØπÊú¨ËØùÈ¢òÁöÑËØÑËÆ∫ÂíåËÆ®ËÆ∫„ÄÇ**

Karri Saarinen

Êù•Ê∫ê: <https://linear.app/now/design-is-more-than-code>

hidden text to trigger resize events if fonts change