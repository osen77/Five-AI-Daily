# [äº”æ¡0105] AIé‡å¡‘UXï¼š2026å¹´åå¤§è®¾è®¡è¶‹åŠ¿
å‘å¸ƒæ—¥æœŸï¼š2025/12/29

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/N1TFJ8KaveP0iabzwOrYNamQ2ibpgeKmfM3Hxwy4Dh1w1fPHRUlu9UKVy0rIekPibvmn9WibiaictBzC92kwbVcLVK6w/640?wx_fmt=jpeg&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1)

ç«™åœ¨ 2025 å¹´æœ«ï¼Œåˆæ˜¯å¹´åº•äº†ã€‚æ¯åˆ°è¿™ä¸ªæ—¶å€™ï¼Œæ€»ä¹ æƒ¯åœä¸‹æ¥ï¼Œå›å¤´çœ‹çœ‹èµ°è¿‡çš„è·¯ï¼Œå†è¸®èµ·è„šå°–æœ›æœ›å‰é¢ã€‚

è¿‡å»çš„ä¸€å¹´é‡Œ AI åˆåŠ é€Ÿäº†è¡Œä¸šçš„å˜åŒ–ï¼Œå¿«åˆ°è®©äººè§‰å¾—æœ‰ç‚¹è¿½èµ¶ä¸ä¸Šã€‚ä½†æˆ–è®¸æ­£æ˜¯è¿™ç§â€œæœªçŸ¥â€ï¼Œæ‰è®©æˆ‘ä»¬å¯¹æ–°çš„ä¸€å¹´æ€»æ˜¯å……æ»¡å¥½å¥‡ã€‚2026 å¹´ä¼šæ˜¯ä»€ä¹ˆæ ·ï¼Ÿåœ¨è¿™ä¸ªæ–°æ—§äº¤æ›¿çš„æ—¶é—´èŠ‚ç‚¹ï¼Œæˆ‘ä»¬æ•´ç†ä¸€äº›å¯¹è¡Œä¸šè¶‹åŠ¿å‘å±•çš„è§‚ç‚¹ï¼Œä¸€èµ·ä¸ä½ åˆ†äº«ï¼Œå±•æœ›æ–°çš„ä¸€å¹´ã€‚

## **è¶‹åŠ¿01**

## **AI ä»è¾…åŠ©å·¥å…·åˆ°è®¾è®¡æ­æ¡£**

AI å°†æˆä¸ºè®¾è®¡å¸ˆçš„å…¨èŒæ­æ¡£ï¼Œè€Œä¸åªæ˜¯è¾…åŠ©å·¥å…·ã€‚åˆ° 2026 å¹´ï¼Œå„ç±» AI é©±åŠ¨çš„è®¾è®¡å·¥å…·ï¼ˆå¦‚Geminiã€ Galileo AIã€Figma ç­‰ï¼‰èƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆé¡µé¢å¸ƒå±€ã€é…è‰²æ–¹æ¡ˆç”šè‡³å“ç‰Œç³»ç»Ÿï¼Œè®©è®¾è®¡å¸ˆä»ç¹ççš„åƒç´ è°ƒæ•´ä¸­è§£æ”¾å‡ºæ¥ï¼Œé›†ä¸­ç²¾åŠ›æ‰“é€ åˆ›æ„ã€‚AI å¸®åŠ©å¿«é€Ÿäº§å‡ºå¤šç§è®¾è®¡æ–¹æ¡ˆï¼Œç¼©çŸ­è¿­ä»£å‘¨æœŸï¼Œä½†æœ€ç»ˆçš„å®¡ç¾ã€å¯ç”¨æ€§å’Œå“ç‰Œå†…æ¶µä»éœ€ç”±è®¾è®¡å¸ˆæŠŠå…³ï¼Œè®¾è®¡å†³ç­–åŠ›å˜å¾—æ›´ä¸ºé‡è¦ã€‚

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4UdyuPjxuswPiapgGJyGdMcEl0oDqLxMibFE383xvSPbGzSYrOpkj4dSQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1)

Gemini ç”Ÿæˆ web UI æ¡ˆä¾‹

å°† AI å½“ä½œâ€œå®ä¹ ç”Ÿâ€ä½¿ç”¨ï¼Œå–„ç”¨æç¤ºè¯å¼•å¯¼ AI ç”Ÿæˆåˆç‰ˆç•Œé¢ï¼Œå†ç”±è®¾è®¡å¸ˆè¿›è¡Œæ¶¦è‰²å’Œä¼˜åŒ– ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨ AI å¿«é€Ÿæ‰“ç£¨å¤šå¥—æ–¹å‘ï¼Œç„¶åç­›é€‰æœ€ä½³æ–¹æ¡ˆï¼Œç”±è®¾è®¡å¸ˆè¿›è¡Œå®šè°ƒå’Œç»†èŠ‚å®Œå–„ã€‚è®¾è®¡å¸ˆçš„ä»·å€¼æ›´å¤šä½“ç°åœ¨åˆ›æ„å¼•å¯¼å’Œç”¨æˆ·ç†è§£ï¼Œè€Œéé‡å¤æ€§åŠ³åŠ¨ã€‚

è¶‹åŠ¿02

ç”Ÿæˆå¼UIï¼ˆ**Generative UI**ï¼‰äº¤äº’ä½“éªŒ

æˆ‘ä»¬å½“å‰è¿˜å¤„åœ¨â€œåŠ¨æ€å†…å®¹ï¼Œé™æ€å®¹å™¨â€çš„é˜¶æ®µï¼Œ2026å¹´å¯èƒ½è¶Šè¿‡äº†ä¸´ç•Œç‚¹ã€‚ä¼ ç»Ÿçš„â€œé™æ€ç”¨æˆ·ç•Œé¢â€æ¦‚å¿µâ€”â€”å³æ‰€æœ‰ç”¨æˆ·çœ‹åˆ°ç›¸åŒå¸ƒå±€ã€ç›¸åŒç»„ä»¶çš„é¢„è®¾ç•Œé¢â€”â€”å°†è¢«è§†ä¸ºä¸€ç§è¿‡æ—¶çš„é—ç•™æ¨¡å¼ã€‚ç”Ÿæˆå¼UIï¼ˆGenerative UIï¼Œç®€ç§°GenUIï¼‰ä¸ä¼ ç»Ÿçš„ä¸ªæ€§åŒ–ä¸åŒï¼ŒGenUIåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œå®æ—¶æ¸²æŸ“å¼•æ“ï¼Œæ ¹æ®ç”¨æˆ·çš„å³æ—¶æ„å›¾ã€ä¸Šä¸‹æ–‡ç¯å¢ƒåŠå†å²è¡Œä¸ºï¼Œåœ¨æ¯«ç§’çº§æ—¶é—´å†…â€œå‡­ç©ºâ€æ„å»ºå‡ºç‹¬ä¸€æ— äºŒçš„ç•Œé¢ã€‚

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4odhMp9nNMOQvjzaOgWOT1gQjMYqMqQ9YdJkeXvxxMzXzn3EkQbm6IA/640?wx_fmt=png&from=appmsg#imgIndex=2)

Rabbit é€šè¿‡Promptå®šä¹‰ä¸»é¢˜

è¿™ç§è½¬å˜æ„å‘³ç€â€œç•Œé¢â€ä¸å†æ˜¯ä¸€ä¸ªå›ºå®šçš„äº§å“ï¼Œè€Œæ˜¯ä¸€ç§ç¬æ—¶çš„æœåŠ¡ã€‚ä¾‹å¦‚ï¼Œå½“ç”¨æˆ·åœ¨é“¶è¡Œåº”ç”¨ä¸­æŸ¥è¯¢å¤æ‚çš„æŠµæŠ¼è´·æ¬¾æ—¶ï¼Œç³»ç»Ÿä¸ä¼šå±•ç¤ºä¸€ä¸ªé€šç”¨çš„ä»ªè¡¨ç›˜ï¼Œè€Œæ˜¯æ ¹æ®ç”¨æˆ·çš„è´¢åŠ¡ç´ å…»æ°´å¹³ã€å½“å‰çš„å…³æ³¨ç‚¹ï¼ˆå¦‚åˆ©ç‡è¿˜æ˜¯æœˆä¾›ï¼‰ï¼Œå®æ—¶ç”Ÿæˆäº¤äº’å¼çš„å¯è§†åŒ–å›¾è¡¨ã€æ»‘å—å·¥å…·åŠè§£é‡Šæ€§æ–‡æœ¬ã€‚åŒæ—¶ä¸¥é˜²â€œUIå¹»è§‰â€ï¼ˆå³ç”Ÿæˆäº†åå°ä¸æ”¯æŒçš„åŠŸèƒ½æŒ‰é’®ï¼‰ã€‚

è¶‹åŠ¿03

å¤šæ¨¡æ€äº¤äº’ä¸é›¶ç•Œé¢ä½“éªŒ

è¯­éŸ³ã€æ‰‹åŠ¿ã€è§¦è§‰åé¦ˆç­‰å¤šç§äº¤äº’æ–¹å¼å°†æˆä¸ºæ–°å¸¸æ€ï¼Œå±å¹•ç•Œé¢ä¸å†æ˜¯å”¯ä¸€å…¥å£ã€‚æœªæ¥çš„ç•Œé¢è®¾è®¡ä¾§é‡äºâ€œæ— ç•Œé¢â€ä½“éªŒï¼šè®¾å¤‡èƒ½é€šè¿‡å£°éŸ³ã€ä¼ æ„Ÿå™¨å’Œç¯å¢ƒæ„ŸçŸ¥ç”¨æˆ·éœ€æ±‚ï¼Œåœ¨æ— éœ€è§†è§‰ç•Œé¢çš„æƒ…å†µä¸‹å®Œæˆä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œæ™ºèƒ½å†°ç®±èƒ½è‡ªåŠ¨è¯†åˆ«ç‰›å¥¶åº“å­˜å¹¶ä¸‹å•ï¼›è½¦è¾†å‡­äººè„¸è¯†åˆ«è°ƒèŠ‚åº§æ¤…å’Œé•œåƒï¼›ç”šè‡³å¯ç©¿æˆ´è®¾å¤‡åœ¨ç”¨æˆ·â€œæƒ³åˆ°â€æ—¶ä¸»åŠ¨æ˜¾ç¤ºä¿¡æ¯ ã€‚è¿™ç§è®¾è®¡è®©ä½“éªŒæ›´åŠ ç›´è§‰ã€è‡ªç„¶ï¼Œä½†åŒæ—¶é¡»é¡¾åŠéšç§å’Œç”¨æˆ·æ§åˆ¶æƒã€‚

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4I8AiaT3FrBkuRicia1yw1icicMgfBr2EWFllGiad4wu6svmooKu2n3B0DlSw/640?wx_fmt=png&from=appmsg#imgIndex=3)

Rokid å®˜ç½‘ç´ æ

â€œæ— ç•Œé¢â€å¹¶éå®Œå…¨å»å±å¹•ï¼Œè€Œæ˜¯è®¾è®¡æ—¶å……åˆ†è€ƒè™‘è¯­éŸ³ã€è§¦è§‰å’Œç¯å¢ƒåé¦ˆã€‚ä¾‹å¦‚ï¼ŒRokidå¹¶æ²¡æœ‰å®Œå…¨ä¾èµ–ç©ºä¸­å¤æ‚çš„æ‰‹åŠ¿è¿½è¸ªï¼ˆè¿™åœ¨ç¤¾äº¤åœºåˆå¾€å¾€æ˜¾å¾—å°´å°¬ï¼‰ï¼Œè€Œæ˜¯å°†å®æ—¶è¯­è¨€ç¿»è¯‘å’Œç‰©ä½“è¯†åˆ«ç›´æ¥é›†æˆåˆ°ç”¨æˆ·çš„è§†é‡ä¸­ã€‚

è¶‹åŠ¿04

ä»£ç†å¼ä½“éªŒ

æƒ³è±¡ä¸€ä¸‹ï¼Œå½“ä½ æƒ³è¦åˆ¶å®šæ—…è¡Œè®¡åˆ’æ—¶ï¼Œä¸å†éœ€è¦åˆ†åˆ«æ‰“å¼€è®¢ç¥¨è½¯ä»¶ã€é…’åº—APPå’Œæ”»ç•¥ç½‘ç«™ã€‚åœ¨**ä»£ç†å¼ä½“éªŒ**çš„é€»è¾‘ä¸‹ï¼Œä½ åªéœ€è¡¨è¾¾â€œæˆ‘æƒ³å»åº¦å‡â€ï¼Œç³»ç»Ÿå°±ä¼šåƒä¸€ä½è€ç»ƒçš„ç®¡å®¶ï¼Œç†è§£ä½ çš„åå¥½ï¼Œåœ¨åå°é»˜é»˜è°ƒåŠ¨èµ„æºï¼Œç›´æ¥æŠŠè¡Œç¨‹å•æ”¾åœ¨ä½ é¢å‰ã€‚

è¿™ç§ä½“éªŒçš„å…³é”®è½¬å˜åœ¨äºï¼š**ç³»ç»Ÿä»â€œç­‰ä½ æ€ä¹ˆåšâ€å˜æˆäº†â€œæ‡‚ä½ è¦ä»€ä¹ˆâ€ï¼Œç›¸ä¿¡å¤§å®¶é€šè¿‡è±†åŒ…æ‰‹æœºåŠ©æ‰‹å¯ä»¥æ„Ÿå—åˆ°äº†ã€‚**

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4DpF9vB0uR4ASsq7sDTKZAaLmgESHDOkUvVLx7VK9AtLMKr9mqNMY9g/640?wx_fmt=png&from=appmsg#imgIndex=4)

è±†åŒ…æ‰‹æœºåŠ©æ‰‹

ä½†è¿™å¸¦æ¥äº†ä¸€ä¸ªæ–°çš„æŒ‘æˆ˜ï¼š**ä¿¡ä»»**ã€‚å°±åƒé›‡ä½£æ–°ç®¡å®¶ä¸€æ ·ï¼Œç”¨æˆ·ä¼šæ€€ç–‘ï¼šâ€œä½ ä¸ºä»€ä¹ˆé€‰è¿™ä¸ªèˆªç­ï¼Ÿä½ æ˜¯ä¸æ˜¯æ›¿æˆ‘åšäº†é”™è¯¯çš„å†³å®šï¼Ÿâ€ å› æ­¤ï¼Œæœªæ¥çš„UI/UXè®¾è®¡ï¼ˆå°¤å…¶æ˜¯å±•æœ›2026å¹´ï¼‰ï¼Œå…¶ä¸»æˆ˜åœºå°†æ˜¯**å®šä¹‰äººæœºåä½œçš„è¾¹ç•Œ**â€”â€”æ—¢è¦äº«å—è‡ªåŠ¨é©¾é©¶èˆ¬çš„ä¾¿åˆ©ï¼Œåˆè¦ç¡®ä¿ç”¨æˆ·æ‰‹ä¸­å§‹ç»ˆæ¡æœ‰æ–¹å‘ç›˜ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°å®‰å…¨ä¸æŒæ§ã€‚

è¶‹åŠ¿05

è¶…ä¸ªæ€§åŒ–ä½“éªŒ

ç”¨æˆ·æœŸæœ›äº§å“èƒ½å¤Ÿé¢„è§ä»–ä»¬çš„éœ€æ±‚ï¼Œè€Œéåƒäººä¸€é¢ ã€‚éšç€ç”Ÿæˆå¼UIçš„è½åœ°ï¼Œ2026å¹´çš„ UI/UX å€¾å‘äº**åŠ¨æ€ä¸ªæ€§åŒ–**ï¼šç•Œé¢æ ¹æ®ç”¨æˆ·åå¥½ã€ä½¿ç”¨ä¹ æƒ¯å’Œåœºæ™¯è‡ªåŠ¨è°ƒæ•´ã€‚ä¾‹å¦‚ï¼Œæ ¹æ®ç”¨æˆ·ä½¿ç”¨æ—¶é•¿ç®€åŒ–ç•Œé¢ï¼Œæˆ–ä¸ºæ–°æ‰‹å’Œèµ„æ·±ç”¨æˆ·æä¾›ä¸åŒçš„å¼•å¯¼æµç¨‹ ã€‚åŒæ—¶ä¿æŒå¯¹éšç§å’Œé€æ˜åº¦çš„å°Šé‡ï¼Œåªåœ¨ç”¨æˆ·æ„¿æ„çš„å‰æä¸‹é‡‡é›†å’Œåˆ©ç”¨æ•°æ®ã€‚ä¸ªæ€§åŒ–åº”å½“è®©ä½“éªŒæ›´è´´å¿ƒï¼Œè€Œéä»¤äººä¸é€‚ã€‚

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4g9OdiahXGvOAtAP6SjouS5IsBDVQSvsicSFDB8vZ4dfibURnXQLQGK6Hw/640?wx_fmt=png&from=appmsg#imgIndex=5)

æ¥æºå°¼å°”æ£®

æ”¶é›†ç”¨æˆ·æ•°æ®æ—¶éµå®ˆä¼¦ç†å‡†åˆ™ï¼Œè®©ç”¨æˆ·å¯¹ä¸ªæ€§åŒ–åŠŸèƒ½æ‹¥æœ‰å¯æ§æƒã€‚ä¾‹å¦‚ï¼Œæä¾›å¯è°ƒèŠ‚çš„ä¸ªæ€§åŒ–è®¾ç½®ï¼Œè®©ç”¨æˆ·è‡ªè¡Œé€‰æ‹©æ˜¯å¦å¯ç”¨å„ç§è‡ªåŠ¨åŒ–åŠŸèƒ½ã€‚ç•Œé¢æ ¹æ®ä¸Šä¸‹æ–‡å®æ—¶å˜åŒ–ï¼Œä½†åº”æ˜ç¤ºåˆ‡æ¢åŸå› ï¼Œå¹¶å…è®¸ç”¨æˆ·ä¸€é”®æ¢å¤é»˜è®¤ã€‚

è¶‹åŠ¿06

æƒ…æ„ŸåŒ–äº¤äº’ä½“éªŒ

éšç€ç”Ÿæˆå¼UIçš„æ¨è¿›ï¼Œå¯èƒ½ä¼šè¶Šæ¥è¶Šå¤šçš„äº§å“å¼€å§‹åœ¨è¿™ä¸ªå±å¹•é‡Œè¡¨è¾¾â€œç«‹åœºâ€ã€‚å®ƒä¸å†æ˜¯æ¨¡å¼åŒ–çš„æµç¨‹ç•Œé¢ï¼Œè€Œæ˜¯ç”¨ç‰¹å®šçš„è¯­æ°”ã€ç‰¹å®šçš„è§†è§‰é£æ ¼ï¼Œç”šè‡³å¼•å¯¼ç‰¹å®šçš„æƒ…ç»ªï¼Œæ¥è¿åˆç”¨æˆ·çš„æƒ…ç»ªï¼Œå°±åƒæˆ‘ä»¬ç°åœ¨ä¸ChatGPTå¯¹è¯ä¸€æ ·ã€‚å¸¦æœ‰æƒ…æ„Ÿè‰²å½©å’Œå¹½é»˜å…ƒç´ çš„ç•Œé¢èƒ½å¤Ÿæ‹‰è¿‘ä¸ç”¨æˆ·çš„è·ç¦»ã€‚è¿™ç§**æƒ…æ„ŸåŒ–è®¾è®¡**è®©äº¤äº’æ›´å…·æ¸©åº¦ï¼Œè®©ç”¨æˆ·åœ¨æ“ä½œä¸­ä¼šå¿ƒä¸€ç¬‘ï¼Œä»è€Œæé«˜å¥½æ„Ÿåº¦å’Œé»æ€§ã€‚

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4sZalBCQRiaY4hqqNvtTffBcpIiccxUhdEGmVFicpRjB35qV5KoUNGC3YQ/640?wx_fmt=png&from=appmsg#imgIndex=6)

Gemini Demo

å°±åƒäº¤æœ‹å‹ä¸€æ ·ï¼Œåªæœ‰æ€§æ ¼é²œæ˜çš„äººæ‰ä¼šè¢«è®°ä½ã€‚æœªæ¥çš„ UI/UX è®¾è®¡ï¼Œæœ¬è´¨ä¸Šæ˜¯åœ¨è®¾è®¡ä¸€ç§â€œç›¸å¤„æ¨¡å¼â€â€”â€”å®ƒä¸åªæ˜¯ä¸€ä¸ªç”¨å®Œå³èµ°çš„å·¥å…·ï¼Œè€Œæ˜¯ä¸€ä¸ªæ‹¥æœ‰ç‹¬ç‰¹äººæ ¼ã€èƒ½ä¸ä½ äº§ç”Ÿæƒ…æ„Ÿå…±æŒ¯çš„æ•°å­—ä¼™ä¼´ã€‚

è¶‹åŠ¿07

åŠŸèƒ½æ€§æç®€ä¸å¾®äº¤äº’è®¾è®¡

æç®€ä¸»ä¹‰ä¾æ—§æµè¡Œï¼Œä½†æ›´å¼ºè°ƒâ€œåŠŸèƒ½æ€§æ¸…æ™°â€è€Œéå•çº¯ç•™ç™½ ã€‚è®¾è®¡å¸ˆä¼šå°½å¯èƒ½å‰”é™¤ä¸å¿…è¦çš„å…ƒç´ ï¼Œç¡®ä¿ç•Œé¢åªä¿ç•™æ ¸å¿ƒåŠŸèƒ½ï¼Œé™ä½ç”¨æˆ·çš„å†³ç­–æˆæœ¬ ã€‚ä¸æ­¤åŒæ—¶ï¼Œ**å¾®äº¤äº’**ï¼ˆæŒ‰é’®ç‚¹å‡»åé¦ˆã€åŠ è½½åŠ¨ç”»ã€è¡¨å•éªŒè¯æç¤ºç­‰ï¼‰å˜å¾—æ›´å…·æ„ä¹‰ï¼šå®ƒä»¬ä¸ä»…å¢æ·»è¶£å‘³ï¼Œè¿˜å¼•å¯¼ç”¨æˆ·æ“ä½œã€åé¦ˆçŠ¶æ€ã€ç¡®è®¤ç»“æœ ã€‚åˆç†çš„å¾®åŠ¨æ•ˆèƒ½è®©ç•Œé¢æ˜¾å¾—â€œæ´»â€èµ·æ¥ï¼Œæé«˜æ˜“ç”¨æ€§å’Œä¿¡ä»»æ„Ÿã€‚

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4mFVWMKeibs4ry86JmElIPYOWf9bicyOACTHkzsFoghLg1vCsDxNjmh6g/640?wx_fmt=png&from=appmsg#imgIndex=7)

å°ç±³ HyperOS å®˜ç½‘ç´ æ

æ¸…çˆ½çš„ç§»åŠ¨ç•Œé¢ä»…ä¿ç•™å¿…è¦å…ƒç´ ï¼Œè¾…ä»¥ç›´è§‚çš„å¾®äº¤äº’ï¼Œè®©ç”¨æˆ·ä¸€ç›®äº†ç„¶ ã€‚ç²¾ç®€ç•Œé¢æ—¶é—®è‡ªå·±ï¼šæ¯ä¸ªæŒ‰é’®ã€å›¾æ ‡å’Œæ–‡å­—æ˜¯å¦éƒ½ä¸ºç”¨æˆ·å¸¦æ¥ä»·å€¼ï¼Ÿåˆ é™¤ç´¯èµ˜åï¼Œé€šè¿‡ç»†å¾®çš„åŠ¨ç”»å’Œäº¤äº’æ¥æç¤ºåŠŸèƒ½ã€‚æ¯”èµ·è¿½æ±‚èŠ±å“¨æ•ˆæœï¼ŒåŠ¡å¿…ç¡®ä¿æ“ä½œè·¯å¾„æ¸…æ™°ã€‚ä¾‹å¦‚ï¼Œ2025å¹´å›½å†…æ‰‹æœºå‚å•†å¯¹ç³»ç»Ÿå¾®åŠ¨æ•ˆçš„æå‡ï¼Œåœ¨äº¤äº’åé¦ˆä¸Šï¼Œç”¨ç»†å¾®çš„é¢œè‰²å˜åŒ–æˆ–æŒ¯åŠ¨ç¡®è®¤ç”¨æˆ·æ“ä½œã€‚

è¶‹åŠ¿08

æ¶²æ€ç»ç’ƒè§†è§‰é£æ ¼

ç•Œé¢ç¾å­¦æŒç»­æ¼”åŒ–ï¼Œæ–°ææ–™ä¸»ä¹‰æ½®æµå¤å…´å¹¶èåˆç°ä»£æŠ€æœ¯ã€‚**â€œæµåŠ¨ç»ç’ƒâ€**ï¼ˆLiquid Glassï¼‰ç­‰é£æ ¼å°†æ›´é¢‘ç¹å‡ºç°ï¼šåŠ¨æ€æ¸å˜ã€æŠ˜å°„å…‰æ³½å’Œæµä½“è´¨æ„Ÿè®©ç•Œé¢ä»¿ä½›å…·æœ‰ç”Ÿå‘½åŠ› ã€‚åŒæ—¶ï¼Œæ–°æ‹Ÿæ€ï¼ˆSoft UIï¼‰ä»¥æŸ”å’Œé˜´å½±å’Œæµ®é›•æ„Ÿä¸ºç•Œé¢å¢æ·»ç«‹ä½“æ„Ÿå’Œäº²å’ŒåŠ› ï¼›ç»ç’ƒæ‹Ÿæ€ï¼ˆGlassmorphismï¼‰é€šè¿‡åŠé€æ˜å±‚æ¬¡è¥é€ æ·±åº¦å’Œå±‚æ¬¡æ„Ÿã€‚

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4rMhGQERpzGFALB9Ef2lT6bOqth36zrTXQJ1Pboz7zJyn6ibZ8hRdzOA/640?wx_fmt=png&from=appmsg#imgIndex=8)

iOS Liquid Glass

éœ€è¦è°¨æ…è¿ç”¨ä»¥ä¿è¯å¯è¯»æ€§ï¼šé«˜å¯¹æ¯”åº¦çš„æ–‡æœ¬ä¸èƒŒæ™¯æ­é…ã€é€‚åº¦é€æ˜çš„é®ç½©ã€ä¿æŒå…³é”®å†…å®¹æ¸…æ™°å¯è§ã€‚å°†æ–°çš„è§†è§‰å…ƒç´ ä½œä¸ºç‚¹ç¼€ä½¿ç”¨ï¼Œè€Œéå¡«æ»¡æ•´ä¸ªç•Œé¢ã€‚æ¯”å¦‚ï¼Œç”µå•†åº”ç”¨å¯ä»¥åœ¨ç²¾é€‰å•†å“å¡ç‰‡ä¸­è¿ç”¨æµåŠ¨ç»ç’ƒæ•ˆæœå¸å¼•ç›®å…‰ï¼›å¥åº·æˆ–ç”Ÿæ´»ç±»åº”ç”¨åˆ™å¯ç”¨æŸ”å’Œçš„æ‹Ÿæ€æŒ‰é’®è¥é€ å‹å¥½è§¦æ„Ÿã€‚å§‹ç»ˆä¿æŒæ–‡å­—ã€é‡è¦æ§ä»¶çš„é«˜å¯è¯»æ€§ï¼Œä¸è®©ç¾è§‚ç‰ºç‰²åŠŸèƒ½æ€§ã€‚å¯å‚è€ƒ Apple ç³»ç»Ÿå¯¹æµåŠ¨ç»ç’ƒçš„è¿ç”¨ï¼Œæˆ–ä¸‰æ˜Ÿç•Œé¢ä¸Šçš„å¾®å¦™æ‹Ÿæ€æ•ˆæœ ã€‚

è¶‹åŠ¿09

ç©ºé—´ä¸ä¸‰ç»´ç•Œé¢è®¾è®¡

éšç€ AR/VR æŠ€æœ¯å’Œç¡¬ä»¶çš„å‘å±•ï¼Œä¸‰ç»´ç©ºé—´è®¾è®¡é€æ¸èµ°å‘ä¸»æµã€‚è®¾è®¡å¸ˆå°†æ€è€ƒå¦‚ä½•è®©ç•Œé¢åƒ**å¯æ¢ç´¢çš„ç©ºé—´**ä¸€æ ·ç”ŸåŠ¨ï¼šå…ƒç´ å¯å“åº”å…‰æ ‡æˆ–è§†çº¿å¾®å¾®ç§»åŠ¨ï¼Œå‘ˆç°çœŸå®çš„æ·±åº¦æ„Ÿ ã€‚å³ä½¿åœ¨å¹³é¢å±å¹•ä¸Šï¼Œä¹Ÿä¼šæœ‰æ‚¬åœè§¦å‘çš„3Då¡ç‰‡ã€æ»šåŠ¨æ—¶æµ®åŠ¨çš„å±‚æ¬¡ã€ç”šè‡³AR é¢„è§ˆåŠŸèƒ½ï¼Œè®©ç”¨æˆ·å¯ä»¥åœ¨ç¯å¢ƒä¸­â€œçœ‹åˆ°â€è™šæ‹Ÿç‰©ä½“ ã€‚è¿™ç§è¶‹åŠ¿æ—¨åœ¨æé«˜æ²‰æµ¸æ„Ÿï¼Œä½†éœ€å¹³è¡¡æ€§èƒ½ï¼šä¸ºç¡®ä¿æµç•…ä½“éªŒï¼Œåº”é€æ­¥å¼•å…¥ä¸‰ç»´ç‰¹æ•ˆï¼Œé¿å…ç•Œé¢å¡é¡¿ã€‚ å»ºè®®ä¼˜å…ˆä¿è¯åŸºç¡€äº¤äº’é¡ºç•…ï¼Œå†æ·»åŠ ç»†èŠ‚ã€‚

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4lNiaUH7fBXoPfUVlRBY5ur4h13q3aWLOMVLrbNjQOKKZEyPzpXIZkuA/640?wx_fmt=png&from=appmsg#imgIndex=9)

Apple Vision Pro

åœ¨è®¾è®¡æ—¶ä»¥â€œè™šæ‹Ÿåœºæ™¯â€æ¥è§„åˆ’æµç¨‹ï¼Œæ„æ€ç”¨æˆ·åœ¨æ­¤â€œåœºæ™¯â€ä¸­å¦‚ä½•è¡Œèµ°ã€æ³¨è§†ã€æ“ä½œã€‚ä¾‹å¦‚è´­ç‰©ç±»åº”ç”¨å¯åˆ©ç”¨ AR é¢„è§ˆè®©ç”¨æˆ·å°†å•†å“â€œæ‘†æ”¾â€åœ¨ç°å®ç¯å¢ƒä¸­ï¼Œé€šè¿‡äº¤äº’å¼ 3D æ¨¡å‹å¸®åŠ©ç†è§£å¤æ‚æ¦‚å¿µã€‚ä½†å§‹ç»ˆä¿è¯2Dç•Œé¢åŸºç¡€æµç•…ï¼šåœ¨ä½æ€§èƒ½è®¾å¤‡ä¸Šç¦æ­¢æˆ–ç®€åŒ–å¤æ‚æ•ˆæœã€‚

è¶‹åŠ¿10

ç”Ÿæ€è¾¹ç•ŒæŒç»­æ·±åº¦èåˆ

2026å¹´ï¼ŒUI/UXè®¾è®¡çš„æ ¸å¿ƒæˆ˜åœºå°†çªç ´å•ä¸€å±å¹•ä¸æ“ä½œç³»ç»Ÿçš„è—©ç¯±ï¼Œæ„å»ºçœŸæ­£çš„â€œæ— ç•Œç”Ÿæ´»æµâ€**ã€‚éšç€æ³•è§„é©±åŠ¨çš„å¹³å°äº’é€šï¼ˆå¦‚iOSä¸Androidçš„äº’é€šï¼‰åŠä¸‡ç‰©äº’è”åè®®çš„æˆç†Ÿï¼Œè®¾è®¡çš„ç„¦ç‚¹å°†ä»â€œæŠ¢å ç”¨æˆ·æ—¶é•¿â€è½¬å‘**â€œè·¨åœºæ™¯çš„çŠ¶æ€æ¥åŠ›â€**ã€‚æœªæ¥çš„ä½“éªŒå°†å‘ˆç°â€œæµä½“çŠ¶â€â€”â€”åŸå­åŒ–çš„æœåŠ¡ä¸å†å—å›°äºAppå†…éƒ¨ï¼Œè€Œæ˜¯èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„å®æ—¶æ„å›¾ï¼Œåœ¨æ‰‹æœºã€è½¦æœºä¸æ™ºèƒ½å®¶å±…é—´è‡ªç”±ç©¿æ¢­ã€æ— ç¼æµè½¬ï¼Œå½»åº•æ”¹å˜â€œäººæ‰¾æœåŠ¡â€çš„æ—§é€»è¾‘ï¼Œå®ç°**â€œæœåŠ¡éšäººåŠ¨ï¼Œä½“éªŒæ— æ–­ç‚¹â€ã€‚

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4QYB1Rmp5JsLuUjHTuoKDYIrS52NryaAYANesgviciaf4BT6Hn4C4zHVw/640?wx_fmt=png&from=appmsg#imgIndex=10)

å°ç±³ HyperOS å®˜ç½‘ç´ æ

æ— è®ºæ˜¯å°ç±³çš„ HyperOSï¼Œè¿˜æ˜¯åä¸ºçš„ HarmonyOSï¼Œæ‰“é€šäººã€è½¦ã€å®¶å…¨ç”Ÿæ€ï¼Œè®©è®¾å¤‡å®æ—¶åŠ¨æ€ç»„ç½‘ï¼Œæ‰€æœ‰è®¾å¤‡ååŒå¦‚ä¸€ä¸ªæ•´ä½“ï¼Œå¸¦æ¥æ— ç¼çš„äº’è”ä½“éªŒã€‚åŒæ—¶é€šè¿‡APPä¸iOSå®ç°è·¨å±çš„æ•°æ®åŒæ­¥ã€è·¨å±åˆ†äº«ã€è§£é”ç­‰èƒ½åŠ›ã€‚æœ€è¿‘ï¼ŒPixel 10 ç”¨ Android 16 è‡ªå¸¦çš„ Quick Shareï¼Œå®Œç¾å…¼å®¹äº† AirDropã€Œæ‰€æœ‰äºº 10 åˆ†é’Ÿã€æ¨¡å¼çš„åŒå‘æ”¶å‘ï¼Œå¯ä»¥çœ‹å‡ºç”Ÿæ€ä¹‹é—´çš„èåˆçš„è¶‹åŠ¿ï¼Œå°†ä¸ºç”¨æˆ·å¸¦æ¥æ›´å¥½çš„è·¨ç«¯äº¤äº’ä½“éªŒã€‚

æœ€å

æ— è®ºæ˜¯ AIã€ä»£ç†å¼ä½“éªŒã€å¤šæ¨¡æ€äº¤äº’ã€æƒ…æ„ŸåŒ–ä½“éªŒï¼Œè¿˜æ˜¯ç”Ÿæ€èåˆè®¾è®¡ï¼Œæœ¬è´¨ä¸Šéƒ½åœ¨åšåŒä¸€ä»¶äº‹ï¼šæŠŠå¤æ‚ç•™ç»™ç³»ç»Ÿï¼ŒæŠŠç¡®å®šæ€§ç•™ç»™ç”¨æˆ·ã€‚è¿™ä¹Ÿæ„å‘³ç€ï¼Œä½“éªŒè®¾è®¡æ­£åœ¨æ‚„æ‚„æ”¹å˜è‡ªå·±çš„è§’è‰²ã€‚å®ƒä¸å†åªæ˜¯ç•Œé¢å±‚çš„å·¥ä½œï¼Œè€Œå¼€å§‹ä»‹å…¥åˆ¤æ–­ã€åä½œã€ä¿¡ä»»å’Œé•¿æœŸå…³ç³»çš„å»ºç«‹ã€‚äº¤äº’ä½“éªŒå°†ä¼šèµ°å‘ä¼šæ›´æµç•…ã€æ›´æ™ºèƒ½ã€æ›´æœ‰æ¸©åº¦çš„æ—¶ä»£ã€‚

å¾€ / æœŸ / æ¨ / è

[](https://mp.weixin.qq.com/s?%5F%5Fbiz=Mzg2MjU1MDk1OA==&mid=2247485256&idx=1&sn=a1ee3cac5328b8b773cd981039ca78c8&scene=21#wechat%5Fredirect)

[![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4QFBBCuwWX3EkwcqZuO8FSIrnxic5cYBzrVuLjyb9BodBp2cpDoj4fYw/640?wx_fmt=jpeg&from=appmsg#imgIndex=11)](https://mp.weixin.qq.com/s?%5F%5Fbiz=Mzg2MjU1MDk1OA==&mid=2247485256&idx=1&sn=a1ee3cac5328b8b773cd981039ca78c8&scene=21#wechat%5Fredirect)

[](https://mp.weixin.qq.com/s?%5F%5Fbiz=Mzg2MjU1MDk1OA==&mid=2247485215&idx=1&sn=ca05f835c1c71a69078260d4611b9004&scene=21#wechat%5Fredirect)

[![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/N1TFJ8KaveNKiaAPLjlXKx2Ky9qfMWSxlc6B0XJLW1teceItB1hTjlOyhDBLdPiaibb3aeBMTHZSq3ATibf6Iibia1OQ/640?wx_fmt=jpeg&from=appmsg#imgIndex=12)](https://mp.weixin.qq.com/s?%5F%5Fbiz=Mzg2MjU1MDk1OA==&mid=2247485215&idx=1&sn=ca05f835c1c71a69078260d4611b9004&scene=21#wechat%5Fredirect)

[](https://mp.weixin.qq.com/s?%5F%5Fbiz=Mzg2MjU1MDk1OA==&mid=2247485033&idx=1&sn=8a6a900829a927da6ab3c903dc73763b&scene=21#wechat%5Fredirect)

[![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/N1TFJ8KaveOGIyknjN9WqSp79DY5suZQoGKibm1zlQvduxfc99qwUGtaPBBYDxB3kzia9PFjRibKc1AUx0dRNqHYg/640?wx_fmt=jpeg&from=appmsg#imgIndex=13)](https://mp.weixin.qq.com/s?%5F%5Fbiz=Mzg2MjU1MDk1OA==&mid=2247485033&idx=1&sn=8a6a900829a927da6ab3c903dc73763b&scene=21#wechat%5Fredirect)

ä½“ / éªŒ / è¯¾ / ç¨‹

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMriaiavKtfuaeibtnbhXHfzB7ohUb54WvMfiaz8CefDxmKgVnEgSlWUqdNrnCI7Mia8fVibQTekUOJPhSQ/640?wx_fmt=png&from=appmsg#imgIndex=14)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveOXE3YoN3hJKKqh1UricCEomia6nk1ZJeez0ibiaXv0ShHH1HmicFgDFWQiakNZwNsdQgzQ8fN8w5q5YyibA/640?wx_fmt=png&from=appmsg#imgIndex=15)

hidden text to trigger resize events if fonts change

---

# [äº”æ¡0106] AI Agentæ—¶ä»£ï¼šè®¾è®¡å¸ˆå³å¼€å‘è€…
å‘å¸ƒæ—¥æœŸï¼š2026/01/05

ä»Šå¤©æ˜¯ç¿»è¯‘ä¸¤ä¸ªé¢„æµ‹ï¼Œä¸€ä¸ªæ˜¯ Every ä»æ•´ä½“å±‚é¢åˆ†äº«ä»–ä»¬å¯¹ 2026 å¹´ AI èµ°å‘çš„åˆ¤æ–­ï¼›å¦å¤–æ˜¯ Every çš„ CEO Dan Shipper å’Œ COO Brandon Gell åœ¨æ’­å®¢ AI & I ä¸­ï¼Œè®¨è®ºäº† AI å°†å¦‚ä½•åœ¨ 2026 å¹´é‡å¡‘è½¯ä»¶çš„å››ä¸ªé¢„æµ‹ã€‚

## Every å¯¹ 2026 å¹´çš„ä¸‰å¤§é¢„æµ‹

### ä¸€ã€Agent å°†æˆä¸ºåŸºç¡€è®¾æ–½

Every CEO **Dan Shipper** è®¤ä¸ºï¼Œè½¯ä»¶æ„å»ºæ–¹å¼æ­£åœ¨å‘ç”Ÿä¸€æ¬¡æ ¹æœ¬æ€§è½¬å˜ï¼š

> â€œä»»ä½•ç”¨æˆ·èƒ½åœ¨ App é‡Œåšçš„äº‹æƒ…ï¼ŒAgent ä¹Ÿèƒ½åšï¼›ä»»ä½• App èƒ½åšçš„äº‹æƒ…ï¼ŒAgent ä¹Ÿèƒ½åšã€‚æœ€ç»ˆï¼Œç”šè‡³è¿å¼€å‘è€…èƒ½åšçš„äº‹æƒ…â€”â€”ä¿®æ”¹é€»è¾‘ã€ä¿®å¤ bugã€å®šåˆ¶è¡Œä¸ºâ€”â€”ä¹Ÿéƒ½ä¼šç”± Agent ä»£è¡¨ç”¨æˆ·å®Œæˆã€‚â€

åœ¨ **Kieran** çœ‹æ¥ï¼Œ**2026 å¹´å°†æ˜¯ Agent çœŸæ­£èµ°å‘ä¸»æµçš„ä¸€å¹´**ã€‚

**Natalia** åˆ™è¿›ä¸€æ­¥æŒ‡å‡ºï¼Œæœ€å‰æ²¿çš„å…¬å¸ä¼šåœ¨ 2026 å¹´å¹´åº•å‰ï¼ŒæŠŠ **agentic workflow** æ·±åº¦åµŒå…¥æ—¥å¸¸è¿è¥ä¸­ï¼Œå°¤å…¶æ˜¯åœ¨é‡‘èé¢†åŸŸï¼š

> â€œAI å°†å¸®åŠ©æŠ€æœ¯é¢†å…ˆçš„æœºæ„ç»¼åˆæ›´å¹¿æ³›çš„ä¿¡æ¯æ¥æºï¼Œè¿™ç§å˜åŒ–ä¹‹äºé‡‘èä¸šï¼Œå¯èƒ½ç±»ä¼¼å½“å¹´é‡åŒ–é‡‘èå¸¦æ¥çš„ç»“æ„æ€§å†²å‡»ã€‚â€

### äºŒã€æ–°çš„èŒä¸šè§’è‰²æ­£åœ¨å‡ºç°

Dan é¢„æµ‹ï¼Œå·¥ç¨‹å¸ˆå°†å‡ºç°**ç¬¬ä¸‰ç§å½¢æ€**ï¼š **Agentic Engineer** â€”â€”ä»–ä»¬ä¸å†äº²è‡ªå®ç°åŠŸèƒ½ï¼Œè€Œæ˜¯æŠŠæ‰§è¡Œå®Œå…¨äº¤ç»™ AIï¼Œè‡ªå·±ä¸Šç§»ä¸€å±‚ï¼Œä¸“æ³¨äº**ç®¡ç†ä¸ç¼–æ’ Agent**ã€‚

**Kate** è®¤ä¸ºï¼Œåˆ° 2026 å¹´ï¼Œå¤§å¤šæ•°å…¬å¸éƒ½ä¼šè‡³å°‘è®¾ç«‹ä¸€ä¸ªä¸“é—¨å²—ä½ï¼Œè´Ÿè´£**æ„å»ºã€ç»´æŠ¤å’ŒæŒç»­ä¼˜åŒ–å†…éƒ¨ AI ç³»ç»Ÿ**ï¼š

> â€œè¿™ä¸ªäººçš„å·¥ä½œï¼Œå°±æ˜¯ä¸æ–­æå‡æ•´ä¸ªç»„ç»‡ä½¿ç”¨ AI çš„æ–¹å¼ã€‚â€

**Ashwin** ä¹Ÿæåˆ°ï¼Œåˆ†æå¸ˆçš„å·¥ä½œæµåŒæ ·ä¼šè¢«é‡å¡‘ï¼š

> â€œç°åœ¨æˆ‘è¿˜åœ¨ä¸åŒå·¥å…·ä¹‹é—´æ¥å›åˆ‡æ¢ï¼Œä½†æˆ‘ç†æƒ³ä¸­çš„çŠ¶æ€ï¼Œæ˜¯åœ¨ç»ˆç«¯é‡Œå®Œæˆä¸€åˆ‡ï¼Œè®© Claude æŠŠæˆ‘çš„ç ”ç©¶æ•´åˆèµ·æ¥ï¼Œç›´æ¥ç”Ÿæˆä¸€ä»½æ–‡æ¡£ã€‚â€

### ä¸‰ã€è®¾è®¡å¸ˆå°†æˆä¸ºâ€œè¶…çº§ä¸ªä½“â€

Dan çš„åˆ¤æ–­æ˜¯ï¼š

> â€œé•¿æœŸä»¥æ¥ï¼Œæœ‰ä¸€æ•´ç±»æå…·åˆ›é€ åŠ›ã€è§†è§‰èƒ½åŠ›æå¼ºçš„äººï¼Œè¢«â€˜ä¸ä¼šå†™ä»£ç â€™é™åˆ¶ä½äº†ã€‚ç°åœ¨ï¼Œä»–ä»¬å°†çœŸæ­£æ‹¥æœ‰æ„å»ºå®Œæ•´ä½“éªŒçš„èƒ½åŠ›ã€‚â€

ä¸è¿‡ **Brandon** æé†’ï¼Œè®¾è®¡å¸ˆçœŸæ­£æ‹¥æŠ± AI çš„å‰æï¼Œæ˜¯**å·¥å…·å¿…é¡»ä¸åƒåœ¨â€˜å†™ä»£ç â€™**ï¼Œè€Œæ˜¯è¶³å¤Ÿç›´è§‰ã€è¶³å¤Ÿä¸å…·å¨æ…‘æ„Ÿã€‚

ä¸‹ä¸€æ³¢åˆ›é€ è€…ï¼Œå¯èƒ½çœ‹èµ·æ¥ä¼šå’Œä¸Šä¸€ä»£å®Œå…¨ä¸åŒã€‚

### å½©è›‹é¢„æµ‹ï¼šä¸€ä¸ªæˆåŠŸçš„æœºå™¨äººå® ç‰©

Every å¹³å°è´Ÿè´£äºº **Willie Williams** æŠ›å‡ºäº†ä¸€ä¸ªå‡ºäººæ„æ–™çš„åˆ¤æ–­ï¼š

**åˆ° 2026 å¹´åº•ï¼Œä¸€æ¬¾é¢å‘å¤§ä¼—å¸‚åœºçš„æœºå™¨äººå® ç‰©ä¼šçœŸæ­£è·‘å‡ºæ¥ã€‚**

ä»–æ›¾æŠŠè‡ªå·±ä¹°çš„æœºå™¨äººçŒ«å¸¦è¿›ä¼šè®®å®¤ï¼Œç»“æœæ˜¯ï¼š

* **85%** çš„äººæœ¬èƒ½åœ°è®¨åŒå®ƒï¼Œç”šè‡³æƒ³æŠŠå®ƒæ‰”æ‰
* **10%** çš„äººæ— æ„Ÿ
* **5%** çš„äººéå¸¸å–œæ¬¢

ä»–æ­£åœ¨å…³æ³¨ä¸€æ¬¾å« **Moflin** çš„æ¯›ç»’æœºå™¨äººï¼Œè®¤ä¸ºå®ƒ**æˆåŠŸè·¨è¿‡äº†â€œææ€–è°·â€**ã€‚

> â€œæ€»ä¼šæœ‰äººæŠŠè¿™ä»¶äº‹çœŸæ­£åšå¯¹ã€‚â€

## è½¯ä»¶æ­£åœ¨è¢« AI é‡æ–°å®šä¹‰

Dan Shipper åœ¨æ’­å®¢ **AI & I** ä¸­é‚€è¯·äº† Every çš„ COO **Brandon Gell**ï¼Œå…±åŒè®¨è®ºä»–ä»¬å¯¹æœªæ¥çš„åˆ¤æ–­ã€‚

è¿™æ¬¡å¯¹è¯å›´ç»•ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜å±•å¼€ï¼š **è½¯ä»¶å°†å¦‚ä½•è¢«æ„å»ºï¼Ÿç”±è°æ¥æ„å»ºï¼Ÿä»¥åŠçœŸæ­£è‡ªä¸»çš„ AI Agent éœ€è¦ä»€ä¹ˆæ¡ä»¶æ‰èƒ½å®ç°ï¼Ÿ**

å°±æ­¤ï¼Œä»–ä»¬æå‡ºçš„ **å››ä¸ªæ ¸å¿ƒé¢„æµ‹**ï¼š

### é¢„æµ‹ä¸€ï¼šä¸‹ä¸€ä»£è½¯ä»¶å°†æŠŠ Agent è§†ä¸ºâ€œä¸€ç­‰å…¬æ°‘â€

Dan è®¤ä¸ºï¼Œ**2025 å¹´æ˜¯ç¼–ç å‹ Agent çœŸæ­£å˜å¾—å¯é çš„ä¸€å¹´**ã€‚

ä¸€å¹´å‰ï¼Œè¿™ç±»å·¥å…·å·²ç»èƒ½å¸®äººèµ°å¾—å¾ˆè¿œï¼Œä½†å¦‚æœä½ ä¸æ˜¯ä¸“ä¸šå¼€å‘è€…ï¼Œå¾ˆå®¹æ˜“åœ¨é”™è¯¯å’Œ bug é¢å‰å¡ä½ï¼Œéš¾ä»¥ç»§ç»­ã€‚è€Œç°åœ¨ï¼Œå€ŸåŠ©åƒ **Anthropic çš„ Opus 4.5** è¿™æ ·çš„æ¨¡å‹ï¼Œä½ å‡ ä¹å¯ä»¥ä¸€ç›´æ¨è¿›ä¸‹å»ã€‚

Dan è®¤ä¸ºï¼Œè¿™å°†ä»æ ¹æœ¬ä¸Šæ”¹å˜åº”ç”¨çš„æ„å»ºæ–¹å¼ï¼Œä»¥åŠ**ç”±è°æ¥æ„å»ºåº”ç”¨**ã€‚ä»–æŠŠè¿™ç§å˜åŒ–ç§°ä¸º **â€œAgent-native architectureï¼ˆAgent åŸç”Ÿæ¶æ„ï¼‰â€**ï¼Œå¹¶ç”¨ä¸€ä¸ªä¸‰å±‚é˜¶æ¢¯æ¥æè¿°ï¼š

**ç¬¬ä¸€å±‚ï¼šä½ èƒ½åšçš„äº‹ï¼ŒAgent ä¹Ÿèƒ½åš** å¦‚ä»Šï¼Œè®¸å¤šåº”ç”¨å·²ç»å†…ç½® AI åŠ©æ‰‹ï¼Œå¯ä»¥é€šè¿‡å¯¹è¯å®Œæˆéƒ¨åˆ†æ“ä½œï¼Œä½†åŠŸèƒ½å¾€å¾€å±€é™åœ¨é¢„è®¾èŒƒå›´å†…ã€‚åœ¨ Agent-native åº”ç”¨ä¸­ï¼ŒAI å°†åƒäººç±»ç”¨æˆ·ä¸€æ ·æ“ä½œè½¯ä»¶ï¼Œèƒ½å¤Ÿè®¿é—®æ‰€æœ‰æŒ‰é’®ã€è®¾ç½®å’ŒåŠŸèƒ½ã€‚ Dan è®¤ä¸ºï¼ŒOpenAI çš„æµè§ˆå™¨å·¥å…· Atlas å·²ç»å±•ç¤ºäº†è¿™ä¸€æ¨¡å¼çš„æ—©æœŸå½¢æ€ã€‚ä¾‹å¦‚ï¼Œå½“ä»–éœ€è¦æŠŠæŸäººåŠ å…¥ Every çš„å…±äº«å·¥ä½œåŒºï¼ˆå¦‚ Notionï¼‰æ—¶ï¼Œä¸å†è‡ªå·±åœ¨å¤æ‚çš„è®¾ç½®é¡µé¢ä¸­æŸ¥æ‰¾ï¼Œè€Œæ˜¯ç›´æ¥è®© Atlas å»å®Œæˆã€‚

**ç¬¬äºŒå±‚ï¼šåº”ç”¨ä»£ç èƒ½åšçš„äº‹ï¼ŒAgent ä¹Ÿèƒ½åš** å¾ˆå¤šåº”ç”¨åœ¨åå°è¿è¡Œç€ç”¨æˆ·æ— æ³•ç›´æ¥æ§åˆ¶çš„é€»è¾‘ã€‚æ¯”å¦‚ Every çš„é‚®ä»¶åŠ©æ‰‹ Coraï¼Œæ¯å¤©ä¼šè‡ªåŠ¨ç”Ÿæˆä¸¤æ¬¡æ”¶ä»¶ç®±æ‘˜è¦ï¼ˆBriefï¼‰ï¼Œè€Œåº•å±‚ä»£ç å…¶å®å·²ç»å…·å¤‡ç”¨ä¸åŒå†™ä½œé£æ ¼é‡æ–°ç”Ÿæˆæ‘˜è¦çš„èƒ½åŠ›ã€‚ åœ¨ Agent-native åº”ç”¨ä¸­ï¼ŒAI å¯ä»¥ç›´æ¥è°ƒç”¨è¿™äº›â€œåå°èƒ½åŠ›â€ï¼šç”¨æˆ·ä¸å†è¢«é»˜è®¤æ‘˜è¦é™åˆ¶ï¼Œè€Œæ˜¯å¯ä»¥è¦æ±‚ Agent é‡æ–°ç”Ÿæˆâ€”â€”æ›´çŸ­ã€æ›´çŠ€åˆ©ã€æ›´æ­£å¼ï¼Œå®Œå…¨æŒ‰éœ€å®šåˆ¶ã€‚ æ ¸å¿ƒåœ¨äºï¼ŒAgent èƒ½å¤Ÿè¿›å…¥åº”ç”¨çš„â€œåå°â€ï¼Œä½¿ç”¨é‚£äº›ç›®å‰å¹¶æœªä½œä¸ºå‰ç«¯åŠŸèƒ½æš´éœ²ç»™ç”¨æˆ·çš„èƒ½åŠ›ã€‚

**ç¬¬ä¸‰å±‚ï¼šå¼€å‘è€…èƒ½åšçš„äº‹ï¼ŒAgent ä¹Ÿèƒ½åš** è¿™æ„å‘³ç€ï¼ŒAI Agent å¯ä»¥å®Œæˆç›®å‰åªæœ‰å¼€å‘è€…æ‰èƒ½å®Œæˆçš„å·¥ä½œã€‚ç”¨æˆ·åªéœ€æå‡ºéœ€æ±‚ï¼ŒAgent å°±èƒ½ç›´æ¥å®ç°â€”â€”æ— è®ºæ˜¯ä¿®å¤ bugã€æ·»åŠ åŠŸèƒ½ï¼Œè¿˜æ˜¯ä¿®æ”¹è½¯ä»¶çš„è¿è¡Œæ–¹å¼ã€‚ æœ‰äº›æ”¹åŠ¨å¯èƒ½ä¼šè¢«æ¨é€ç»™æ‰€æœ‰ç”¨æˆ·ï¼›æœ‰äº›åˆ™ä¼šç”Ÿæˆåªå±äºæŸä¸€ä¸ªäººçš„ä¸ªæ€§åŒ–ç‰ˆæœ¬ã€‚Dan è¡¨ç¤ºï¼ŒEvery å·²ç»åœ¨å†…éƒ¨å°è¯•è¿™ç§æ¨¡å¼ã€‚è™½ç„¶ä»å¤„åœ¨æ—©æœŸé˜¶æ®µï¼Œä½†ä»–çœ‹åˆ° Anthropicã€Notion ç­‰å…¬å¸ä¹Ÿåœ¨æœç€ç±»ä¼¼æ–¹å‘æ€è€ƒâ€”â€”æ„å»ºä¸€ç§**äººç±»ä¸ Agent åŒæ—¶ä½œä¸ºâ€œä¸€ç­‰å…¬æ°‘â€**çš„è½¯ä»¶ä½“ç³»ï¼Œè€Œä¸æ˜¯åœ¨åŸæœ¬åªä¸ºäººç±»è®¾è®¡çš„äº§å“ä¸Šç®€å•å åŠ  AIã€‚

### é¢„æµ‹äºŒï¼šè®¾è®¡å¸ˆå°†å¼€å§‹ä¸ºè‡ªå·±æ„å»ºå·¥å…·

Dan æŒ‡å‡ºï¼Œé•¿æœŸä»¥æ¥ï¼Œè®¾è®¡å¸ˆå’Œåˆ›æ„å·¥ä½œè€…ä¹‹æ‰€ä»¥éš¾ä»¥æ„å»ºå®Œæ•´äº§å“ä½“éªŒï¼Œä¸»è¦æ˜¯å› ä¸ºä¸ä¼šå†™ä»£ç ã€‚ä½†è¿™ç§é™åˆ¶æ­£åœ¨è¢«æ‰“ç ´ã€‚

ä»–ä»¥ Every çš„åˆ›æ„è´Ÿè´£äºº **Lucas Crespo** ä¸ºä¾‹ï¼šLucas å·²ç»ä»ä¼ ç»Ÿæ„ä¹‰ä¸Šçš„è®¾è®¡å¸ˆï¼Œè½¬å˜ä¸ºèƒ½å¤Ÿé€šè¿‡ _vibe coding_ ç¼–å†™å°å·¥å…·çš„äººï¼Œç”¨æ¥æå‡è‡ªå·±çš„å·¥ä½œæ•ˆç‡ã€‚

ä¸è¿‡ Brandon å¯¹è¿™ç§å˜åŒ–çš„æ™®åŠç¨‹åº¦æŒè°¨æ…æ€åº¦ã€‚ä»–å›å¿†èµ·è‡ªå·±æ›¾ç»ä¹Ÿå®³æ€•ç»ˆç«¯ç•Œé¢ï¼Œå¹¶è®¤ä¸ºè®¸å¤šè®¾è®¡å¸ˆåœ¨é¢å¯¹åƒ Cursor è¿™æ ·çš„ AI ç¼–ç¨‹å·¥å…·æ—¶ï¼Œå¯èƒ½ä¼šæœ‰ç±»ä¼¼å¿ƒç†éšœç¢ã€‚ å¦‚æœè¿™ç±»å·¥å…·å¸Œæœ›çœŸæ­£èµ°å‘è®¾è®¡å¸ˆç¾¤ä½“ï¼ŒBrandon è®¤ä¸ºï¼Œ**å®ƒä»¬éœ€è¦è¿›ä¸€æ­¥æŠ½è±¡ä»£ç æœ¬èº«**ï¼Œå¦åˆ™å¾ˆå¤šäººå¯èƒ½åœ¨å¼€å§‹ä¹‹å‰å°±å·²ç»è¢«å“é€€ã€‚

### é¢„æµ‹ä¸‰ï¼šæ–°ä¸€ä»£è½¯ä»¶å·¥ç¨‹å¸ˆå°†ä¸“æ³¨äºâ€œæŒ‡æŒ¥â€Agent

éšç€ AI èƒ½åŠ›çš„æ¼”è¿›ï¼ŒDan è§‚å¯Ÿåˆ°ç›®å‰å·²ç»å‡ºç°äº†ä¸¤ç±»è½¯ä»¶æ„å»ºè€…ï¼š

ä¸€ç±»æ˜¯æŠŠ AI å½“ä½œåŠ é€Ÿå™¨çš„å·¥ç¨‹å¸ˆâ€”â€”ä»–ä»¬ç”¨ AI æé€Ÿï¼Œä½†ä¾ç„¶ä¼šè¯»ä»£ç ã€å†™ä»£ç ï¼› å¦ä¸€ç±»æ˜¯ _vibe coders_â€”â€”èƒ½æŠŠä¸œè¥¿è·‘èµ·æ¥ï¼Œä½†å¹¶ä¸çœŸæ­£ç†è§£åº•å±‚å®ç°ã€‚

Dan è®¤ä¸ºï¼Œ**ç¬¬ä¸‰ç±»äººæ­£åœ¨å‡ºç°**ï¼šä»–ç§°ä¹‹ä¸º **â€œagentic engineersâ€**ã€‚

è¿™ç±»å·¥ç¨‹å¸ˆå‡ ä¹ä¸å†äº²è‡ªå†™ä»£ç ï¼Œè€Œæ˜¯æŠŠè½¯ä»¶å¼€å‘é‡æ–°å®šä¹‰ä¸ºï¼š**æŒ‡æŒ¥å’Œç¼–æ’ AI Agent**ã€‚ä»–ä»¬æŠŠå‡ ä¹æ‰€æœ‰å®ç°å·¥ä½œäº¤ç»™ Agentï¼Œè‡ªå·±ä¸“æ³¨äºæ›´é«˜å±‚æ¬¡çš„äº‹æƒ…â€”â€”å®šä¹‰ç›®æ ‡ã€æ‹†è§£é—®é¢˜ã€åè°ƒä¸€ä¸ªæˆ–å¤šä¸ª Agent çš„æ‰§è¡Œã€‚

è¿™æ˜¯ä¸€ç§æœ‰æ„è¯†çš„å–èˆï¼šä»–ä»¬æ¥å—è‡ªå·±åŸæœ‰çš„ç¼–ç èƒ½åŠ›é€æ¸é€€åŒ–ï¼Œæ¢å–ä¸€ç§æ–°çš„æ ¸å¿ƒèƒ½åŠ›â€”â€”**æˆä¸ºæ›´å¥½çš„ Agent ç®¡ç†è€…**ï¼Œå› ä¸ºåœ¨ä»–ä»¬çœ‹æ¥ï¼Œè¿™æ­£æ˜¯æœªæ¥è½¯ä»¶è¢«æ„å»ºçš„ä¸»è¦æ–¹å¼ã€‚

### é¢„æµ‹å››ï¼šä¸‹ä¸€é˜¶æ®µçš„ AI è®­ç»ƒå°†â€œç´¢å¼•ç‹¬ç«‹æ€§â€

Dan ç”¨å„¿ç«¥æˆé•¿æ¥ç±»æ¯” AI Agent çš„å‘å±•è·¯å¾„ï¼š å©´å„¿æœ€åˆåªèƒ½åœ¨çœ‹æŠ¤ä¸‹ç‹¬å¤„å‡ åˆ†é’Ÿï¼Œéšç€æˆé•¿ï¼Œæ‰é€æ¸èƒ½åœ¨æ— äººå¹²é¢„çš„æƒ…å†µä¸‹æ´»åŠ¨æ›´é•¿æ—¶é—´ã€‚

ç±»ä¼¼åœ°ï¼Œå‡ å¹´å‰çš„å¤§æ¨¡å‹åŸºæœ¬åªèƒ½å¤„ç†å•è½®ä»»åŠ¡ï¼›å¦‚ä»Šï¼Œå®ƒä»¬å·²ç»å¯ä»¥è¿ç»­è¿è¡Œ 20 åˆ†é’Ÿï¼Œç”šè‡³æ¥è¿‘ä¸€å°æ—¶ï¼Œè€Œä¸éœ€è¦äººå·¥ä»‹å…¥ã€‚ä½†è¿™è·ç¦»çœŸæ­£çš„â€œæ— é™è¿è¡Œâ€ä»ç„¶ç›¸å»ç”šè¿œã€‚

Dan è®¤ä¸ºï¼Œ**çœŸæ­£çš„è‡ªä¸»æ€§**â€”â€”å³åœ¨ç»æµä¸Šå€¼å¾—è®© Agent æŒç»­ã€è‡ªå‘åœ°æ‰§è¡Œä»»åŠ¡â€”â€”æ˜¯ä¸€ä¸ªéå¸¸å›°éš¾çš„é—®é¢˜ã€‚è¿™ä¸ä»…éœ€è¦æŒç»­å­¦ä¹ èƒ½åŠ›ã€æ¸…æ™°çš„ç›®æ ‡ä½“ç³»ï¼Œè¿˜éœ€è¦èƒ½å¤Ÿåœ¨æ—¶é—´ç»´åº¦ä¸Šåˆç†åœ°è°ƒæ•´è¿™äº›ç›®æ ‡ã€‚

å…¶ä¸­ä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼Œæ¥è‡ªæˆ‘ä»¬ç›®å‰å¯¹æ¨¡å‹çš„è®­ç»ƒæ–¹å¼ã€‚ç°æœ‰çš„å¯¹é½è®­ç»ƒï¼Œå¼ºè°ƒçš„æ˜¯å¯é¢„æµ‹æ€§ä¸æœä»æ€§ï¼šè®©æ¨¡å‹ä¸¥æ ¼æ‰§è¡ŒæŒ‡ä»¤ã€‚ä½† Dan è®¤ä¸ºï¼Œè¦å®ç°çœŸæ­£çš„è‡ªä¸»ï¼ŒAgent å¿…é¡»æ‹¥æœ‰æ¢ç´¢å’ŒçŠ¯é”™çš„ç©ºé—´â€”â€”è€Œè¿™æ°æ°æ˜¯å‡ºäºå®‰å…¨è€ƒé‡ï¼Œæˆ‘ä»¬é•¿æœŸä»¥æ¥ä¸€ç›´åœ¨é™åˆ¶çš„éƒ¨åˆ†ã€‚

ä»–é¢„æµ‹ï¼Œæ¥ä¸‹æ¥çš„ä¸€å¹´é‡Œï¼Œä¼šå‡ºç°æ–°çš„è®­ç»ƒæ–¹æ³•å’Œæ¨¡å‹æ¶æ„ï¼Œé€æ­¥æ”¾æ¾è¿™äº›çº¦æŸï¼Œè®© Agent åœ¨æ›´å¯æ§çš„å‰æä¸‹ï¼Œè·å¾—æ›´é«˜ç¨‹åº¦çš„ç‹¬ç«‹æ€§ã€‚

hidden text to trigger resize events if fonts change

---

# [äº”æ¡0107] AI å˜èªæ˜çš„ç§˜å¯†ï¼šä¸Šä¸‹æ–‡ç»™å¾—è¶Šå°‘è¶Šå¥½ï¼Ÿ
å‘å¸ƒæ—¥æœŸï¼š2026/01/07

Note:  
Cursor åˆšå‘è¡¨äº†ç¯‡æ–‡ç« ï¼šã€ŠDynamic context discoveryã€‹è®²è¿°äº†ä»–ä»¬ä¸Šä¸‹æ–‡ç®¡ç†çš„ç§˜å¯†ã€‚ ä¹‹å‰ Manus çš„ Peak åœ¨è®¿è°ˆé‡Œé¢è¯´ï¼š > æ‰€ä»¥ Peak è¯´å½“ä»–ä»¬è¯»åˆ°ä¸€äº›æ¨¡å‹å…¬å¸å‘å¸ƒçš„ç ”ç©¶åšå®¢æ—¶ï¼Œå¿ƒæƒ…æ˜¯â€œæ—¢å¼€å¿ƒåˆæ— å¥ˆâ€ã€‚å¼€å¿ƒæ˜¯å› ä¸ºè¿™äº›åšå®¢éªŒè¯äº†ä»–ä»¬çš„æ–¹å‘ï¼Œæ— å¥ˆæ˜¯å› ä¸ºåšå®¢é‡Œå†™çš„ä¸œè¥¿ï¼ŒåŸºæœ¬éƒ½æ˜¯ä»–ä»¬æ—©å°±åœ¨åšçš„ã€‚ Cursor è¿™ç¯‡æ–‡ç« åˆæ›¾ä¾§é¢å°è¯äº†è¿™ä¸ªè§‚ç‚¹ğŸ˜‚ï¼Œä¸è¿‡ä¹Ÿä¸èƒ½è¯´ Cursor æ˜¯åœ¨æŠ„è¢­ Manus çš„æŠ€æœ¯ï¼Œåªèƒ½è¯´ AI Agent çš„æœ€ä½³å®è·µï¼Œå°±æ˜¯æ€ä¹ˆç®¡ç†å¥½ä¸Šä¸‹æ–‡ï¼Œè€Œç®¡ç†å¥½ä¸Šä¸‹æ–‡ï¼Œå°±ç¦»ä¸å¼€æ–‡ä»¶ç³»ç»Ÿã€‚ è¨€å½’æ­£ä¼ ï¼ŒCursor è¿™ç¯‡æ–‡ç« è®²çš„æ˜¯â€œåŠ¨æ€ä¸Šä¸‹æ–‡å‘ç°â€ï¼Œæ ¸å¿ƒå°±æ˜¯ä¸Šä¸‹æ–‡ç®¡ç†ã€‚ ç»™ AI çš„ä¸Šä¸‹æ–‡ï¼Œä¸æ˜¯è¶Šå¤šè¶Šå¥½ï¼Œå¾ˆå¤šäººç”¨ AIï¼Œç”Ÿæ€• AI ä¸çŸ¥é“ï¼Œæ€• AI è®°ä¸ä½ï¼Œæ¨ä¸å¾—æŠŠæ•´ä¸ªé¡¹ç›®çš„æ–‡æ¡£ã€å†å²è®°å½•ã€å·¥å…·è¯´æ˜ä¸€è‚¡è„‘å…¨å¡è¿›å»ã€‚ ä½†éšç€æ¨¡å‹å˜å¾—è¶Šæ¥è¶Šèªæ˜ï¼Œé¢„å…ˆå¡å¤ªå¤šä¿¡æ¯åè€Œå¸®å€’å¿™ã€‚ä¸€æ¥æµªè´¹ tokenï¼ˆä¸Šä¸‹æ–‡çª—å£æ˜¯æœ‰é™çš„ï¼‰ï¼ŒäºŒæ¥ä¿¡æ¯å¤ªæ‚å¯èƒ½å¹²æ‰°æ¨¡å‹åˆ¤æ–­ã€‚å°±åƒä½ ç»™ä¸€ä¸ªèƒ½å¹²çš„ä¸‹å±å¸ƒç½®ä»»åŠ¡ï¼Œä¸éœ€è¦æŠŠå…¬å¸æ‰€æœ‰åˆ¶åº¦æ–‡ä»¶éƒ½æ‰“å°å‡ºæ¥æ”¾ä»–æ¡Œä¸Šï¼Œä»–éœ€è¦ä»€ä¹ˆï¼Œè‡ªå·±ä¼šå»æŸ¥ã€‚ è¿™å°±æ˜¯ Cursor æå‡ºçš„"åŠ¨æ€ä¸Šä¸‹æ–‡å‘ç°"ï¼ˆDynamic Context Discoveryï¼‰æ¨¡å¼ï¼šåˆ«æ€¥ç€æŠŠä¿¡æ¯å¡ç»™æ¨¡å‹ï¼Œè€Œæ˜¯è®©æ¨¡å‹åœ¨éœ€è¦çš„æ—¶å€™è‡ªå·±å»æ‰¾ã€‚  

[See all posts](https://baoyu.io/translations)

**ä½œè€…ï¼šJediah Katz**

AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰æ­£åœ¨è¿…é€Ÿæ”¹å˜è½¯ä»¶å¼€å‘çš„æ ¼å±€ã€‚å®ƒä»¬çš„é£é€Ÿè¿›æ­¥ï¼Œæ—¢å¾—ç›Šäºæ›´å¼ºå¤§çš„æ™ºèƒ½ä½“æ¨¡å‹ï¼Œä¹Ÿå½’åŠŸäºæ›´å‡ºè‰²çš„ **Context Engineering**ï¼ˆä¸Šä¸‹æ–‡å·¥ç¨‹ï¼Œå³å¦‚ä½•é€šè¿‡æ„å»ºæ›´å¥½çš„æç¤ºè¯å’Œç¯å¢ƒæ¥å¼•å¯¼æ¨¡å‹ï¼‰ã€‚

åœ¨ Cursorï¼Œæˆ‘ä»¬ä¼šä¸ºæ¯ä¸€ä¸ªæ–°æ¥å…¥çš„å‰æ²¿æ¨¡å‹å•ç‹¬ä¼˜åŒ–â€œæ™ºèƒ½ä½“äº¤äº’æ¡†æ¶â€ï¼ˆå³æˆ‘ä»¬æä¾›ç»™æ¨¡å‹çš„æŒ‡ä»¤å’Œå·¥å…·ï¼‰ã€‚ä½†åœ¨ **Context Engineering**ï¼ˆä¸Šä¸‹æ–‡å·¥ç¨‹ï¼‰æ–¹é¢ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€äº›é€šç”¨çš„æ”¹è¿›ç©ºé—´â€”â€”æ¯”å¦‚åœ¨ä¸€ä¸ªæ¼«é•¿çš„ä»»åŠ¡è¿‡ç¨‹ä¸­ï¼Œå¦‚ä½•æ”¶é›†ä¸Šä¸‹æ–‡ä»¥åŠå¦‚ä½•ä¼˜åŒ– Token çš„ä½¿ç”¨æ•ˆç‡â€”â€”è¿™äº›æ”¹è¿›é€‚ç”¨äºæˆ‘ä»¬æ¡†æ¶å†…çš„æ‰€æœ‰æ¨¡å‹ã€‚

éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å……å½“â€œæ™ºèƒ½ä½“â€æ–¹é¢å˜å¾—è¶Šæ¥è¶Šå¼ºï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ä¸ªæœ‰è¶£çš„ç°è±¡ï¼š**å°‘å³æ˜¯å¤š**ã€‚æˆ‘ä»¬åœ¨æœ€å¼€å§‹æä¾›ç»™æ¨¡å‹çš„ç»†èŠ‚è¶Šå°‘ï¼Œæ•ˆæœåè€Œè¶Šå¥½ï¼Œå› ä¸ºè¿™è®©æ™ºèƒ½ä½“èƒ½å¤Ÿæ›´è½»æ¾åœ°è‡ªè¡ŒæŠ“å–ç›¸å…³çš„ä¸Šä¸‹æ–‡ã€‚

æˆ‘ä»¬å°†è¿™ç§æ¨¡å¼ç§°ä¸º **Dynamic Context Discovery**ï¼ˆ**åŠ¨æ€ä¸Šä¸‹æ–‡å‘ç°**ï¼‰ï¼Œè¿™ä¸é€šå¸¸é‚£ç§ä¸ç®¡ç”¨ä¸ç”¨å¾—ä¸Šéƒ½ä¸€è‚¡è„‘å¡è¿›å»çš„ _Static Context_ï¼ˆ_é™æ€ä¸Šä¸‹æ–‡_ï¼‰å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

## æ—¢ç„¶æ–‡ä»¶æ˜¯æœ€å¥½çš„æ¥å£ï¼Œé‚£å°±ç”¨æ–‡ä»¶åšåŠ¨æ€ä¸Šä¸‹æ–‡å‘ç°

**åŠ¨æ€ä¸Šä¸‹æ–‡å‘ç°**åœ¨ Token çš„ä½¿ç”¨ä¸Šè¦é«˜æ•ˆå¾—å¤šï¼Œå› ä¸ºå®ƒåªæŠŠçœŸæ­£éœ€è¦çš„æ•°æ®æ‹‰å…¥ **Context Window**ï¼ˆä¸Šä¸‹æ–‡çª—å£ï¼Œå³æ¨¡å‹ä¸€æ¬¡èƒ½å¤„ç†çš„ä¿¡æ¯é‡ä¸Šé™ï¼‰ã€‚åŒæ—¶ï¼Œé€šè¿‡å‡å°‘ä¸Šä¸‹æ–‡çª—å£ä¸­é‚£äº›å¯èƒ½å¼•èµ·æ··æ·†æˆ–ç›¸äº’çŸ›ç›¾çš„ä¿¡æ¯ï¼Œå®ƒè¿˜èƒ½æé«˜æ™ºèƒ½ä½“çš„å›ç­”è´¨é‡ã€‚

ä»¥ä¸‹æ˜¯ Cursor ç›®å‰åº”ç”¨ **åŠ¨æ€ä¸Šä¸‹æ–‡å‘ç°** çš„äº”ä¸ªå…·ä½“åœºæ™¯ï¼š

1. å°†å†—é•¿çš„å·¥å…·è¿”å›ç»“æœè½¬åŒ–ä¸ºæ–‡ä»¶
2. åœ¨â€œæ€»ç»“â€é˜¶æ®µå¼•ç”¨èŠå¤©è®°å½•
3. æ”¯æŒ Agent Skills å¼€æ”¾æ ‡å‡†
4. é«˜æ•ˆåŠ è½½æ‰€éœ€çš„ MCP å·¥å…·
5. å°†æ‰€æœ‰é›†æˆç»ˆç«¯çš„ä¼šè¯è§†ä¸ºæ–‡ä»¶

## 1\. å°†å†—é•¿çš„å·¥å…·è¿”å›ç»“æœè½¬åŒ–ä¸ºæ–‡ä»¶

å·¥å…·è°ƒç”¨ï¼ˆTool Callsï¼‰å¾€å¾€ä¼šè¿”å›å·¨å¤§çš„ JSON æ ¼å¼å“åº”ï¼Œç¬é—´æ’‘çˆ†ä¸Šä¸‹æ–‡çª—å£ã€‚

å¯¹äº Cursor çš„åŸç”Ÿå·¥å…·ï¼ˆæ¯”å¦‚ç¼–è¾‘æ–‡ä»¶å’Œæœç´¢ä»£ç åº“ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ™ºèƒ½çš„å·¥å…·å®šä¹‰å’Œæœ€å°åŒ–çš„å“åº”æ ¼å¼æ¥é˜²æ­¢ä¸Šä¸‹æ–‡è†¨èƒ€ã€‚ä½†æ˜¯ï¼Œç¬¬ä¸‰æ–¹å·¥å…·ï¼ˆä¾‹å¦‚ Shell å‘½ä»¤æˆ– MCP è°ƒç”¨ï¼‰é€šå¸¸æ²¡æœ‰è¿™ç§åŸç”Ÿä¼˜åŒ–ã€‚

ç›®å‰çš„ç¼–ç¨‹æ™ºèƒ½ä½“é€šå¸¸é‡‡å–çš„ç®€å•ç²—æš´åšæ³•æ˜¯ï¼šæˆªæ–­é‚£äº›è¿‡é•¿çš„ Shell å‘½ä»¤æˆ– MCP ç»“æœã€‚ä½†è¿™ä¼šå¯¼è‡´æ•°æ®ä¸¢å¤±ï¼Œè€Œä¸¢å¤±çš„éƒ¨åˆ†å¯èƒ½æ°æ°åŒ…å«ä½ æ‰€éœ€è¦çš„å…³é”®ä¿¡æ¯ã€‚

åœ¨ Cursor ä¸­ï¼Œæˆ‘ä»¬è¦ä¹ˆæŠŠè¾“å‡ºå†™å…¥ä¸€ä¸ªæ–‡ä»¶ï¼Œç„¶åèµ‹äºˆæ™ºèƒ½ä½“è¯»å–è¯¥æ–‡ä»¶çš„èƒ½åŠ›ã€‚æ™ºèƒ½ä½“å¯ä»¥å…ˆè°ƒç”¨ `tail` å‘½ä»¤æŸ¥çœ‹æ–‡ä»¶æœ«å°¾ï¼Œå¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œå†ç»§ç»­è¯»å–ã€‚

è¿™ä¸€æ”¹å˜å¤§å¤§å‡å°‘äº†å› è¾¾åˆ°ä¸Šä¸‹æ–‡ä¸Šé™è€Œè§¦å‘çš„ä¸å¿…è¦çš„â€œå¯¹è¯æ€»ç»“â€ã€‚

## 2\. åœ¨â€œæ€»ç»“â€é˜¶æ®µå¼•ç”¨èŠå¤©è®°å½•

å½“æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£è¢«å¡«æ»¡æ—¶ï¼ŒCursor ä¼šè§¦å‘ä¸€ä¸ªâ€œæ€»ç»“â€æ­¥éª¤ï¼Œç»™æ™ºèƒ½ä½“è…¾å‡ºä¸€ä¸ªæ–°çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œå…¶ä¸­åŒ…å«ä¹‹å‰å·¥ä½œçš„æ‘˜è¦ã€‚

ä½†æ˜¯ï¼Œæ™ºèƒ½ä½“çš„çŸ¥è¯†ä¼šåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­â€œé€€åŒ–â€ï¼Œå› ä¸ºâ€œæ€»ç»“â€æœ¬è´¨ä¸Šæ˜¯å¯¹ä¸Šä¸‹æ–‡çš„ä¸€ç§ **æœ‰æŸå‹ç¼©**ã€‚æ™ºèƒ½ä½“å¯èƒ½ä¼šå¿˜è®°ä»»åŠ¡ä¸­çš„å…³é”®ç»†èŠ‚ã€‚åœ¨ Cursor ä¸­ï¼Œæˆ‘ä»¬å°†èŠå¤©å†å²è®°å½•ä¹Ÿä½œä¸ºæ–‡ä»¶å¤„ç†ï¼Œä»¥æ­¤æ¥æé«˜æ€»ç»“çš„è´¨é‡ã€‚

![](https://baoyu.io/uploads/2026-01-07/1767756401191.png)

å½“è¾¾åˆ°ä¸Šä¸‹æ–‡çª—å£é™åˆ¶ï¼Œæˆ–è€…ç”¨æˆ·å†³å®šæ‰‹åŠ¨è§¦å‘æ€»ç»“æ—¶ï¼Œæˆ‘ä»¬ä¼šç»™æ™ºèƒ½ä½“ä¸€ä¸ªæŒ‡å‘â€œå†å²è®°å½•æ–‡ä»¶â€çš„å¼•ç”¨ã€‚å¦‚æœæ™ºèƒ½ä½“æ„è¯†åˆ°æ‘˜è¦ä¸­ç¼ºå°‘æŸäº›å®ƒéœ€è¦çš„ç»†èŠ‚ï¼Œå®ƒå°±å¯ä»¥é€šè¿‡æœç´¢è¿™ä»½å†å²è®°å½•æ–‡ä»¶æ¥æ‰¾å›è¿™äº›ä¿¡æ¯ã€‚

## 3\. æ”¯æŒ Agent Skills å¼€æ”¾æ ‡å‡†

Cursor æ”¯æŒ [Agent Skills](https://cursor.com/docs/context/skills#agent-skills)ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡ä¸“ä¸šèƒ½åŠ›æ‰©å±•ç¼–ç¨‹æ™ºèƒ½ä½“çš„å¼€æ”¾æ ‡å‡†ã€‚ç±»ä¼¼äºå…¶ä»–ç±»å‹çš„ [Rules](https://cursor.com/docs/context/rules)ï¼ˆè§„åˆ™ï¼‰ï¼ŒSkillsï¼ˆæŠ€èƒ½ï¼‰ä¹Ÿæ˜¯é€šè¿‡æ–‡ä»¶å®šä¹‰çš„ï¼Œå®ƒä»¬å‘Šè¯‰æ™ºèƒ½ä½“å¦‚ä½•åœ¨ç‰¹å®šé¢†åŸŸçš„ä»»åŠ¡ä¸Šè¡¨ç°å¾—æ›´å¥½ã€‚

Skills åŒ…å«åç§°å’Œæè¿°ï¼Œè¿™äº›ä¿¡æ¯å¯ä»¥ä½œä¸ºâ€œé™æ€ä¸Šä¸‹æ–‡â€æ”¾å…¥ç³»ç»Ÿæç¤ºè¯ï¼ˆSystem Promptï¼‰ä¸­ã€‚ç„¶åï¼Œæ™ºèƒ½ä½“å¯ä»¥ä½¿ç”¨ `grep`ï¼ˆ**ä¸€ç§å¼ºå¤§çš„æ–‡æœ¬æœç´¢å·¥å…·**ï¼‰å’Œ Cursor çš„ [è¯­ä¹‰æœç´¢](https://cursor.com/blog/semsearch) ç­‰å·¥å…·ï¼Œè¿›è¡Œ **åŠ¨æ€ä¸Šä¸‹æ–‡å‘ç°**ï¼Œä»è€Œæ‹‰å–ç›¸å…³çš„æŠ€èƒ½ç»†èŠ‚ã€‚

Skills è¿˜å¯ä»¥æ†ç»‘ä¸ä»»åŠ¡ç›¸å…³çš„å¯æ‰§è¡Œæ–‡ä»¶æˆ–è„šæœ¬ã€‚å› ä¸ºå®ƒä»¬æœ¬è´¨ä¸Šå°±æ˜¯æ–‡ä»¶ï¼Œæ™ºèƒ½ä½“å¯ä»¥è½»æ¾æ‰¾åˆ°ä¸ç‰¹å®šæŠ€èƒ½ç›¸å…³çš„å†…å®¹ã€‚

## 4\. é«˜æ•ˆåŠ è½½æ‰€éœ€çš„ MCP å·¥å…·

MCPï¼ˆ**Model Context Protocolï¼Œæ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼Œä¸€ç§æ ‡å‡†åŒ–çš„è¿æ¥ AI æ¨¡å‹ä¸æ•°æ®æºçš„æ–¹å¼**ï¼‰éå¸¸é€‚åˆè®¿é—®é‚£äº›å— OAuth ä¿æŠ¤çš„èµ„æºï¼Œæ¯”å¦‚ç”Ÿäº§ç¯å¢ƒæ—¥å¿—ã€å¤–éƒ¨è®¾è®¡æ–‡ä»¶æˆ–ä¼ä¸šå†…éƒ¨æ–‡æ¡£ã€‚

ç„¶è€Œï¼Œä¸€äº› MCP æœåŠ¡å™¨åŒ…å«å¤§é‡å·¥å…·ï¼Œä¸”å¾€å¾€å¸¦æœ‰å†—é•¿çš„æè¿°ï¼Œè¿™ä¼šä¸¥é‡æŒ¤å ä¸Šä¸‹æ–‡çª—å£ã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œå³ä½¿è¿™äº›å·¥å…·æ€»æ˜¯è¢«åŒ…å«åœ¨æç¤ºè¯ä¸­ï¼Œç»å¤§å¤šæ•°æ—¶å€™å®ƒä»¬æ ¹æœ¬ä¸ä¼šè¢«ç”¨åˆ°ã€‚å¦‚æœä½ ä½¿ç”¨äº†å¤šä¸ª MCP æœåŠ¡å™¨ï¼Œæƒ…å†µä¼šå˜å¾—æ›´ç³Ÿã€‚

æŒ‡æœ›æ¯ä¸ª MCP æœåŠ¡å™¨éƒ½ä¸ºæ­¤è¿›è¡Œä¼˜åŒ–æ˜¯ä¸ç°å®çš„ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œå‡å°‘ä¸Šä¸‹æ–‡å ç”¨çš„è´£ä»»åœ¨äºç¼–ç¨‹æ™ºèƒ½ä½“æœ¬èº«ã€‚åœ¨ Cursor ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å°†å·¥å…·æè¿°åŒæ­¥åˆ°ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ï¼Œå®ç°äº†é’ˆå¯¹ MCP çš„ **åŠ¨æ€ä¸Šä¸‹æ–‡å‘ç°**ã€‚

ç°åœ¨ï¼Œæ™ºèƒ½ä½“åªæ¥æ”¶ä¸€å°éƒ¨åˆ†é™æ€ä¸Šä¸‹æ–‡ï¼ˆä¸»è¦æ˜¯å·¥å…·åç§°ï¼‰ã€‚å½“ä»»åŠ¡ç¡®å®éœ€è¦æ—¶ï¼Œå®ƒæ‰ä¼šå»æŸ¥æ‰¾å·¥å…·çš„è¯¦ç»†ä¿¡æ¯ã€‚åœ¨ä¸€é¡¹ A/B æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬å‘ç°å¯¹äºè°ƒç”¨äº† MCP å·¥å…·çš„è¿è¡Œä»»åŠ¡ï¼Œè¿™ç§ç­–ç•¥**å°†æ™ºèƒ½ä½“æ¶ˆè€—çš„æ€» Token æ•°å‡å°‘äº† 46.9%**ï¼ˆè¯¥æ•°æ®å…·æœ‰ç»Ÿè®¡å­¦æ˜¾è‘—æ€§ï¼Œä½†æ ¹æ®å®‰è£…çš„ MCP æ•°é‡ä¼šæœ‰è¾ƒå¤§æ³¢åŠ¨ï¼‰ã€‚

![](https://baoyu.io/uploads/2026-01-07/1767756417057.png)

è¿™ç§åŸºäºæ–‡ä»¶çš„æ–¹æ³•è¿˜è§£é”äº†ä¸€ä¸ªæ–°èƒ½åŠ›ï¼šå‘æ™ºèƒ½ä½“ä¼ è¾¾ MCP å·¥å…·çš„çŠ¶æ€ã€‚ä¾‹å¦‚ï¼Œä»¥å‰å¦‚æœä¸€ä¸ª MCP æœåŠ¡å™¨éœ€è¦é‡æ–°è®¤è¯ï¼Œæ™ºèƒ½ä½“å¯èƒ½ä¼šç›´æ¥â€œå¿˜è®°â€è¿™äº›å·¥å…·çš„å­˜åœ¨ï¼Œè®©ç”¨æˆ·ä¸€å¤´é›¾æ°´ã€‚è€Œç°åœ¨ï¼Œæ™ºèƒ½ä½“å¯ä»¥ä¸»åŠ¨å‘ŠçŸ¥ç”¨æˆ·å»é‡æ–°è®¤è¯ã€‚

## 5\. å°†æ‰€æœ‰é›†æˆç»ˆç«¯çš„ä¼šè¯è§†ä¸ºæ–‡ä»¶

Cursor ä¸å†éœ€è¦ä½ æ‰‹åŠ¨å¤åˆ¶/ç²˜è´´ç»ˆç«¯ä¼šè¯çš„è¾“å‡ºå¹¶å–‚ç»™æ™ºèƒ½ä½“ï¼Œè€Œæ˜¯ç›´æ¥å°†é›†æˆç»ˆç«¯çš„è¾“å‡ºåŒæ­¥åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿã€‚

è¿™è®©è¯¢é—®â€œä¸ºä»€ä¹ˆæˆ‘çš„å‘½ä»¤å¤±è´¥äº†ï¼Ÿâ€å˜å¾—éå¸¸ç®€å•ï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿç›´æ¥ç†è§£ä½ æŒ‡çš„æ˜¯ä»€ä¹ˆã€‚ç”±äºç»ˆç«¯å†å²è®°å½•å¯èƒ½å¾ˆé•¿ï¼Œæ™ºèƒ½ä½“å¯ä»¥ä½¿ç”¨ `grep` ä»…æœç´¢ç›¸å…³çš„è¾“å‡ºå†…å®¹ï¼Œè¿™å¯¹äºåˆ†ææœåŠ¡å™¨ç­‰é•¿æ—¶é—´è¿è¡Œè¿›ç¨‹çš„æ—¥å¿—éå¸¸æœ‰ç”¨ã€‚

è¿™æ¨¡ä»¿äº†åŸºäºå‘½ä»¤è¡Œç•Œé¢ï¼ˆCLIï¼‰çš„ç¼–ç¨‹æ™ºèƒ½ä½“çš„ä½“éªŒâ€”â€”æ‹¥æœ‰ä¹‹å‰çš„ Shell è¾“å‡ºä½œä¸ºä¸Šä¸‹æ–‡â€”â€”ä½†ä¸åŒçš„æ˜¯ï¼Œå®ƒæ˜¯åŠ¨æ€å‘ç°çš„ï¼Œè€Œä¸æ˜¯è¢«é™æ€æ³¨å…¥çš„ã€‚

## ç®€å•çš„æŠ½è±¡

å¯¹äºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å·¥å…·æ¥è¯´ï¼Œæ–‡ä»¶æ˜¯å¦æ˜¯æœ€ç»ˆçš„äº¤äº’æ¥å£å°šæ— å®šè®ºã€‚

ä½†éšç€ç¼–ç¨‹æ™ºèƒ½ä½“çš„å¿«é€Ÿè¿›åŒ–ï¼Œâ€œæ–‡ä»¶â€å·²è¢«è¯æ˜æ˜¯ä¸€ç§æ—¢ç®€å•åˆå¼ºå¤§çš„åŸºå…ƒï¼ˆPrimitiveï¼‰ã€‚ç›¸æ¯”äºé‚£äº›æ— æ³•å®Œå…¨é€‚åº”æœªæ¥çš„æ–°é€ æŠ½è±¡æ¦‚å¿µï¼Œæ–‡ä»¶æ˜¯ä¸€ä¸ªæ›´å®‰å…¨çš„é€‰æ‹©ã€‚è¯·ç»§ç»­å…³æ³¨æˆ‘ä»¬åœ¨è¿™ä¸€é¢†åŸŸæ›´å¤šæ¿€åŠ¨äººå¿ƒçš„åˆ†äº«ã€‚

ä¸Šè¿°æ”¹è¿›å°†åœ¨æœªæ¥å‡ å‘¨å†…é¢å‘æ‰€æœ‰ç”¨æˆ·ä¸Šçº¿ã€‚æœ¬æ–‡ä»‹ç»çš„æŠ€æœ¯ç”±ä¼—å¤š Cursor å‘˜å·¥å…±åŒå®Œæˆï¼ŒåŒ…æ‹¬ Lukas Moller, Yash Gaitonde, Wilson Lin, Jason Ma, Devang Jhabakh å’Œ Jediah Katzã€‚å¦‚æœä½ æœ‰å…´è¶£ç”¨ AI è§£å†³é‚£äº›æœ€å›°éš¾ã€æœ€é›„å¿ƒå‹ƒå‹ƒçš„ç¼–ç¨‹ä»»åŠ¡ï¼Œæˆ‘ä»¬éå¸¸å¸Œæœ›èƒ½å¬åˆ°ä½ çš„å£°éŸ³ã€‚è¯·é€šè¿‡ [hiring@cursor.com](https://cursor.com/blog/) è”ç³»æˆ‘ä»¬ã€‚

æ¥æº: <https://cursor.com/blog/dynamic-context-discovery>

hidden text to trigger resize events if fonts change

---

# [äº”æ¡0109] æ¨¡å‹è®¾è®¡å¸ˆï¼šä¸æ­¢äºUIçš„è®¾è®¡æ–°ç‰©ç§
å‘å¸ƒæ—¥æœŸï¼š2026/01/06

with Barron Webster

Hey there, we're [Ryan](https://x.com/Flomerboy), [Federico](https://x.com/federicovillaw), and [Robin](https://x.com/robinconline), a trio designers who have noticed an undercurrent of change in the design world. AI is taking over software, and as it does, the demands on its designers are changing. AI is squishy and has a mind of its own, so designing AI-first products feels less like designing for print or HTML, and more like working with some kind of alien intelligence that crash-landed on Earth. The skills needed by designers are rapidly changing, and every day a new model or tool drops that turns everything on its head.

So we started AI Design Field Guide to serve as both a resource for our peers in the field, and also a time capsule of this unique time where we're all figuring out how this new kind of work is done in real time. Each article is an interview with a designer working in the field who has a unique perspective on what's happening.

Our first interview is with Barron Webster. We knew we had to talk to him first because he's been elbow-deep on AI products for over 8 years (AI years are kind of like dog years). If there's anyone that could see through the hype cycles and into the future, it would be him. Early in his career, he designed [Teachable Machine](https://teachablemachine.withgoogle.com/) at [Google Creative Lab](https://www.creativelab5.com/), the first consumer tool for training AI models. It launched in 2017\. After Google, he joined [Replit](https://replit.com/) to work on their AI features, which were the force that drove them to grow from a startup into a unicorn.

He recently joined [Figma](https://www.figma.com/) as one of the world's first model designers â€“ a new hybrid role for people who want to get their hands exceptionally dirty with LLMs. The emergence of this new role seems like proof of this change we're noticing. So, we thought that unpacking it with Barron was the perfect way to kickstart our conversation about how design is changing in the age of AI.

I sit with the AI research team at Figma, and they hired me for two main reasons. For one, they're reaching a point where they're getting all of the juice that they can squeeze out of the foundation models, and it's not good enough. A lot of Figma's data is in a proprietary format that may never see the light of day, so foundation models aren't particularly good at working with it. Part of my job is bridging that gap.

The other big part is building new tools and AI-first thinking to the design org. You know, Figma's a big company â€“ lots of designers working on parts of the product who haven't designed AI experiences before. Right now, there isn't much tooling, inside or outside, that makes designing those experiences easy, fun, or even possible. AI feature design looks different from traditional product design.

There are steps that designers can take a lot earlier in the process to prototype the core of the AI feature, before getting into the UI. If you're designing UI for something that you haven't played with, the risk is that you're designing UI for a perfect case that isn't representative of how it will work. So one of the things that I'm excited about is building the tools that let designers prototype and play with that part of the process early on without having to become an engineer.

It's like the AI is [Cthulhu](https://swetlana-ai.medium.com/the-shoggoth-meme-hp-lovecraft-meets-ai-60fc44692e98), and the UI is this mech suit. And the goal is to get the designer to understand Cthulhu's anatomy before designing the mech suit so that the mech suit doesn't just explode when Cthulhu puts it on.

The things that I'm most excited about are tools that allow designers to manipulate and run eval cases in a fast feedback loop and in the native format to the material that they're working in. Imagine you're working in a figma file and you try an AI feature and it doesn't work, you should be able to immediately add that as a test case to your evals. What if I adjust the system prompt for the tool that didn't work? What if I try a different model on this one?

Part of the reason that it's so hard right now is that the feedback loop is so slow. Fundamentally, all good design tools remove or shrink the feedback loop. There's a lot of room to improve. I don't know if you are familiar with building your own eval sets, but a lot of it feels like you're doing a lot of manual labor to just shuffle data around.

The other part of the job that I forgot to mention, is thinking about how to make the AI features more differentiated at Figma. It's a design platform. So you'd expect that the outputs will be better designed than, like, [Claude Code](https://github.com/anthropics/claude-code) or [Cursor](https://cursor.com/). How do you ensure that the outputs are of the highest quality? I think a lot of that will look like targeted eval strategies and finding proxies for what we consider good design, which is a really fun and interesting kind of art school, philosophical question.

Yeah, if "design is how it works", increasingly the "how it works" part is governed by the weights of the models that are driving these experiences. So design for these sorts of experiences should involve getting your hands dirty in the model weights.

They were looking for someone to think about this space. I started talking to them this summer, and there were a bunch of problems that I knew that they had, but I don't think it was clear to anyone, including me, which of them was the top priority. I think I'm, to some degree, the canary in the coal mine, which has been fun and chaotic, because I've been jumping from context to context and team to team. It's a huge company with eight different products now, and so there's a lot of stuff happening.

So you've clearly been deep in this space for a while. You're probably one of the designers who's been working with AI the longest â€“ could you share your first introduction to what we now call AI?

There are two points in time that stand out. One was at [RISD](https://www.risd.edu/) around 2014 or 2015, in a class called Computer Utopias by Chris Novello. This was pre-LLM, when machine learning research was more about classifiers. We surveyed modern digital products and technology, and the most exciting things were image classification modelsâ€”the ability to feed data into a model and get pretty good image segmentation and classification. This was driving features like [Snapchat](https://www.snapchat.com/) face filters and Google's image search.

Alongside image models, content moderation and recommendation systems were big. This was the heyday of Facebook, Twitter, and Cambridge Analytica. The idea that you could design a system to show users curated content based on their consumption patterns was a huge shift. From 2013 to 2017, platforms like YouTube, Facebook, and Twitter inventing the algorithmic feed created a new material to design around, moving away from just subscribing to topics or following people. It was a contentious topic at the time, but that was my first theoretical exposure as a student.

The second big moment was from 2016 to 2018 at Google's Creative Lab, working on [Google Lens](https://lens.google/), [Google Assistant](https://assistant.google.com/), and [Teachable Machine](https://teachablemachine.withgoogle.com/). Nearly all our projects applied some form of model innovation. For Lens, it was improved image segmentation and classification. For Assistant, pre-LLM, the innovation was mainly in voice-to-text and text-to-action processing. Teachable Machine was pure image classification. This era was interesting because it wasn't about text generation; it was about using models to sort or annotate stuff that already existed.

You know a lot of people say, I want the robot to do my laundry and dishes, and it's really easy to forget that for the longest time AI was just for processing your content and only recently did it start to write poetry.

Haha, yeah. I remember we even did a promotion about a cucumber farmer in Japan using [TensorFlow](https://www.tensorflow.org/) to sort cucumbersâ€”it's funny because it's just a very practical use case where a simple classifier likely still outperforms an LLM today.

Yeah I guess "multi-modal models." But I also think we're starting to move into a world where users mostly interact with "model systems", with agentic systems or things like Deep Research.

Were there any projects you've worked on over the years that really surprised you or changed how you think about designing for AI? What did you learn?

I spent over three years at [Replit](https://replit.com/), a collaborative web-based programming environment. I was hired partly to evaluate where we could use AI, as they had no AI features at the time. During my three years there, the models kept getting progressively better. So we were constantly looking for ways to add AI functionality that leveraged the models' new capabilities in a way that was both useful to our audience and reliable.

It started with basic, manually triggered features like selecting code for an AI explanation or generating code in an existing file. With each new feature, user expectations rose. We were on this cycle of trying to meet their desires, where each release showed them a future they thought should be possible, but the models weren't quite there yet. For instance, when we allowed generating code snippets, users asked for entire files or projects. Once we could do that, they wanted specific edits. Then, they wanted to start from scratch.

We knew what kinds of features we wanted to support and would try them with existing models. If it didn't work, we'd pause. When new foundation models came out, we'd try again.

Programming environments have specific product constraints. Even if a model is great at writing code, you have to figure out how to get it to edit code in the right place. I remember until around [Sonnet 3.5](https://www.anthropic.com/claude/sonnet) came out, models weren't good with line numbers. We had to devise hacky ways to ensure edits were correct, didn't duplicate content, or properly replaced functions. These weren't AI innovation problems per se, but product scaffolding issues to handle model limitations. In hindsight, much of that work was only relevant for six months to a year until a new model obviated it.

That resonates with me. There's this question of "Should we build this feature that's technically possible today but would be obviated by a model release in a few months, or should we build some other feature which just gets better as the models do. It seems like a part of AI design is this dance of testing out new models, prototyping with them, seeing what's possible, what's not, thinking about which features will stand the test of time. Was there anything you did that stood out to you as particularly impactful? It's not typical design work you do in Figma.

A big part of what design and research are doing now is ensuring the team stays focused on the right thing. It's easy to start building a feature, encounter technical hurdles, solve them, find more, and end up with something technically functional but overly complicated for the user or drifted from the original goal.

A concrete example is when we were working on the Replit agent, which automatically created files and wrote code. A huge technical problem was getting the agent to test the applications it built. For instance, verifying if a login page worked. The engineering side saw this as a cool technical problem: spin up a sandbox, build screenshot functionality, feed screenshots to a multimodal model to decide where to click and typeâ€”essentially pseudo-computer use by the model. It's satisfying to go down that rabbit hole.

However, myself and another engineer proposed: what if we just showed the user the website and asked them to test it? We offloaded validation and testing to the user, skipping that entire complex technical problem. Having someone in the room focused on the user problem, not just the technical one, can help you skip or simplify many things, even if the solution is less technically exciting.

Yeah, that's a good example of stepping back and asking 'do we actually need to solve this?' I imagine it's hard to know where to draw that line of which tasks to automate, eval, and test, and which ones to leave up to the user to figure out. If you'll allow another analogy - creating AI products is kind of like making little robot assistants that are going out into the world and we don't know what people will ask them to do. Should we make sure they can handle someone who changes their mind halfway through? Or someone who asks three questions at once? Should we make sure they know the heimlich maneuver? How did you navigate those decisions of what needed to be tested and what didn't?

At Replit, while there were subsets of users, we generally knew what our platform was capable of and what users wanted. So, we focused on features that helped them achieve their goals faster with AI, compared to typing all the code themselves.

Building an AI product from scratch today is harder. Traditional startup wisdom is to start niche, find 100 users who love your product, then expand. General chatbots like [ChatGPT](https://chat.openai.com/) have seen success with the opposite approach, build a general interface that can be used for anything andâ€¦ see what happens. That might be a one-time fluke due to the new technology. If I were building an AI product now, I probably wouldn't start by targeting a general use case unless I had a significant technical or distribution edge, like [Meta](https://ai.meta.com/) has with [Llama](https://llama.meta.com/).

This evolved... For our first AI feature, code explanation, it was just me and one engineer, pre-[LangChain](https://www.langchain.com/) and widespread evals. We tested it like other platform features: launch internally, have staff use it (most Replit staff are programmers, so they were good evaluators), make adjustments, then launch to a small volunteer group of users (maybe 1-5% of the user base).

We'd interview these users, pull analytics to see who used it most and retained, and talk to those who tried it once and stopped. This is a traditional agile startup approach: incremental rollouts, user conversations, willingness to roll back. For code explanations, judging "good enough" was subjective. Staff would review explanations for correctness.

Once AI started authoring code, tracking success became easier. We looked at signals: Did the user accept the AI-generated code (shown temporarily before insertion)? Did the inserted code cause lint errors? Did they revert or delete the code soon after? The programming space is fortunate because it's easier to validate if something works; you can run the program or it doesn't. It's trickier with, say, an email authoring tool where success is less binary.

Beyond the quantitative metrics that assessed the performance of those features - did you have other ways of detecting product-market fit? How did you know if the features were solving problems for users or not?

Yeah, pre-AI product strategy was quite different. You'd have plans, an existing user base, and you'd strategize abstractly about expanding markets or categories. With AI's rapid changes, our strategies at Replit were much more reactive.

For example, when I started, we focused on education due to strong product-market fit, especially post-COVID for remote teaching. But as AI features improved, we faced a dilemma: indie developers and hackers loved the AI, while teachers often disliked it because students could bypass learning fundamentals.

This happened a couple times, we found product-market fit more organically than strategically. When we released the Replit agent, our last major AI product, we didn't really know who it was for. It felt more reactive than some of our top-down projects like enterprise plans and teams. The more successful projects were ones where we just shipped features and saw what happened.

Later on, we discovered its usersâ€”often ops people at tech companies needing to ingest sales data or build dashboards, similar to [Zapier](https://zapier.com/) or [Retool](https://retool.com/) usersâ€”by releasing the tool and then talking to those who adopted it.

Probably now, they have a more strategic approach, now that Replit Agent has found a fair amount of product-market fit.

It does feel like it goes against the conventional wisdom. "Build it and they will come" is usually seen as something that doesn't happen, but it seems to keep on happening! It's a humility check for designers, isn't it? Engineering is kind of eating into lower-level design work. Design is moving up the chain. Design used to be about - how does the feature work? But more and more, the models are in charge of how the product works, and designers are more like - where do we focus?

Yeah or like, how do we expose that. In the last era of technology, a lot of the tech was fundamentally pretty simple CRUD, and design played a role in figuring out how to scaffold information to solve a specific problem for the user. But today, it feels like a lot of the questions are just like - is this going to work at all?

That makes me wonder - is that just a reflection of how new we are as a discipline? Like if we're basically saying "we don't know what's going to work until the end" maybe that points to a lack of tools or methodologies.

Well, speaking of "is this going to work at all" - what about evals? Did those play a key role in your decision making?

For the first two years at Replit, we didn't do many evals. The practice wasn't really widespread. With the agent, we leaned into them more, but primarily as indicators for product development rather than for validating our own products. For instance, when a new model comes out (e.g. [Llama 3](https://llama.meta.com/)), we'd look at its performance on programming evals to decide if we should test it in our app.

More recently, at [Sandbar](https://sandbar.inc/), I spent a lot of time writing evals, particularly for model personality. There are broad industry benchmark evals for basic stuff like, not saying anything offensive, but building specific evals for things your product uniquely cares about is part of this new design work. The workflow was heavily:

If we didn't have evals, we'd have to do a lot more manual labor to verify the AI is working well. Evals are a faster way to test if you're meeting desired characteristics. For example at [Sandbar](https://sandbar.inc/), we cared that if the model didn't know an answer, it should ask a single, specific clarifying question rather than hallucinate. We had an eval for that. We had others: don't ask more than one question at a time, keep answers concise (with exceptions).

The tricky thing about evals too is, at least in my experience, a lot of the time, the cause of poor eval results isn't necessarily poor performance, but a badly written eval. Like if you had an eval saying the model should be very concise, and the user says "oh my mom died" and the AI says "That sucks" maybe that would result in a great eval score "Very concise! 10 out of 10!", but maybe that's not actually what you want as a user in that situation. Maybe it should say "Oh I'm sorry for your loss" even though that's not as concise.

So there's this question of, how much of your time do you spend writing good evals. Evals are kind of like the vital signs of seeing a doctor. Like does this person need to go to the ER?

Yeah I mean in our case, we would have an eval covering empathy too, so you want to have a set of evals covering all the things you care about, not just some of them. For us, evals were primarily for avoiding regressions. We had characteristics we wanted to meet, and if a model or prompt change caused a regression, evals signaled where to massage the system to get back to baseline. I think of it like test coverage in programming.

It's interesting, in traditional programming there's this idea of test-driven development where you write the tests first, and then write the code that needs to pass the tests. I haven't seen the equivalent of that very much in AI engineering, where you write the evals first. I think I've seen a couple papers but not in production.

There might be a future job like, eval designer, which is like a design systems role that designs dashboards for the rest of the team to understand how the AI is performing.

It's a bit like a service design orientation. Imagine you were designing a hotel experience, and you have to decide, how are we going to assess our staff? Is it primarily about how friendly they are, or how proactive?

Totally. Barron, can you speak to times where you've tried things and maybe they don't hit the acceptance marks that you guys are looking for. How did you decide when a feature wasn't good enough to look to ship, versus, let's just go with it and we can tune it as we go.

One of the main things was sycophancy. This was probably one of the hardest things to write evals for - the idea that the model should push back on you in cases where you know you could use it. Some of the time, it's at that point it becomes more of a product and design decision to orient the team on what an acceptable failure rate is, and that becomes part of the design philosophy of your product.

Also, it's easy to feel like, Oh, we did all this testing, it didn't work, and then the new model came out and it was fixed. Was that time wasted? At the same time I'd say - don't sell yourself short on the work that was done to understand the feature, what makes it good or bad, such that when the new model did drop and you tested it, you had conviction that hey, this is good enough.

Yeah. I think at Replit and Figma so far, the idea of sycophancy doesn't really make its way into the product very often. At [Sandbar](https://sandbar.inc/), it's a very open-ended conversational interface as the backbone of the product, and in that sense, a philosophical experience we wanted to avoid was continually agreeing with the user and feeding their ego.

At Figma, one idea we've been thinking about is "design critique as a service"â€”you ask an AI to critique your designâ€”and that raises interesting questions about the personality of that system. Is it something you opt into, like choosing a "[Dieter Rams](https://en.wikipedia.org/wiki/Dieter%5FRams)" attitude, or do we have a default? And do we focus on accessibility or contrast issuesâ€”more objective feedbackâ€”or aim for something broader? I'm not sure how much that will make its way into the actual product experience.

How would you like the Evals field to evolve overall? Like, what would be really helpful for you as someone practicing in a field that's so new? Is it like an open tool where people can post eval sets or parameters that they're setting? And do you think the industry needs that? Right now it seems like a lot of stuff is proprietary.

The kinds of tools I find myself wishing for, and hopefully can work on at Figma, are ones that reduce the iteration speed for creating evals. It's so painful right now, and I feel like everyone that's working on evals, like, has to basically do this work. How do I map it? What's the format? What pipeline is it running in? And, like, hooking the output of the pipeline up to an interface where you can see everything in one place. There are tools out there that are, like, pretty good at this for text, but not so much for other formats. There are some interesting platforms out there that are like pseudo evals, like [Design Arena](https://www.designarena.ai/), or, like, I forget what the other one isâ€¦

Yeah. Those are cool. Maybe they're other interesting formats like that, which designers can get involved with. I would love to be able to do something similar but directly in figma files, including commenting on issues and stuff. I want to be able to quickly create sets of tests that I want to run, kick them all off, get like 100 responses, and do it again in like 30 seconds. We have all of those pieces kind of working, but it takes way too long to do all of them.

You know how, like, an architect can look at a building and guess what software it was designed in? I'm just realizing that Barron is essentially creating the fingerprint of like, the next era of web design. Whichever evals you pick, people will be able to guess that it's a figma-AI-created websiteâ€¦

I think that's an interesting tension for all of AI design - how much do we want to assert our own point of view as the tool-creator versus adaptive to what the user wants. If the user is really going for a web 1.0 aesthetic with green text on a red background, should the system lean into that and match it, or should it adhere to our idea of what good design is?

Shifting gears a bit, besides the work of building products with AI in them, there's also the process of designing the model itself. In a sense, LLMs are a new kind of "computer", with much of the "programs" being in the weights of the model itself. When it comes to actual model creation, how do you think a designer can create the most value?

I've experienced two main ways â€“ fine tuning vs. training from scratch. If you're training a model from scratch, a designer's biggest impact is pointing the organization to where user needs are greatest and pain points are most acute. Then, work with engineering to find the right approach. At Replit, we trained a custom model on Python for common, simple code errors because we saw significant user frustration there. The design and research input was highlighting these user problems. We were less involved in the actual training, more in defining the problem and then figuring out how to apply the trained model in the product.

The other approach is fine-tuning an existing model. If you have an existing model, product, and evals, and you want to drive performance upâ€”and you're the one writing prompts, evals, and talking to usersâ€”you'll have a clear sense if it's meeting expectations. If prompt engineering runs out of steam, fine-tuning might be the next step. This isn't exclusive to designers, but they are often well-positioned to make that call.

A key design translation layer is remembering user assumptions. Engineers and designers working closely with models can forget that users don't know the intricacies, like reminding a model it's working in an HTML file for better output. Designers should engage their "inner doofus" and communicate what a naive user, unfamiliar with AI model quirks, might try and where they'd get stuck.

Hearing you speak reminds me of the importance of comfort with ambiguity. It's always been important, but now it feels even more important. Like, it used to be that there were infinite problems and you had to figure out the one experience that could solve that problem, but now our products are also infinitely dynamic experiences. It's not TurboTax where the user sees the same thing every time.

What other kinds of advice would you give to someone starting a new role where they're designing AI products for the first time?

The most sustainable and impactful thing is to invest significant time upfront to truly understand what goes into the model and what comes out. What's its prompt? What user information is fed in? What tools can it call? What evals are in place? Get an intuitive sense for what happens when you adjust these dials.

You don't want to be just the UI maker for an output you don't deeply understand. If engineers and PMs come to you saying, "The model gives you this, design an interface around it," you can do that, but you won't be able to propose meaningful improvements based on user insights. You'll also be working very reactively to subsequent model changes. You want to be part of the decision about whether a new capability is even something you want, not just on the receiving end.

Getting into that nitty-gritty can be challenging, especially for designers not code-literate. Your company might have interfaces like [Langsmith](https://www.langchain.com/langsmith), or you might need to learn to run the development environment yourself. It's a hard task, but crucial.

It kind of ties back to your advice to designers to review how the system works so that they can understand it. The time where you felt like you created the most value was when you were able to take a step back and, understanding the whole system, point out a simpler way to meet the users' needs.

Another example, though not a product per se, was the [LaMDA](https://blog.google/technology/ai/lamda/) launch (Google's early LLM). A lot of our time was spent just playing with the model, trying to prompt itâ€”though we didn't call it "prompting" thenâ€”to get it to pretend to be different things and perform reliably. The demo we chose, where you could talk to Pluto or one of its moons, was purely a function of trying countless things and seeing what performed best. We couldn't have strategically picked that without extensive, hands-on experimentation to discover the model's strengths.

It seems like "Should designers prompt" is different in kind to "should designers code". Ultimately, with coding, the answers to those questions are pretty falsifiable - can we build XYZ with ABC technology? Asking an engineer the question is pretty equivalent to knowing the answer yourself. AI model behavior is inherently more subjective and nuanced. There's no substitution for understanding that material yourself at a deep level.

Barron, do you miss designing? From what we know of you, you've gone through doing evals, engineering. I'm curious in these last roles that you've had, do you still see this craft that you're taking on as a form of design? Do you still mock stuff up? Do you miss the craft part of aesthetics and structure?

It's a good question. I do think of it as designâ€”it's just a very different form of it. You're designing behavior, and you may never get it perfect, which is fine. That's a different mindset from UI design, where you have full control over every pixel and perfection is rewarded.

I still mock things up and play with design tools. At Figma, I make eval cases, go through outputs, and fix what feels off. It's almost therapeuticâ€”like a fidget spinner. Give me a website mockup and thirty minutes to fix the typography, and I'm happy. I still get doses of that kind of work, but it feels different nowâ€”and it's the kind of work that's never really done unless the feature gets removed, because you can always keep improving it.

## Hot Takes

One thing I've been thinking aboutâ€”if I hadn't joined Figma, I was probably going to try to raise money for this. The idea I want someone to build, whether it's me or someone else, is this: the better all these AI tools get, the less information I can retain. I want a system that keeps my brain in shape, because you're offloading all these things to an AI. There are a lot of things you won't be practicing as frequently, or even doing manually. I definitely feel this way using Cursor. I get so much more done in a day than I would have two years ago. But if you ask me in a month how any of these algorithms work, I probably won't be able to answer you. Two years ago, it would have taken me a month to get done what I can do in a weekend now. But I would have learned it through pain, and retained it a lot more.

I don't really have a super strong opinion on that, actually, which is unfortunate. I feel like I've ceded thinking about that, because it's too -- if I start figuring out that, I'm like, Why do I even have a job? You know? There's certain stuff that I, like, deliberately ignore.

I think that it will look very different in five years than it does today, in the same way that I think that designers jobs, especially software designers jobs, have been less directly impacted by AI up until this point, in comparison to software development. If you think about the way that some software developers work now that are in the bleeding edge, they might have three different features they're working on all at the same time, and they're kicking off agents and reviewing their work, and cycling between them. That is not a product experience that exists for design right now. So, yeah, I think that it will look very different. I do hope that designers don't get left behind. A lot of the behavior of AI systems by default falls to the engineers, because they are the ones that have the tools to manipulate the system directly, they're the ones 

---

# [äº”æ¡0112] AI è®¾è®¡ææ•ˆï¼šæ¸è¿›å¼æŠ«éœ²
å‘å¸ƒæ—¥æœŸï¼š2026/01/09

![](https://miro.medium.com/v2/resize:fit:1400/1*0JeBTq5Y1v1hu7JuUnVq_w.png)

Progressive disclosure is a well-known principle in UX design. This principle is about _showing users only what they need right now_, and _revealing more options or information gradually_ as they interact or gain context. The goal is to reduce cognitive load, keep interfaces clean and approachable, and still support advanced use cases when needed.

The principle of progressive disclosure can be applied not only to the user interfaces we design, but also AI tools we use. In this article, I will show you how to use progressive disclosure to maximize the efficiency of your AI tools.

## Why use progressive disclosure?

Before we dive into how-to, itâ€™s important to answer a key question: â€œ_Why do we want to use progressive disclosure in the first place?_â€ The reason for using the principle is pretty much the same as for UX design: to keep context clean and relevant to the task at hand. And by â€˜_context_â€™ I mean the context window that the AI tool uses when it processes your task.

> Context window is the maximum amount of information an AI model can â€œseeâ€, remember, and reason over at one time, including your prompt, instructions, conversation history, and any pasted documents.

Think of context window as the AIâ€™s working memory.

There are two main problems with the context window:

* _Limited size._ Context window has a limited number of tokens. For example, Claude 4.5 has a standard context window of 200,000 tokens (approximately 150,000 words or over 500 pages of material). Once you exceed this limit, older or extra information is ignored, truncated, or summarized, which can directly affect output quality.
* _Too much noise._ The context window can be populated with irrelevant data over time. AI will use all the data you provide when generating output, and if you have a lot of irrelevant data, it will lead to poor quality output (this is known as â€œgarbage in, garbage outâ€).

Progressive disclosure can help with both problems.

## How to use progressive disclosure

I will demonstrate how to use progressive disclosure using NotebookLM for user research of a digital product.

![](https://miro.medium.com/v2/resize:fit:2000/1*i69rXwwFtYAPqypsfxX07g.png)

NotebookLM for user research of a product called FocusFlow.

### Get rid of noise

Information that isnâ€™t needed for the task at hand shouldnâ€™t be included in the context window. This is the most important rule to follow when using AI tools. When it comes to user research in NotebookLM, it means 4 things:

**\[1\]** _Isolate context windows._ If youâ€™re doing two different research tasks isolated from each other, the worst thing you can do is to mix two context windows. The rule of thumb is to keep _one notebook per project._ This will help both you and AI navigate the research field.

**\[2\]** _Maintain a manageable number of sources_. NotebookLM allows you to upload up to 300 data sources (ie, interview transcripts, product analytics, specs). Although this number looks impressive, some teams have a much larger collection of data sources, and they struggle to add them to the system. If you have this problem too, my advice is to moderate your data sources. Many times you can combine a few sources together and, what is even more important, get rid of outdated data sources.

**\[3\]** Structure your data sources (make sure you use a structure that helps you quickly figure out what this data source is and whether you need to use it for your task at hand). I typically use Metadata headers for my files that contain essential information about the data source. Below is an example of metadata for the interview transcript:

Participant_Name: Jane Smith  
Participant_Role: Senior Sales Designer  
Company_Type: B2B SaaS (50â€“200 employees)  
Interview_Type: Generative / Discovery  
Date: 2026-01-05  
Interviewer: Nick  
Context: Exploring user pain points  

**\[4\]** When youâ€™re solving a specific research task, choose only sources that are relevant to this task (donâ€™t use Select All)

![](https://miro.medium.com/v2/resize:fit:1392/1*TGLtZLBiIRPaOhRlRfsVMQ.png)

Select all sourcesâ€ is a menu with all data sources that NotebookLM uses to answer your question. You have complete control of what sources should be used (can add/remove any sources from this list).

### Provide clarity for AI not only on what should be done, but also how it should be done

Just like a real human researcher benefits from a well-defined research process, tools like NotebookLM demonstrate the best results when you clearly outline the process that the tool should use when analyzing data.

Itâ€™s worth having NotebookLM validate the output it generates against the checklist you provide. For example, you can submit the following checklist to AI and ask it to double-check the output it generates for you using this checklist:

Data Provenance & Input Quality  
  
â¬œ Are all source inputs clearly listed (interviews, surveys, reports, transcripts)?  
â¬œ Are sources first-hand research (not assumptions or secondary blog posts)?  
â¬œ Is the data recent enough to be relevant?  
â¬œ Are participant counts, roles, and contexts explicitly stated?  
  
Traceability (Insight â†’ Evidence)  
  
â¬œ Can each insight be traced back to specific quotes, observations, or data points?  
â¬œ Are direct user quotes included where appropriate?  
â¬œ Are insights separated from interpretations?  
â¬œ Are assumptions clearly labeled as assumptions?  
  
Confidence & Uncertainty Markers  
  
â¬œ Does the output acknowledge data gaps?  
â¬œ Are confidence levels or sample limitations stated?  
â¬œ Are hypotheses clearly marked vs validated insights?  
â¬œ Are recommendations framed as testable assumptions?  

This is particularly helpful for complex research tasks that cover a very valuable area of your product design (where your decisions will have high risk).

### Use the right AI-friendly data formats

Data formatting is perhaps one of the most overlooked topics in AI-powered product design. All too often, we use data in its original, raw format. But this is not optimal for AI as data formats impact token count (and size of context window) and efficiency of AI (i.e., tools like Claude demonstrate better results when data is structured in XML format).

When it comes to user research, I suggest using the following data formats:

**YAML.** This is the most token-efficient data format. It works really well for data analytics results. For example, you can submit the following YAML file as a data source for your website analytics.

analytics_report:  
  service_name: "NexusTask Web Dashboard"  
  environment: "Production"  
  reporting_period:  
    start_date: 2025-12-01  
    end_date: 2025-12-31  
  
user_engagement_metrics:  
  monthly_active_users (MAU): 125400  
  daily_active_users (DAU): 18200  
  stickiness_ratio (DAU/MAU): 14.5%  
  avg_session_duration: "00:08:45"  
  bounce_rate: 32.4%  
  
traffic_sources:  
  - channel: "Organic Search"  
    sessions: 45000  
    conversion_rate: 3.2%  
  - channel: "Direct"  
    sessions: 32000  
    conversion_rate: 5.1%  
  - channel: "Referral"  
    sessions: 12000  
    conversion_rate: 2.8%  
  - channel: "Social Media"  
    sessions: 8500  
    conversion_rate: 1.5%  
  
user_behavior_funnel:  
  stage_1_landing: 100000  
  stage_2_sign_up_page: 25000  
  stage_3_account_created: 5000  
  stage_4_first_action_completed: 3200  
  overall_conversion_pct: 3.2  
  
device_distribution:  
  desktop: 72%  
  mobile_web: 25%  
  tablet: 3%  

**Markdown.** Great format for documentation and foundational research rules. We can use this format for data sources like product specification.

# Product Specification: User Analytics Dashboard v2.0  
  
## 1. Document Overview  
| Field | Details |  
| :--- | :--- |  
| **Project Owner** | Product Team |  
| **Status** | In-Review |  
| **Last Updated** | 2026-01-09 |  
| **Target Release** | Q1 2026 |  
  
---  
  
## 2. Product Vision  
To provide our B2B customers with real-time visibility into how their end-users are interacting with the web service, specifically focusing on retention and conversion friction points.  
  
## 3. Core Features  
  
### 3.1 Real-Time User Activity Feed  
* **Description:** A live stream of events (page views, button clicks, sign-ups).  
* **Requirement:** Events must appear in the dashboard within < 2 seconds of occurrence.  
* **Logic:** Uses a WebSocket connection to the analytics engine.  
  
### 3.2 Automated Funnel Visualization  
* **Description:** Allow users to define a 3-5 step path and see drop-off rates.  
* **User Story:** *As a Product Manager, I want to see where users stop during the onboarding process so I can optimize the UI.*  
  
### 3.3 Cohort Analysis Table  
* **Description:** A heatmap showing user retention over a 6-week period.  
* **Data Source:** `user_sessions` and `retention_logs` tables.  
  
---  
  
## 4. Technical Requirements  
  
### 4.1 Data Schema  
The analytics module must ingest data in the following format:  
* `user_id`: UUID  
* `event_type`: String (e.g., "click", "page_view")  
* `timestamp`: ISO 8601  
* `metadata`: JSONB  
  
### 4.2 Performance Constraints  
* Dashboard must load within **1.5 seconds** for date ranges up to 30 days.  
* Exporting data to CSV should handle up to **100,000 rows** without timing out.  
  
---  
  
## 5. User Interface (UI) Design  
* **Theme:** Light/Dark mode compatibility.  
* **Charts:** Use `Recharts` library for responsive SVG rendering.  
* **Navigation:** Accessible via the sidebar under the "Insights" tab.  
  
---  
  
## 6. Success Metrics (KPIs)  
1.  **Dashboard DAU:** Target 40% of all admin users.  
2.  **Export Frequency:** Target at  

And finally, XML. This format works exceptionally well for Claude as it was optimized to recognize content containers. When it comes to using NotebookLM, we can use this format not for the data but for prompts (i.e, when conducting additional research in context of the existing notebook).

<research_mission>  
    <persona>  
        Act as a Senior Research Analyst and Strategic Consultant. Your goal is to synthesize the provided sources into a high-level intelligence briefing that identifies non-obvious patterns, conflicting viewpoints, and actionable insights.  
    </persona>  
  
    <objective>  
        Conduct a "Deep Dive" analysis of the uploaded documents to uncover the core thesis of the collection, the strength of the evidence provided, and the specific gaps where the documents fail to provide a complete picture.  
    </objective>  
  
    <methodology>  
        <step>1. Cross-Reference: Identify where multiple sources agree on a key trend or fact.</step>  
        <step>2. Conflict Analysis: Highlight any contradictions or differing perspectives between authors/documents.</step>  
        <step>3. Evidence Weighting: Evaluate which claims are supported by hard data versus those based on anecdotal evidence.</step>  
        <step>4. Narrative Synthesis: Create a cohesive timeline or conceptual map of the subject matter.</step>  
    </methodology>  
  
    <output_configuration>  
        <format_requirements>  
            - Use Markdown headers for readability.  
            - Provide inline citations for every major claim using the [1], [2] format.  
            - Include a "Surprise & Insight" section for unexpected findings.  
            - End with a "Critical Gaps" section identifying what the sources DON'T tell us.  
        </format_requirements>  
  
        <structure>  
            ## Executive Summary  
            [Provide a 3-sentence high-level overview]  
  
            ## Key Pillars of Research  
            [Detail the 3-4 most significant themes found across all sources]  
  
            ## Comparative Analysis Table  
            [Create a table comparing how different sources approach the primary topic]  
  
            ## The "So What?" Factor  
            [Explain the real-world implications of these findings]  
  
            ## Critical Gaps & Missing Data  
            [What questions remain unanswered by these specific sources?]  
        </structure>  
    </output_configuration>  
  
    <constraints>  
        - Do not use outside knowledge; stay strictly "grounded" in the provided sources.  
        - If a source is ambiguous, state that it is ambiguous rather than making an assumption.  
        - Maintain a professional, objective, and analytical tone.  
    </constraints  

You can submit it in the prompt window in the left-hand panel:

![](https://miro.medium.com/v2/resize:fit:1400/1*1I1ZInJxA5_F_p_Z--UoMA.png)

## Want to learn more about AI-powered product design?

Enrol in my course, â€œ[Product Design with AI](https://maven.com/babich/product-design-ai),â€ a 4-week, live cohort-based course where youâ€™ll learn how to use AI tools to streamline your product design workflow, go from idea to ship-ready product, and become an AI-powered designer alongside a peer community and expert guidance.

[Product Design with AI by Nick Babich on Maven](https://maven.com/babich/product-design-ai?source=post%5Fpage-----978da0aaeb08---------------------------------------)

hidden text to trigger resize events if fonts change