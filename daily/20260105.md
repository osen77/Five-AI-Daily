# [五条0105] Claude Code之父揭秘：高手的工作流
发布日期：2026/01/03

[See all posts](https://baoyu.io/translations)

Boris Cherny 在 Anthropic 内部有个绰号：Claude Code 之父。他最近在 X 上很活跃，于是很多人问 Boris：你自己到底怎么用 Claude Code？他刚在 X 上分享了 9 条实战技巧。

没有你想象的那么多技巧，每一条都朴实无华。

【1】核心理念：Claude Code 的最佳实践并没有标准答案

Boris 开场就说：

> My setup might be surprisingly vanilla! Claude Code works great out of the box, so I personally don't customize it much. 我的配置可能出乎你意料地“原装”。Claude Code 开箱即用效果就很好，我个人没做太多定制。

也能理解，那些最佳实践，比如 Skills、Plugins，作为 Claude Code 开发者，他们早就作为功能内置了。

使用 Claude Code 没有唯一正确的方式。团队故意把它设计成可以随便折腾的样子，你想怎么用、怎么改、怎么魔改都行。Claude Code 团队内部每个人的用法都完全不同。

所以没必要去费力找“最佳实践”，适合自己的节奏最重要。

【2】多 Agent 任务并行：同时开十几个 Claude

![](https://baoyu.io/uploads/2026-01-02-1767391980628-22c0e3a5-6b11-46c1-891b-f0bdba1278b6.png)

Boris 的日常是这样的：终端里开 5 个 Claude Code 实例，标签页编号 1 到 5，开着系统通知，哪个需要输入就跳过去处理。

![](https://baoyu.io/uploads/2026-01-02-1767392000913-0edf6bd2-47ea-4baf-ab5a-f2b1ca6df605.png)

同时，他还在 claude.ai/code 网页版上跑 5 到 10 个任务。终端和网页可以互相“交接”：用&符号把本地会话转到网页，或者用--teleport 在两边来回切换。

他每天早上和白天会从手机 Claude 应用上启动几个任务，晚点再回来看结果。

这种“多线程”工作方式的核心逻辑是：Claude Code 擅长自主执行，很多任务不需要你盯着。你启动任务、给个方向，让它跑着，自己去忙别的。等它需要你确认的时候再切回来。

这跟传统的“人敲一行代码、AI 补几行”完全是两种节奏。但这也对使用者有更高的要求，你需要擅长给 Agent 分配任务，并且能随时在多个任务之间切换。对于习惯了自己开发，同时只有一个任务进行的传统开发模式来说，是个很大挑战。

惭愧的说，虽然我也常用 Coding Agent，还是不习惯太多任务同时运行，今年要加强这方面的练习。

【3】模型选择：为什么用 Opus 而不是更快的 Sonnet

Boris 说他所有任务都用 Opus 4.5 加上 thinking 模式。这是他用过最好的编程模型。

有人会问：Opus 不是比 Sonnet 更大、更慢吗？Boris 的回答是：虽然单次响应慢一点，但你需要纠正它的次数少得多，工具调用也更准确，最终算下来反而更快。

这点其实我一直很认同，写代码这种事不能求快，还是得质量高，如果一个快模型需要你来回纠正三次，不如用个慢模型一次搞定。时间不只是模型响应时间，还有你的注意力和精力成本。

唯一的问题就是 Opus 成本更高。

【4】CLAUDE.md：团队共享的“项目记忆”

CLAUDE.md 是 Claude Code 的一个特殊配置文件，放在项目根目录。每次启动 Claude Code，它会自动读取这个文件，把里面的内容当作“背景知识”。你可以理解为：这是你给 AI 写的项目说明书，告诉它这个项目的架构、规范、注意事项。

![](https://baoyu.io/uploads/2026-01-02-1767392047324-97ba2ffe-3389-499a-97c7-bdbc17cd03f6.png)

Boris 团队的做法是：整个 Claude Code 仓库共用一个 CLAUDE.md，提交到 Git 里，所有人一起维护。每周都有人往里加东西。规则很简单：每次看到 Claude 做错了什么，就把“别这样做”写进去，下次它就知道了。

![](https://baoyu.io/uploads/2026-01-02-1767392115435-782996b2-9e0d-4b34-a234-994dc1f56150.png)

更有意思的是，他们在代码审查时也会用到这个机制。Boris 会在同事的 PR 里@.claude，让 Claude 把某条新规则加到 CLAUDE.md 里。这是通过 Claude Code 的 GitHub Action 实现的。

Dan Shipper 管这种做法叫“复利工程”：每一次纠错都变成团队资产，让 AI 越来越懂你们的项目。

如果你还没用过 CLAUDE.md，或者没像他们这样频繁更新规则，强烈建议试试。最简单的起步方式是运行/init 命令，Claude 会自动分析项目结构，生成一个初始版本。然后你边用边补充，看到不对的地方就加进去。

【5】Plan 模式：先想清楚再动手

![](https://baoyu.io/uploads/2026-01-02-1767392129337-1b3fbe50-0d62-42a3-9544-5ae5e4001652.png)

Boris 说，他大多数会话都从 Plan 模式开始。在 Claude Code 中按两下 Shift+Tab 就能切换。

Plan 模式下，Claude 不会直接改代码，而是先给你一个执行计划。你可以来回讨论、修改计划，直到满意为止。然后切到自动接受模式，Claude 通常能一次性完成。

“好的计划真的很重要”，这个习惯其实是把软件开发的经典智慧搬到了 AI 协作里：先设计再编码。很多人用 AI 写代码的问题是直接开干，结果方向错了返工成本很高。花几分钟对齐计划，能省几小时的返工。

【6】自动化重复工作：斜杠命令和子 Agent

![](https://baoyu.io/uploads/2026-01-02-1767392144770-9e0c6563-7b90-4317-b18b-b0041c8aa0bd.png)

Boris 有几个每天要用几十次的操作，他把它们做成了斜杠命令。比如"/commit-push-pr"，一键完成提交、推送、创建 PR。

斜杠命令本质上是 Markdown 文件，放在.claude/commands/目录下。你可以用自然语言写指令，还能嵌入 bash 脚本预先获取一些信息，减少模型来回调用的次数。这些命令可以提交到 Git，整个团队共享。

![](https://baoyu.io/uploads/2026-01-02-1767392162735-19e04f57-b7b7-467a-bb3f-184f24f6c312.png)

除了斜杠命令，他还用子 Agent（<https://code.claude.com/docs/en/sub-agents> ）。子 Agent 是独立的 Claude 实例，专门干某类活。比如他有个 code-simplifier 子 Agent，在主 Claude 完成工作后自动简化代码；还有个 verify-app 子 Agent，专门负责端到端测试。

这两个功能的共同点是：把你反复做的事情固化下来，让 Claude 自己调用。你不用每次都重复解释，也不用记住各种命令细节。

![](https://baoyu.io/uploads/2026-01-02-1767392196338-e22d7b84-3f2f-41ad-b363-cd7b3f16bcad.png)

使用 PostToolUse Hook 来格式化 Claude 生成的代码。Claude 通常能自动生成格式良好的代码，而这个 Hook 会处理最后 10% 的代码，以避免后续在持续集成 (CI) 过程中出现格式错误。

【7】安全与集成：权限配置和外部工具

![](https://baoyu.io/uploads/2026-01-02-1767392327598-eb1a93fc-8a7a-45a6-b1dc-344d20b4f17f.png)

Boris 不用--dangerously-skip-permissions 这个“危险”选项。相反，他用/permissions 命令预先批准一些常用的安全命令，避免每次都弹确认框。这些配置保存在.claude/settings.json 里，团队共享。

![](https://baoyu.io/uploads/2026-01-02-1767392360739-cf8b5f0b-69c5-423b-ab3a-e8ddb65af83b.png)

更强大的是 MCP 服务器集成。MCP 是 Model Context Protocol 的缩写，是 Anthropic 推出的让 AI 连接外部工具的标准协议。通过 MCP，Claude Code 可以直接：

* 搜索和发送 Slack 消息
* 跑 BigQuery 查询回答数据问题
* 从 Sentry 拉错误日志

Boris 团队把 Slack 的 MCP 配置也提交到了仓库，所有人开箱即用。

这意味着 Claude Code 不只是个编程工具，而是能调用你整个工具链的“全能助手”。

【8】长任务处理：让 Claude 自己验证

![](https://baoyu.io/uploads/2026-01-02-1767392385108-9004f62a-8158-499c-8010-610045248cd6.png)

对于跑很久的任务，Boris 有几个策略：

一是让 Claude 完成后自动用后台 Agent 验证结果。你可以在提示词里要求，也可以用 Stop Hook 更确定性地触发。

> 注：Hooks 是 Claude Code 的"钩子"机制，让你在 Claude 执行操作的特定时刻插入自定义逻辑。你可以把它理解为"触发器"：当某个事件发生时，自动执行你预设的命令或脚本。 Stop Hook 就是在 Claude 完成响应、准备交还控制权时。 相关文档：<https://code.claude.com/docs/en/hooks>

二是用 ralph-wiggum 插件 <https://github.com/anthropics/claude-plugins-official/tree/main/plugins/ralph-wiggum> 。这是一个有趣的设计：“Ralph 本质上就是一个 Bash 循环”：想象一个简单的死循环（while true），它不停地把同一个任务说明书（提示词文件）喂给 AI 智能体，让它一遍又一遍地改进工作，直到彻底完成。

三是在沙箱环境里用--permission-mode=dontAsk 或--dangerously-skip-permissions，让 Claude 不被权限确认打断，自己跑到底。

核心思路是：既然是长任务，就别让它等你。给它足够的自主权和自我纠错能力。

【9】最重要的一条：给 Claude 验证能力

Boris 把这条放在最后，说这可能是获得好结果最重要的因素。

如果 Claude 能验证自己的工作，最终产出质量能提升 2 到 3 倍。

他举了个例子：他们提交到 claude.ai/code 的每一个改动，Claude 都会用 Chrome 扩展自己测试：打开浏览器、测试 UI、发现问题就迭代，直到功能正常、体验合理。

验证方式因场景而异。可能是跑一个 bash 命令，可能是跑测试套件，可能是在浏览器或手机模拟器里测试应用。形式不重要，重要的是：让 AI 有反馈闘环。

这个道理其实很朴素。人类工程师也是靠“写代码—测试—看结果—修改”这个循环来保证质量的。AI 也一样。如果它只能写不能测，就像闭着眼睛做事，质量全靠运气。

Boris 的建议是：投入精力把验证机制做扎实。这是回报率最高的投资。

![](https://baoyu.io/uploads/2026-01-02-1767392416023-840bd6ae-f940-4f8e-9940-bbfd8c186d4e.png)

【10】高手用剑无招胜有招

武侠小说里面，高手用剑没有那么多花里胡哨的招式，无招胜有招。Boris 没有炫耀复杂的定制配置，没有神秘的私藏提示词，用的就是官方功能。区别在于：他真正理解这些功能背后的逻辑，然后把它们组合成高效的工作流。

并行工作是因为 Claude 能自主执行；用 Opus 是因为综合效率更高；CLAUDE.md 是把纠错变成资产；Plan 模式是先想清楚再动手；斜杠命令和子 Agent 是自动化重复劳动；验证机制是给 AI 反馈闭环。

如果你刚开始用 Claude Code，不必急着研究各种高级配置。先把基础用好：学会并行，学会规划，学会积累 CLAUDE.md，学会给 AI 验证手段。

等你真正遇到瓶颈了，再去折腾那些花活不迟。

hidden text to trigger resize events if fonts change

---

# [五条0105] Claude Code团队揭秘：AI产品开发新范式
发布日期：2026/01/04

![](https://imgproxy.readwise.io/?url=http%3A//mmbiz.qpic.cn/mmbiz_png/sBQys0vjP4qIzqjoFjlw4pT4vsctjPEUCSJo6gTbYLToPGVCJ07U2v97n0BOJYxsqp4ML26ZsY7apm9cvgUqpw/300%3Fwx_fmt%3Dpng%26wxfrom%3D19&hash=387bcd433e3623d5f8d66355c3c40b5a)

**投资实习所**

以产品视角洞察趋势

799篇原创内容

公众号

Claude Code 产品负责人 Cat Wu 在最近与 Peter Yang 的一个访谈里，分享了 Claude 团队的一些独特工作方法，不少理念和之前 Lovable 增长负责人 Elena Vera 分享的非常类似《[Lovable 融资 3.3 亿美金估值 66 亿，一个新向量数据库产品如何年收入涨了 10 多倍](https://mp.weixin.qq.com/s?%5F%5Fbiz=MzIyMDA3MjMwNw==&mid=2455857487&idx=1&sn=9c413246720fa15d12babf6d97d25352&scene=21#wechat%5Fredirect)》。

相比于传统软件团队，Cat Wu 说 Claude Code 团队的独特性在于：**极少文档、极快原型、强 dogfooding、持续反馈回路，以及在实际用户场景中反复验证“是否真的有用”的方法论。**

**没有宏伟战略，产品自己长出来**

Cat Wu 说，Claude Code 并不是一个自上而下规划的明星项目， 它的起点非常“草根”：一名叫 Boris 的工程师，为了更好地理解公司内部 API，写了一个小工具自用。没有立项、没有 OKR，甚至没有“这是个产品”的自觉。

但这个工具足够有用，于是开始在团队内部被分享、被推荐，随后扩散到更多工程团队，甚至研究、数据、产品等非工程岗位也开始使用。

所以在正式对外发布前，Claude Code 已经完成了一次完整的“内部市场验证”。这是一种典型的自下而上、由真实需求驱动的病毒式增长路径。

而 Cat Wu 在产品的早期阶段加入，一方面把工程原型转译为清晰的用户价值，另一方面让产品路径从“工具集合”走向“工作流与场景”的稳定能力。她强调：Claude Code 的根基不是“做一个新 IDE”，而是“理解开发者与知识工作者在真实场景中的高频痛点”，然后把 AI 能力嵌进关键节点。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/sBQys0vjP4oAJ6rYRHmpmJRUsia07jb1VicHHdWB9haBS5iaUmYOYoicKuj3UKryxDCamo5C5j74uUPyc4pciavdEfg/640?wx_fmt=png&from=appmsg&watermark=1#imgIndex=0)

**不写 PRD，先做原型**

在 Claude Code 团队，传统意义上的 PRD 几乎不存在。团队由大量“产品型工程师”构成，他们对功能拥有端到端的决策权。一个想法出现后，最优先的动作不是讨论、评审或写文档，而是直接做成原型，丢进内部 dogfooding 环境。

Anthropic 内部有超过 1000 名员工在使用 Claude Code，这意味着任何新功能几乎都会在第一时间收到真实反馈：是否好理解、哪里让人困惑、有没有 bug、值不值得继续做。正如 Cat Wu 所说：

> 我们最好的功能，几乎都是工程师先做出来，再看大家怎么用。

当然，这并不是对流程的盲目否定。对于 IDE 集成这类周期长、影响大的项目，团队仍然会进行更正式的产品评审。真正的智慧在于：**为大多数功能争取极致速度，只在关键节点上投入严肃成本。**

**产品决策机制：数据+体感的“双通道”反馈驱动**

大多数团队都喜欢“好评”，而 Claude Code 团队恰恰相反，是负面反馈优先。为此，他们刻意搭建了两条高强度的反馈通道：

* 一是内部超过千人的高频反馈群，平均每十分钟就会出现一条有价值的意见；
* 二是与约 10 家企业客户深度绑定，鼓励对方“尽可能直接地吐槽”。

他们会分类归并负面反馈，把“阻塞体验的要点”排到近期迭代清单的优先级顶端。这让 Claude Code 形成了一个极短的迭代闭环：问题被迅速暴露、快速修复、立刻上线验证。

**代码就是文档，代码库是唯一事实来源**

Claude Code 团队几乎不依赖 Google Docs。一个功能的背景、决策过程、设计权衡，通常都存在于 Pull Request、commit 记录和代码本身。

当有人想了解“当初为什么要这么做”，他们不会去翻一份可能早已过期的文档，而是直接用 Claude Code 去查询代码库和 GitHub 历史。

在强大的代码理解型 AI 出现之后，代码本身第一次具备了“可被查询、可被解释”的能力，代码库也因此成为一种动态、始终最新的“活文档”。这是几年前的团队根本无法享受的奢侈。

**忘掉两年规划，只谈未来几个月**

当被问到 Claude Code 一到两年的愿景时，Cat Wu 的回答异常克制：**一两年太长了，我能聊的是未来几个月。**

原因很简单——模型变化太快了。在一个底层能力每隔几个月就发生跃迁的领域，试图制定长期 roadmap，往往只会让团队被自己的预测绑住。相比之下，保持高度敏捷、持续试错，反而是一种更高级的战略选择。这和 Lovable 的理念几乎一样：**PMF 不是终点，而是每 3 个月一次的重来**。

非常认同 Peter Yang 的一个说法，他说在他看来，**Anthropic 在产品方面取得成功的原因，恰恰在于他们决定聚焦于企业级市场，特别是编程以及帮助人们完成工作**。他们没有试图涉足消费市场，也没有在多模态领域与 Google 竞争，更没有去打造硬件设备、其它应用 App 或类似的东西。

另外，看了几个一直在关注的产品对过去一年的总结，发现有的增长是真快，比方说 Mercor CEO Brendan 说，**在过去的 2025 年，Mercor 的收入增长了 4658%，也就是 46 倍。**

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/sBQys0vjP4oAJ6rYRHmpmJRUsia07jb1V0wDtV3CKffbpcHLv7yYhic9NOcmubfCuMBjctK4n7uJ9ar8jTq0VuAQ/640?wx_fmt=webp&from=appmsg&watermark=1#imgIndex=1)

Mercor 之前每月付出去的费用是 200 万美金，现在每天就付出去这么多。其用户从 21.7 万涨到了现在的 340 万，AI 的采访次数从之前的 8.8 万增加到了 150 万，人才推荐量从 1198 增长到了 190 万，可以说是真正的爆发式增长。

而另一个**用 AI 做客户问卷调研的产品，过去一年的收入增长了 15 倍，它实现了规模化定性研究，而且把分析师最痛苦的“苦力活”部分全部自动化了。通过数千个同时进行的……**

全文共 **3486 字** **后续内容为付费会员专属，** **会员扫码登录直接阅读** 

![](https://mmbiz.qpic.cn/sz_mmbiz_png/sBQys0vjP4oAJ6rYRHmpmJRUsia07jb1V3jwsKSHMQhKbejJ8vUNLlFse4TVYcicaaXH7mqwfNPTISVTwdlCmNTw/640?wx_fmt=png&from=appmsg&watermark=1#imgIndex=2)

Memo: Signal, not noise!

扫码或点击「阅读原文」继续阅读

**订阅 Memo Pro** 
  
Memo（vcsmemo.com）是一个基于付费订阅模式的创投内容平台，已得到大量 VC、企业 CEO 以及高管的支持，我们希望帮助你捕捉最具价值的行业信号、过滤噪音（Signal,Not Noise）。

**订阅 Memo Pro** 
**你将获得：** 
  
1.解锁未来一年以及之前的所有会员专属内容  
2.邮件订阅功能：付费内容+最新行业快讯+...  
3.优先体验 Memo 新产品和新功能  
4.后台回复“发票”获得开票入口  
**限时 799 元/年（原价 999 元/年），扫码立即订阅** 

![](https://mmbiz.qpic.cn/mmbiz_png/mrJibAziaMQhQGoNHniac6wGOyRe172dlS0HCYicyjiaCTtly2pULIz6YPNsXeRjoQFSuDYezsia4ibhbAc1X3GKtVRyw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1#imgIndex=3)

1.[Lovable 融资 3.3 亿美金估值 66 亿，一个新向量数据库产品如何年收入涨了 10 多倍](https://mp.weixin.qq.com/s?%5F%5Fbiz=MzIyMDA3MjMwNw==&mid=2455857487&idx=1&sn=9c413246720fa15d12babf6d97d25352&scene=21#wechat%5Fredirect)

2.[当下 AI 的 4 波浪潮，与 AI 时代的一种新型商业模式](https://mp.weixin.qq.com/s?%5F%5Fbiz=MzIyMDA3MjMwNw==&mid=2455851826&idx=1&sn=7c15434cb3583316520cb391201e7427&scene=21#wechat%5Fredirect)

3.[100 万到 1 亿美金收入，AI 招聘平台 Mercor 只用了 11 个月](https://mp.weixin.qq.com/s?%5F%5Fbiz=MzIyMDA3MjMwNw==&mid=2455856237&idx=1&sn=0dfa3114b4909860dff65f1345a779a4&scene=21#wechat%5Fredirect)

hidden text to trigger resize events if fonts change

---

# [五条0105] AI 设计流程实战：从研究到交付的提效指南
发布日期：2026/01/02

![](https://miro.medium.com/v2/resize:fit:1400/1*qZCb8Cfc24uycYGceZikAA.png)

## Dos and Don’ts for using AI tools in the design process

AI tools are now embedded across almost every stage of product design. We use AI to generate ideas, summarize research findings, explore visual directions, write UX copy, and even ship working prototypes.

Yet despite widespread adoption, many teams still struggle with a key question:

> **How do you integrate AI into the design process without weakening design quality?**

![](https://miro.medium.com/v2/resize:fit:2000/0*y6yxp8AXoJjwFk8n.png)

Conventional design process. Image by Atlassian.

In this article, I’ll walk through 5 stages of the product design process and explain how I use AI to strengthen each stage.

## Stage 1: Research & Problem Understanding

User & market research forms the foundation of the entire design process. It helps understand users and their core needs, the context in which the product will be used, and constraints well enough to articulate the problem you solve in design and help make informed decisions along the way. The better you complete your research, the more relevant product you will be able to release to the market.

### How AI tools can help with research

User research is one of the most time-consuming parts of the design process because it requires collecting and analyzing large amounts of data. Manual analysis takes days or even months. AI tools can analyze large amounts of data about your users and market and extract valuable insights.

### Recommended AI tool to use for research

[NotebookLM](https://notebooklm.google/) is my go-to AI tool for research. The key advantage of this tool is that it can help you create and maintain a database of various data about your users and market, so you can extract valuable insights from it. You can extend the database (adding more data to it) and keep it up to date (by removing unnecessary data from it).

[NotebookLM for Product Designers](/notebooklm-for-product-designers-cb84f1fcc22d?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

### Product research process with AI, step by step

Research process with AI is slightly different from a traditional research process:

1. _Start with a “Research Brief.”_ The first thing you need to do is create a proper context for both yourself and the AI. AI works best with context because it becomes clearer what you expect to get and why.
2. _Turn raw inputs into a structured knowledge base._ AI is not a magic pillow that will solve all your problems. You still need to structure the data input to ensure it is relevant and reliable.
3. _Translate research into design-ready outputs._ You need to go beyond understanding the current state of your product design and explore opportunities to make it better.

If you’re looking for more detailed dive into this process, check the article “[Product Research with AI](https://medium.com/p/108a1141729c)”

[Product Research with AI](/product-research-with-ai-108a1141729c?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

### ✅ Dos for AI-powered research

One of the key advantages of using AI for research is its ability to analyze large amount of data and extract valuable insights from it. You can use AI to:

* Summarise, cluster, and reframe research data;
* Surface contradictions, edge cases, and unanswered questions.

### ❌ Don’t for AI-powered research

Two things to avoid when doing AI research are feeding all possible data you have to AI, hoping it will make sense of it (this is known as “garbage in, garbage out”), and relying too heavily on AI to drive decisions. You should treat AI as a research assistant, not a replacement for a human researcher. At the end of the day, it should be you who makes a decision, and AI can only help you with that. Here are a few things to avoid when using AI for research:

* Not cleaning up data before submitting it to AI;
* Replace user research with AI-generated personas or assumptions;
* Skip validation and treat AI outputs as a true evidence.

## Stage 2: Framing & Problem Definition

Design is problem-solving. And the better you define the problem you want to solve and why it matters, the more relevant the solution you will get and the easier it will be to get product team buy-in. One common mistake many teams make during this stage is rushing to build something rather than spending more time elaborating on the problem. As a result, the framing stage is where many design failures originate.

### How AI tools can help with problem definition

During the framing stage, it’s vital to get a bird’s-eye view of your problem space: zoom out to explore the broader problem, then zoom in to specific design aspects. AI tools can stress-test problem framing and explore alternative angles and “what if” scenarios.

### Recommended AI tool for problem definition

Google Gemini and NotebookLM are my go-to tools for problem definition. I particularly like the Canvas mode in Gemini, which lets you turn plain-text output generated by AI into various formats, such as an infographic.

![](https://miro.medium.com/v2/resize:fit:1400/1*ME08mbhP7pEaCbzmAYGUSg.gif)

Infographics generated by Google Gemini for EV analysis.

[Google Gemini’s Most Overlooked (and valuable) Feature](/google-geminis-most-overlooked-and-valuable-feature-72c1172da0f7?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

### Problem definition with AI, step by step

1. _Create a proper context for AI_. Start by dumping raw notes, signals, and observations so AI has real material to structure. If you’re using NootebookLM creating context is basically selecting the right data inputs from the list of submitted data (files, videos, etc)
2. _Generate problem statement options._ Use AI to produce multiple framings of the problem so you can compare perspectives and choose the one that best reflects reality.
3. _Set clear scope boundaries_**.** Explicitly define what is in scope, out of scope, and constrained to prevent uncontrolled expansion of the problem by AI.
4. _Define expected outcome and success metrics._ Translate the problem into measurable user, product, and business outcomes to make success unambiguous. You can ask AI to suggest relevant metrics, but similar to any other parts you should always validate the output generated by AI.
5. _Compile a one-page problem brief._ Have AI synthesize everything into a concise, shareable brief that aligns the team before ideation begins.

If you want to know how to define success metrics for your product, check the article [Measuring Design](https://medium.com/p/55a423d6fb94).

[Measuring Design: Essential Metrics](/measuring-design-essential-metrics-55a423d6fb94?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

### ✅ Dos for problem statement with AI

* Use AI to compare and critique multiple framings.
* Ask AI to identify hidden risks, assumptions, and missing context.

### ❌ Don’t for problem statement with AI

* Accept a well-written problem statement without understanding and validating it
* Optimize for elegance (aka “sounds right”) over accuracy (rooted in facts and detailed analysis)

## Stage 3: Ideation & Vibe Design

Ideation is idea generation. For me, this is the most fun phase of the design process. During this stage, you generate various ideas and prototype them.

### How AI tools can help with ideation and vibe design

Ideation and vibe design is where AI truly shines. AI can suggest various solutions to your problem and quickly visualize it for you.

> Vibe design turns taste into executable logic.

### Recommended AI tool for ideation and vibe design

There is a broad range of tools you can use to ideate and craft design. Early on this phase, you can hire ChatGPT or Gemini to suggest possible UI layout.

[Gemini 3 For UI Design](/gemini-3-for-ui-design-f3fb44a295a6?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

Both ChatGPT and Gemini can also generate you a mockup of your future design based on your description. OpenAI and Google constantly improve the quality of the output generated by their AI models (below you can see the progress for ChatGPT model)

![](https://miro.medium.com/v2/resize:fit:1400/0*vnSf0GsiOXkMofXt.png)

ChatGPT 4o vs ChatGPT 5 for UI generation.

If you want to learn more about basic UI design with ChatGPT, check this article:

[UI Design with ChatGPT 5](/ui-design-with-chatgpt-5-afc67dc501a1?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

Alternatively, you can hire a specialised AI tool for UI design called Google Stitch. I’ve shown my entire 3-step workflow using this tool and highlighted the most important things you need to consider to make the most of it.

[Google Stitch for UI Design](/google-stitch-for-ui-design-544cf8b42d52?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

![](https://miro.medium.com/v2/resize:fit:2000/0*drjeEgQc68L0rHt1.png)

Design of a mobile app generated by Google Sitch.

Later, when you have a clear idea of what you want to build and why, you can hire Figma Make to do vibe design. The output that the tool generates is a real-coded prototype. Note that the prototype is still not a final solution.

![](https://miro.medium.com/v2/resize:fit:2000/0*t5v-rasZBEF7P_4t.png)

Mobile app design generated by Figma Make based on provided description.

[A Practical Prompting Guide for Figma Make](/a-practical-prompting-guide-for-figma-make-eb72f78ff1ce?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

One great advantage of using Figma Make for design implementation is its ability to configure MCP (Model Context Protocol), which makes it possible to translate your design assets, like UI components and styles, almost 1:1 from Figma to coding tools like Cursor.

[Figma MCP: Complete Guide](/figma-mcp-complete-guide-c45af0975ab8?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

### ✅ Do for vibe design

* Use AI to generate multiple visual and interaction directions
* Explore extremes, not just safe options

### ❌ Don’t vibe design

* Treat the first AI output as “the idea”
* Skip human judgment and taste

## Stage 4: Design Execution & Prototyping

_Vibe coding is design execution with AI._ During this phase, you turn your design intent into tangible, testable artefacts (ready-for-implementation design)

### How AI tools can help with design execution

AI can help convert designs into working prototypes, maintaining your design decisions (styles, components, interaction patterns) in a final design.

### Recommended AI tools for design execution

[Claude](https://claude.ai/) is my go-to tool for all design execution tasks. Claude can help you with design-to-code translation (creating quick prototypes), coding UI components, and even making UI feel alive by adding animated transitions.

[Claude For Code: How to use Claude to Streamline Product Design Process](/claude-for-code-how-to-use-claude-to-streamline-product-design-process-97d4e4c43ca4?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

Creating quick prototypes with Claude feels magical—you can provide a screenshot of your UI and ask Claude to code it. And the tool just do it. Many times you can get a fully functional coded prototype after a single try.

![](https://miro.medium.com/v2/resize:fit:1400/0*mCXzq0X5tqiGknXG.png)

Coded version of the mobile app provided to Claude as a screenshot.

If you want to refine a coded design, you can use [Cursor](https://cursor.com/) for that. This tool is an IDE powered by AI that helps you polish your solution and prepare it for release.

## Stage 5: Design Validation & Audit

_Test early, test often_. Design validation is an integral phase of the design process as it helps to reduce risk before committing to implementation.

### How AI tools can help with design audit

AI can help with design validation by creating usability testing screeners, analysing usability test notes, summarising feedback across sessions, and suggesting iteration ideas based on findings. It’s especially effective when dealing with _volume_.

### Recommended AI tools for design validation

Gemini is my go-to tool for design validation. It can help with exploring “What-If” scenarios and get multi-modal critique.

[Design Audit with Google Gemini 3](/design-audit-with-google-gemini-3-bfe0ee9c972e?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

The tool can also help you generate a nice visual summary for design audit, such as accessibility annotations (you can feed your existing UI and ask the tool to write annotations).

![](https://miro.medium.com/v2/resize:fit:1400/0*--h8cQsCqBAAAfly.jpeg)

Accessibility audit conducted by Gemini & Nano Banana.

[3 Popular Ways to Use Nano Banana Pro for Complex Product Design Tasks](/3-popular-ways-to-use-nano-banana-pro-for-complex-product-design-tasks-1e7439b7775d?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

Or even a detailed summary for the product in a visual format:

![](https://miro.medium.com/v2/resize:fit:1400/0*7W5Whjl_1r5zbkFv.jpeg)

Visual summary of design audit for ride sharing app. Summary generated by Gemini.

### ✅ Do for design validation with AI

* Use AI to synthesise feedback at scale
* Ask it to highlight trends and anomalies
* Combine AI insights with human interpretation

### ❌ Don’t for design validation with AI

AI helps you see patterns but humans make decisions. So you should never:

* Let AI decide what to fix first
* Treat frequency as severity
* Ignore qualitative nuance

## Want to learn more about AI-powered product design?

Enrol in my course, “[Product Design with AI](https://maven.com/babich/product-design-ai),” a 4-week, live cohort-based course where you’ll learn how to use AI tools to streamline your product design workflow, go from idea to ship-ready product, and become an AI-powered designer alongside a peer community and expert guidance.

[Product Design with AI by Nick Babich on Maven](https://maven.com/babich/product-design-ai?source=post%5Fpage-----3b57f9aaf97d---------------------------------------)

hidden text to trigger resize events if fonts change

---

# [五条0105] AI重塑UX：2026年十大设计趋势
发布日期：2025/12/29

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/N1TFJ8KaveP0iabzwOrYNamQ2ibpgeKmfM3Hxwy4Dh1w1fPHRUlu9UKVy0rIekPibvmn9WibiaictBzC92kwbVcLVK6w/640?wx_fmt=jpeg&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1)

站在 2025 年末，又是年底了。每到这个时候，总习惯停下来，回头看看走过的路，再踮起脚尖望望前面。

过去的一年里 AI 又加速了行业的变化，快到让人觉得有点追赶不上。但或许正是这种“未知”，才让我们对新的一年总是充满好奇。2026 年会是什么样？在这个新旧交替的时间节点，我们整理一些对行业趋势发展的观点，一起与你分享，展望新的一年。

## **趋势01**

## **AI 从辅助工具到设计搭档**

AI 将成为设计师的全职搭档，而不只是辅助工具。到 2026 年，各类 AI 驱动的设计工具（如Gemini、 Galileo AI、Figma 等）能够自动生成页面布局、配色方案甚至品牌系统，让设计师从繁琐的像素调整中解放出来，集中精力打造创意。AI 帮助快速产出多种设计方案，缩短迭代周期，但最终的审美、可用性和品牌内涵仍需由设计师把关，设计决策力变得更为重要。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4UdyuPjxuswPiapgGJyGdMcEl0oDqLxMibFE383xvSPbGzSYrOpkj4dSQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1)

Gemini 生成 web UI 案例

将 AI 当作“实习生”使用，善用提示词引导 AI 生成初版界面，再由设计师进行润色和优化 。例如，可以用 AI 快速打磨多套方向，然后筛选最佳方案，由设计师进行定调和细节完善。设计师的价值更多体现在创意引导和用户理解，而非重复性劳动。

趋势02

生成式UI（**Generative UI**）交互体验

我们当前还处在“动态内容，静态容器”的阶段，2026年可能越过了临界点。传统的“静态用户界面”概念——即所有用户看到相同布局、相同组件的预设界面——将被视为一种过时的遗留模式。生成式UI（Generative UI，简称GenUI）与传统的个性化不同，GenUI利用大型语言模型（LLMs）和实时渲染引擎，根据用户的即时意图、上下文环境及历史行为，在毫秒级时间内“凭空”构建出独一无二的界面。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4odhMp9nNMOQvjzaOgWOT1gQjMYqMqQ9YdJkeXvxxMzXzn3EkQbm6IA/640?wx_fmt=png&from=appmsg#imgIndex=2)

Rabbit 通过Prompt定义主题

这种转变意味着“界面”不再是一个固定的产品，而是一种瞬时的服务。例如，当用户在银行应用中查询复杂的抵押贷款时，系统不会展示一个通用的仪表盘，而是根据用户的财务素养水平、当前的关注点（如利率还是月供），实时生成交互式的可视化图表、滑块工具及解释性文本。同时严防“UI幻觉”（即生成了后台不支持的功能按钮）。

趋势03

多模态交互与零界面体验

语音、手势、触觉反馈等多种交互方式将成为新常态，屏幕界面不再是唯一入口。未来的界面设计侧重于“无界面”体验：设备能通过声音、传感器和环境感知用户需求，在无需视觉界面的情况下完成任务。例如，智能冰箱能自动识别牛奶库存并下单；车辆凭人脸识别调节座椅和镜像；甚至可穿戴设备在用户“想到”时主动显示信息 。这种设计让体验更加直觉、自然，但同时须顾及隐私和用户控制权。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4I8AiaT3FrBkuRicia1yw1icicMgfBr2EWFllGiad4wu6svmooKu2n3B0DlSw/640?wx_fmt=png&from=appmsg#imgIndex=3)

Rokid 官网素材

“无界面”并非完全去屏幕，而是设计时充分考虑语音、触觉和环境反馈。例如，Rokid并没有完全依赖空中复杂的手势追踪（这在社交场合往往显得尴尬），而是将实时语言翻译和物体识别直接集成到用户的视野中。

趋势04

代理式体验

想象一下，当你想要制定旅行计划时，不再需要分别打开订票软件、酒店APP和攻略网站。在**代理式体验**的逻辑下，你只需表达“我想去度假”，系统就会像一位老练的管家，理解你的偏好，在后台默默调动资源，直接把行程单放在你面前。

这种体验的关键转变在于：**系统从“等你怎么做”变成了“懂你要什么”，相信大家通过豆包手机助手可以感受到了。**

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4DpF9vB0uR4ASsq7sDTKZAaLmgESHDOkUvVLx7VK9AtLMKr9mqNMY9g/640?wx_fmt=png&from=appmsg#imgIndex=4)

豆包手机助手

但这带来了一个新的挑战：**信任**。就像雇佣新管家一样，用户会怀疑：“你为什么选这个航班？你是不是替我做了错误的决定？” 因此，未来的UI/UX设计（尤其是展望2026年），其主战场将是**定义人机协作的边界**——既要享受自动驾驶般的便利，又要确保用户手中始终握有方向盘，让用户感到安全与掌控。

趋势05

超个性化体验

用户期望产品能够预见他们的需求，而非千人一面 。随着生成式UI的落地，2026年的 UI/UX 倾向于**动态个性化**：界面根据用户偏好、使用习惯和场景自动调整。例如，根据用户使用时长简化界面，或为新手和资深用户提供不同的引导流程 。同时保持对隐私和透明度的尊重，只在用户愿意的前提下采集和利用数据。个性化应当让体验更贴心，而非令人不适。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4g9OdiahXGvOAtAP6SjouS5IsBDVQSvsicSFDB8vZ4dfibURnXQLQGK6Hw/640?wx_fmt=png&from=appmsg#imgIndex=5)

来源尼尔森

收集用户数据时遵守伦理准则，让用户对个性化功能拥有可控权。例如，提供可调节的个性化设置，让用户自行选择是否启用各种自动化功能。界面根据上下文实时变化，但应明示切换原因，并允许用户一键恢复默认。

趋势06

情感化交互体验

随着生成式UI的推进，可能会越来越多的产品开始在这个屏幕里表达“立场”。它不再是模式化的流程界面，而是用特定的语气、特定的视觉风格，甚至引导特定的情绪，来迎合用户的情绪，就像我们现在与ChatGPT对话一样。带有情感色彩和幽默元素的界面能够拉近与用户的距离。这种**情感化设计**让交互更具温度，让用户在操作中会心一笑，从而提高好感度和黏性。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4sZalBCQRiaY4hqqNvtTffBcpIiccxUhdEGmVFicpRjB35qV5KoUNGC3YQ/640?wx_fmt=png&from=appmsg#imgIndex=6)

Gemini Demo

就像交朋友一样，只有性格鲜明的人才会被记住。未来的 UI/UX 设计，本质上是在设计一种“相处模式”——它不只是一个用完即走的工具，而是一个拥有独特人格、能与你产生情感共振的数字伙伴。

趋势07

功能性极简与微交互设计

极简主义依旧流行，但更强调“功能性清晰”而非单纯留白 。设计师会尽可能剔除不必要的元素，确保界面只保留核心功能，降低用户的决策成本 。与此同时，**微交互**（按钮点击反馈、加载动画、表单验证提示等）变得更具意义：它们不仅增添趣味，还引导用户操作、反馈状态、确认结果 。合理的微动效能让界面显得“活”起来，提高易用性和信任感。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4mFVWMKeibs4ry86JmElIPYOWf9bicyOACTHkzsFoghLg1vCsDxNjmh6g/640?wx_fmt=png&from=appmsg#imgIndex=7)

小米 HyperOS 官网素材

清爽的移动界面仅保留必要元素，辅以直观的微交互，让用户一目了然 。精简界面时问自己：每个按钮、图标和文字是否都为用户带来价值？删除累赘后，通过细微的动画和交互来提示功能。比起追求花哨效果，务必确保操作路径清晰。例如，2025年国内手机厂商对系统微动效的提升，在交互反馈上，用细微的颜色变化或振动确认用户操作。

趋势08

液态玻璃视觉风格

界面美学持续演化，新材料主义潮流复兴并融合现代技术。**“流动玻璃”**（Liquid Glass）等风格将更频繁出现：动态渐变、折射光泽和流体质感让界面仿佛具有生命力 。同时，新拟态（Soft UI）以柔和阴影和浮雕感为界面增添立体感和亲和力 ；玻璃拟态（Glassmorphism）通过半透明层次营造深度和层次感。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4rMhGQERpzGFALB9Ef2lT6bOqth36zrTXQJ1Pboz7zJyn6ibZ8hRdzOA/640?wx_fmt=png&from=appmsg#imgIndex=8)

iOS Liquid Glass

需要谨慎运用以保证可读性：高对比度的文本与背景搭配、适度透明的遮罩、保持关键内容清晰可见。将新的视觉元素作为点缀使用，而非填满整个界面。比如，电商应用可以在精选商品卡片中运用流动玻璃效果吸引目光；健康或生活类应用则可用柔和的拟态按钮营造友好触感。始终保持文字、重要控件的高可读性，不让美观牺牲功能性。可参考 Apple 系统对流动玻璃的运用，或三星界面上的微妙拟态效果 。

趋势09

空间与三维界面设计

随着 AR/VR 技术和硬件的发展，三维空间设计逐渐走向主流。设计师将思考如何让界面像**可探索的空间**一样生动：元素可响应光标或视线微微移动，呈现真实的深度感 。即使在平面屏幕上，也会有悬停触发的3D卡片、滚动时浮动的层次、甚至AR 预览功能，让用户可以在环境中“看到”虚拟物体 。这种趋势旨在提高沉浸感，但需平衡性能：为确保流畅体验，应逐步引入三维特效，避免界面卡顿。 建议优先保证基础交互顺畅，再添加细节。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4lNiaUH7fBXoPfUVlRBY5ur4h13q3aWLOMVLrbNjQOKKZEyPzpXIZkuA/640?wx_fmt=png&from=appmsg#imgIndex=9)

Apple Vision Pro

在设计时以“虚拟场景”来规划流程，构思用户在此“场景”中如何行走、注视、操作。例如购物类应用可利用 AR 预览让用户将商品“摆放”在现实环境中，通过交互式 3D 模型帮助理解复杂概念。但始终保证2D界面基础流畅：在低性能设备上禁止或简化复杂效果。

趋势10

生态边界持续深度融合

2026年，UI/UX设计的核心战场将突破单一屏幕与操作系统的藩篱，构建真正的“无界生活流”**。随着法规驱动的平台互通（如iOS与Android的互通）及万物互联协议的成熟，设计的焦点将从“抢占用户时长”转向**“跨场景的状态接力”**。未来的体验将呈现“流体状”——原子化的服务不再受困于App内部，而是能够根据用户的实时意图，在手机、车机与智能家居间自由穿梭、无缝流转，彻底改变“人找服务”的旧逻辑，实现**“服务随人动，体验无断点”。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4QYB1Rmp5JsLuUjHTuoKDYIrS52NryaAYANesgviciaf4BT6Hn4C4zHVw/640?wx_fmt=png&from=appmsg#imgIndex=10)

小米 HyperOS 官网素材

无论是小米的 HyperOS，还是华为的 HarmonyOS，打通人、车、家全生态，让设备实时动态组网，所有设备协同如一个整体，带来无缝的互联体验。同时通过APP与iOS实现跨屏的数据同步、跨屏分享、解锁等能力。最近，Pixel 10 用 Android 16 自带的 Quick Share，完美兼容了 AirDrop「所有人 10 分钟」模式的双向收发，可以看出生态之间的融合的趋势，将为用户带来更好的跨端交互体验。

最后

无论是 AI、代理式体验、多模态交互、情感化体验，还是生态融合设计，本质上都在做同一件事：把复杂留给系统，把确定性留给用户。这也意味着，体验设计正在悄悄改变自己的角色。它不再只是界面层的工作，而开始介入判断、协作、信任和长期关系的建立。交互体验将会走向会更流畅、更智能、更有温度的时代。

往 / 期 / 推 / 荐

[](https://mp.weixin.qq.com/s?%5F%5Fbiz=Mzg2MjU1MDk1OA==&mid=2247485256&idx=1&sn=a1ee3cac5328b8b773cd981039ca78c8&scene=21#wechat%5Fredirect)

[![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/N1TFJ8KaveMYQ15TiaxhIxKUdgH1B2gU4QFBBCuwWX3EkwcqZuO8FSIrnxic5cYBzrVuLjyb9BodBp2cpDoj4fYw/640?wx_fmt=jpeg&from=appmsg#imgIndex=11)](https://mp.weixin.qq.com/s?%5F%5Fbiz=Mzg2MjU1MDk1OA==&mid=2247485256&idx=1&sn=a1ee3cac5328b8b773cd981039ca78c8&scene=21#wechat%5Fredirect)

[](https://mp.weixin.qq.com/s?%5F%5Fbiz=Mzg2MjU1MDk1OA==&mid=2247485215&idx=1&sn=ca05f835c1c71a69078260d4611b9004&scene=21#wechat%5Fredirect)

[![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/N1TFJ8KaveNKiaAPLjlXKx2Ky9qfMWSxlc6B0XJLW1teceItB1hTjlOyhDBLdPiaibb3aeBMTHZSq3ATibf6Iibia1OQ/640?wx_fmt=jpeg&from=appmsg#imgIndex=12)](https://mp.weixin.qq.com/s?%5F%5Fbiz=Mzg2MjU1MDk1OA==&mid=2247485215&idx=1&sn=ca05f835c1c71a69078260d4611b9004&scene=21#wechat%5Fredirect)

[](https://mp.weixin.qq.com/s?%5F%5Fbiz=Mzg2MjU1MDk1OA==&mid=2247485033&idx=1&sn=8a6a900829a927da6ab3c903dc73763b&scene=21#wechat%5Fredirect)

[![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/N1TFJ8KaveOGIyknjN9WqSp79DY5suZQoGKibm1zlQvduxfc99qwUGtaPBBYDxB3kzia9PFjRibKc1AUx0dRNqHYg/640?wx_fmt=jpeg&from=appmsg#imgIndex=13)](https://mp.weixin.qq.com/s?%5F%5Fbiz=Mzg2MjU1MDk1OA==&mid=2247485033&idx=1&sn=8a6a900829a927da6ab3c903dc73763b&scene=21#wechat%5Fredirect)

体 / 验 / 课 / 程

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveMriaiavKtfuaeibtnbhXHfzB7ohUb54WvMfiaz8CefDxmKgVnEgSlWUqdNrnCI7Mia8fVibQTekUOJPhSQ/640?wx_fmt=png&from=appmsg#imgIndex=14)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/N1TFJ8KaveOXE3YoN3hJKKqh1UricCEomia6nk1ZJeez0ibiaXv0ShHH1HmicFgDFWQiakNZwNsdQgzQ8fN8w5q5YyibA/640?wx_fmt=png&from=appmsg#imgIndex=15)

hidden text to trigger resize events if fonts change