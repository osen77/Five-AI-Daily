# [äº”æ¡0108] LLMæ—¶ä»£ï¼ŒUXç ”ç©¶å¦‚ä½•å®šä¹‰äº§å“ä»·å€¼ï¼Ÿ
å‘å¸ƒæ—¥æœŸï¼š2026/01/07

# Same, but new: 

AI agents, synthetic users, deep research, staying relevant as a UX researcher can feel like a challenge that resets every week. Teams across product, design, and engineering are moving faster than ever, often powered by the same underlying AI technologies. [Prompt engineering and system design have quickly become central topics across disciplines](https://medium.com/user-experience-design-1/human-machine-responsible-ai-workflows-for-ux-research-22a5c39ac0ec), raising a familiar, and uncomfortable, question: _where does UX research fit now?_

My experience building LLM-based products over the past two years has led me to a clear conclusion. This moment is not the end of UX research. It is the same work we have always done, understanding people, defining value, but applied to a new class of systems. And for researchers willing to adapt, it creates an opportunity to move upstream and become more strategic than ever. As products become cheaper to build and AI spreads across nearly every workflow, teams now face a new foundational decision: how much AI should this feature contain?

[When the answer is â€œyesâ€, and it is not always](https://uxdesign.cc/is-your-ai-use-case-idea-really-going-to-work-7718c695e7c0), the work does not stop there. A second, equally important question follows: _what form should that AI take?_ One of the most prescient frameworks in this space comes from [Jake Saper and Jessica Cohen at Emergence Capital, who describe AI products along a spectrum](https://www.emcap.com/thoughts/your-success-with-generative-ai-may-come-down-to-these-ux-decisions). On one end are pure chat-based systems that maximize flexibility. On the other are AI-enhanced features that trade flexibility for simplicity. Most production features live closer to the latter. The product defines the prompt, sometimes with light user input, and delivers the output in a predetermined format. Every â€œsummarize,â€ â€œrewrite,â€ or â€œgenerateâ€ button we encounter today reflects this tradeoff.

Delivering value with AI enhanced features means having a solid understanding of what the user is attempting to achieve within the context of their workflow both for the actual output and the design of how it is delivered. Take for example, a summarize feature. A summary can mean many different things depending on where it is being delivered. A â€œSummarizeâ€ button offered in Gmail likely needs punchy and bulleted contents. The same within Adobe acrobat for a large PDF could mean a multi paragraph executive summary. It is all about context and the actual need in the moment. The same we have always been doing but new.

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/1*lYL-7x1LLVuJ-LBP0ey62w.png)

Adobe buttons for taking AI Actions

NotebookLM offers a compelling example of this shift. The product began as a chat-based, retrieval-augmented system. It gained widespread attention with its audio overview feature, which generated a podcast-style summary of a userâ€™s materials, no prompting required. That feature delivered immediate, differentiated value by meeting a specific user need in a novel format. While the initial novelty has faded, subsequent updates have reinforced NotebookLMâ€™s position as a model for AI-enhanced productivity.

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:1000/1*5e0Ox6q7MpceIhZjBBiXBw.png)

A screenshot of the NotebookLM feature including sources, the overview page, and the studio features

The Studio feature set within NotebookLM illustrates the pattern particularly well. Users are presented with a set of structured options that guide them toward generating reports, briefs, or analyses. The real power lies not in unrestricted chat, but in the ability to lightly customize a pre-generated prompt. In Emergence Capitalâ€™s terms, this is a true copilot: a system that helps users provide the right input in order to receive a valuable output. When a user asks NotebookLM to generate a report, success is not defined by grammatical correctness or factual accuracy alone. Success is whether the output fits the userâ€™s actual need, whether it advances their task, supports their workflow, or deepens their understanding.

This is where the role of UX research begins to changeâ€¦ not in kind, but in scope.

## A New Way to Create Value

Creating value with LLM-based features is not about writing the cleverest prompt. It is about defining the right instructions so the system produces something that is genuinely useful to the user in that moment. Prompt quality matters, but prompts do not exist in a vacuum. They sit at the intersection of engineering, design, and, critically, research.

NotebookLMâ€™s opening chat response is a useful example. As a user logs in, the chat window is filled with an overview of all contents that helps users make sense of their materials as soon as they open a notebook, reducing the cognitive cost of re-orienting themselves. Engineering work was required to craft prompts that reliably surface the right insights. Design work was required to decide how that information should appear on the page. But neither of those efforts can succeed without first understanding what users actually need at the moment of entry. That understanding is where research does its most important work, informing both what the system should generate and how that output should be presented.

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/1*Hk912CHJxIPta3jysWeUEg.png)

NotebookLM opens with a summary of the Notebooks

[Design guidance for displaying AI-generated content is relatively well covered.](https://uxdesign.cc/ai-ux-design-for-intelligent-interfaces-bc966e96107d) [Many strong frameworks already exist for structuring text, surfacing key information, and presenting outputs in ways that are readable and actionable.](https://medium.com/user-experience-design-1/search?q=ai+in+product) What has received far less attention is the upstream work of shaping the instructions that guide generation in the first place. Ensuring a prompt is directionally correct â€” aligned to real user needs rather than abstract capabilities, was always important. With LLMs, it becomes foundational.

This is where UX research creates new leverage. By engaging early, researchers can help teams anchor feature development in what is actually possible given both the state of the technology and the userâ€™s needs in context. In my experience, this approach consistently opens up more promising product directions. Instead of retrofitting research onto an already-defined solution, teams start with a shared understanding of value, giving design and engineering a clearer target to aim for as they build.

## A New Process for Defining Quality in Outputs

For decades, UX research has focused on identifying the user needs a product must satisfy. That part of the work is unchanged. What _is_ new is the nature of the systems we are designing. With large language models, teams no longer have complete control over outputs. These systems are inherently non-deterministic, we can guide them, but we cannot fully dictate what they will produce.

In traditional product design, many needs could be satisfied with deterministic solutions. When Apple realized people were using their iPhones as flashlights, the solution was straightforward: a single button that produced a single, predictable outcome. One tap, immediate value. No ambiguity, no interpretation required. That model works well when the need is simple and the desired outcome is clear.

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/0*WDyogOfVTb78FQwo)

iPhone flashlight buttons that is placed on the Lock Screen for ease of use

As needs become more complex, so does the solution. Uber faced a different problem: passengers felt anxious while waiting for their ride. The company could not control the behavior of individual drivers, so instead it designed an experience to manage uncertainty. [A live map showed the driverâ€™s progress (although not always truthfully)](https://www.wired.com/story/uber-algorithm-fake/?utm%5Fsource=chatgpt.com). Messaging explained potential delays. Contact options gave users a sense of agency. Each element addressed the same underlying issue, negative sentiment during the wait, even though the core system remained unpredictable.

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/0*SrfQbAaDBqm8Gh6H)

A screen grab of a car moving toward a destination on Uber App

[Working with LLMs is similar, but amplified](https://medium.com/ai-ux-designers/ai-is-breaking-free-an-emerging-ai-ux-pattern-26894a915d93). An LLM behaves less like a traditional interface and more like a human collaborator: responsive, capable, and inconsistent. It may produce insightful results one moment and confident-sounding nonsense the next. This unpredictability is not a flaw; it is a property of the technology. The challenge, then, is not eliminating variability, but maximizing output quality despite it.

That challenge requires a different approach. Rather than treating quality as an after-the-fact judgment, teams must define what â€œgoodâ€ looks like in advance, and do so in a way that acknowledges uncertainty. This is where UX research plays a central role: translating user needs into clear quality signals that can guide generation, evaluation, and ongoing refinement, even when outputs cannot be fully controlled. Here is how I got about it.

### Surfacing Quality Signals

The first step is establishing a shared understanding of what constitutes a high-quality experience. When a user requests a briefing document in NotebookLM, what are they actually expecting to see? The answer is inherently subjective. Different users bring different expectations, shaped by their goals, context, and prior experience.

This is why qualitative research is essential. In-depth interviews allow teams to understand not just _what_ users say they want, but _how_ they judge AI-generated outputs in practice. I start by asking users to share what they expect to see as an output. Afterwards, I walk them through examples, either outputs they already use or ones I introduce, and have them describe what they mean when they say something â€œinforms,â€ â€œsummarizes,â€ or â€œprovides direction.â€ These conversations reveal the mental models users bring to AI systems and the tradeoffs they are willing to make.

As classic Jobs to Be Done research has shown, people are rarely asking for features in the abstract, they are trying to make progress in a specific situation. The same principle applies here. With that mindset, research becomes a game of identifying the main themes in what users are asking for in the output.

In the case of NotebookLM, early qualitative work might surface themes such as trust, cognitive relief, contextual relevance, and actionability. Users may not articulate all of these dimensions explicitly, but patterns emerge across interviews. A useful heuristic here is the 80/20 rule: a relatively small set of research-derived criteria can account for the majority of usersâ€™ expectations.

For example, a high-quality briefing report in Notebook might be judged on whether it:

* Feels trustworthy
* Demonstrates understanding across multiple sources
* Reflects the userâ€™s current context
* Connects insights to realistic next actions

### Validation and Refinement

Once core quality themes are identified, the next step is validation and refinement at scale. Surveys are particularly effective here. They allow teams to translate high-level themes into more specific, testable factors and to understand how consistently those factors matter across users and contexts. When designing these studies, I ask participants to evaluate outputs that closely resemble what the product would actually generate. Users are then asked to rate and critique those outputs, providing nuance around what makes them useful, or not.

Take trust as an example. Users frequently say they want AI outputs they can trust, but trust is not a single, universal attribute. At a minimum, it implies factual correctness. Beyond that, trust is shaped by tone, length, structure, and framing, all of which vary by context. [An email summary should be concise and direct. An executive briefing should surface key themes and unexpected insights.](https://medium.com/%40mariamargarida/designing-with-ai-ux-considerations-and-best-practices-5c6b69b92c4c) A call recap should highlight action items and mention relevant stakeholders. When an output matches what users expect in that situation, trust follows.

Surveys help teams refine these distinctions. In the NotebookLM case, researchers might explore when users feel a pre-created executive briefing demonstrates contextual awareness and when it does not. For example, users may respond positively when recent meetings or emails are incorporated appropriately, and negatively when outdated or irrelevant documents are surfaced. This level of specificity is critical, it directly informs how prompts should be written and constrained.

### Creating a Quality Rubric

With qualitative depth and survey validation in place, the next step is synthesizing insights into a shared quality rubric. There is an immediate opportunity for the engineering team to create refinement, yet as previously suggested, it is not just about the actual output but how it is designed. As such, this rubric can become the centering focus for the entire team.

A well-designed rubric defines each quality factor clearly, illustrates what good and poor outputs look like, and makes tradeoffs explicit. It allows designers, product managers, and engineers to align on what success means and how it should be evaluated. Importantly, it translates research insights into something actionable.

For prompt engineers, the rubric serves as a definition of the **global maximum**, the set of characteristics the system should optimize for overall. Prompt iteration can then focus on finding local maxima within that boundary, confident that improvements are aligned with real user needs rather than proxy metrics.

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/1*r0e7MNnSxTo_jHMxDAVlug.png)

EXAMPLE: NotebookLM Summary Output Quality Rubric

### Continued Refinement

Even with a strong rubric and well-crafted prompts, the work does not end. Many teams now rely on AI-based testing and automated evaluation to refine LLM outputs over time. Companies such as [BrainTrust](https://www.braintrust.dev/) have built extensive platforms that allow product teams to test the output of their prompts at scale, across models. Leveraging these tools are far more effective when grounded in research-defined quality criteria.

Press enter or click to view image in full size![](https://miro.medium.com/v2/resize:fit:700/1*ci85QVqGfpeeBUbeWFYSlw.png)

Braintrust has an extensive automated evaluation system

A solid rubric ensures that synthetic user testing, automated scoring, and iterative refinement are anchored in metrics that matter to real people. Rather than optimizing loosely connected signals, teams can focus on outcomes that genuinely improve the user experience.

This ongoing refinement is especially important in a fast-moving market. User expectations are evolving quickly as the Overton window of what is possible with AI continues to shift. A bullet-point summary that felt impressive yesterday may be table stakes today, replaced by audio, visual, or personalized formats tomorrow. Quality rubrics must be revisited and updated as expectations change, creating a sustained, strategic role for UX research in keeping AI systems aligned with human value.

## UX Research as the Interpreter of Human Value

The science of UX research has not changed. People are still complex, contextual, and inconsistent, and understanding what they need remains the core of the work. The methods have not changed either. UX researchers are still experts at learning from users, identifying patterns, and translating insight into action.

What _has_ changed is the nature of the systems we are shaping. With LLM-based products, outputs are no longer guaranteed, and a new stakeholder, the prompt engineer, has entered the room. [Research now has a direct line into how AI systems are instructed, evaluated, and scaled.](https://uxdesign.cc/a-practitioners-journal-on-navigating-ux-in-the-age-of-ai-97f0a11e8319) Insights no longer stop at informing interfaces or features; they define the criteria by which machine-generated work is judged as successful.

This process is not foreign to UX research, but the leverage it creates is new. By defining quality up front, researchers can shape how intelligence itself is tuned, guiding optimization, grounding automation, and ensuring that faster iteration does not come at the expense of human value. In my own work, this shift has made the field feel more relevant and more exciting than it has in years.

Done well, UX research can become the discipline that defines what people want from AI systems, and holds those systems accountable to real outcomes. AI will continue to do more of the work. That is not changing. What can change is whether that work actually matters. UX research is uniquely positioned to make sure it does.

hidden text to trigger resize events if fonts change

---

# [äº”æ¡0108] AIæµé‡æŠ¥å‘Šï¼šç‹‚çƒ­é€€æ½®ï¼Œè°ä¸»æ²‰æµ®ï¼Ÿ
å‘å¸ƒæ—¥æœŸï¼š2026/01/08

[See all posts](https://baoyu.io/translations)

2025 å¹´æœ€åä¸€ä¸ªå­£åº¦ï¼ŒChatGPT çš„ç½‘ç«™æµé‡åŒæ¯”ä¸‹è·Œäº† 22%ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767828819090-c2356110-7d46-401f-9334-bce644608beb.png)

è¿™ä¸ªæ•°å­—æ¥è‡ª Similarweb åˆšåˆšå‘å¸ƒçš„å…¨çƒ AI è¡Œä¸šæµé‡è¿½è¸ªæŠ¥å‘Šï¼ˆ <https://www.similarweb.com/corp/wp-content/uploads/2026/01/attachment-Global-AI-Tracker-6.pdf> ï¼‰ï¼Œæ•°æ®æˆªæ­¢ 2026 å¹´ 1 æœˆ 2 æ—¥ã€‚ä½œä¸ºå…¨çƒæµé‡åˆ†æçš„æƒå¨æœºæ„ï¼Œä»–ä»¬çš„æ•°æ®ä¸€ç›´æ˜¯æŠ•èµ„è€…åˆ¤æ–­ç§‘æŠ€å…¬å¸çœŸå®çŠ¶å†µçš„é‡è¦å‚è€ƒã€‚

![](https://baoyu.io/uploads/2026-01-08-1767828798436-e256d02a-def5-44e2-babc-8f9d17e4679a.png)

ChatGPT æµé‡å‡ºç°ä¸¤ä½æ•°ä¸‹æ»‘ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„ä¿¡å·ã€‚

ã€1ã€‘è°åœ¨æ¶¨ï¼Œè°åœ¨è·Œ

å…ˆè¯´æ•°æ®å£å¾„ï¼šè¿™ä»½æŠ¥å‘Šè¿½è¸ªçš„æ˜¯ç½‘ç«™è®¿é—®é‡ï¼Œä¸åŒ…æ‹¬ API è°ƒç”¨å’Œç¬¬ä¸‰æ–¹é›†æˆã€‚å¦‚æœä½ é€šè¿‡ Cursorã€Claude Code è¿™ç±»å·¥å…·é—´æ¥ä½¿ç”¨æŸä¸ª AI æ¨¡å‹ï¼Œè¿™éƒ¨åˆ†ç»Ÿè®¡ä¸åˆ°ã€‚ä½†å³ä¾¿è€ƒè™‘åˆ°è¿™ä¸ªå±€é™æ€§ï¼Œå‡ å®¶ä¸»è¦ç©å®¶çš„èµ°åŠ¿ä»ç„¶å€¼å¾—ç»†çœ‹ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767828879550-ec30467c-ebec-4b2a-b998-54005016b5b5.png)

ChatGPT çš„ä¸‹æ»‘ä¸æ˜¯çªç„¶å‘ç”Ÿçš„ã€‚ä»å»å¹´ 8 æœˆåˆ°ä»Šå¹´ 1 æœˆï¼Œå®ƒçš„ 12 å‘¨åŒæ¯”å¢é•¿ç‡ä¸€è·¯èµ°ä½ï¼š+4%ã€+5%ã€+3%ï¼Œåæœˆä»½å¼€å§‹è½¬è´Ÿï¼Œ-2%ã€-4%ã€-8%ï¼Œåˆ°æœ€æ–°çš„ -22%ã€‚è¿™ä¸æ˜¯å­£èŠ‚æ€§æ³¢åŠ¨èƒ½è§£é‡Šçš„ã€‚åœ£è¯æ–°å¹´å‡æœŸç¡®å®ä¼šå½±å“æµé‡ï¼Œä½†å…¶ä»– AI äº§å“å¹¶æ²¡æœ‰å‡ºç°ç±»ä¼¼çš„å¤§å¹…ä¸‹è·Œã€‚æ›´é‡è¦çš„æ˜¯ï¼Œä¸‹æ»‘è¶‹åŠ¿ä»ç§‹å¤©å°±å¼€å§‹äº†ï¼Œå‡æœŸåªæ˜¯åŠ é€Ÿå™¨ã€‚

å¯èƒ½çš„è§£é‡Šæœ‰å‡ ä¸ªã€‚ä¸€æ˜¯ç«äº‰åŠ å‰§ï¼Œç”¨æˆ·å¼€å§‹æ ¹æ®ä¸åŒä»»åŠ¡é€‰æ‹©ä¸åŒå·¥å…·ï¼Œä¸å†æŠŠ ChatGPT å½“ä½œä¸‡èƒ½å…¥å£ã€‚äºŒæ˜¯â€œè¶…çº§åº”ç”¨â€å™äº‹æ­£åœ¨è¢«è§£æ„ï¼šä½ å¯èƒ½ç”¨ Claude å†™é•¿æ–‡ï¼Œç”¨ Perplexity æœèµ„æ–™ï¼Œç”¨ä¸“é—¨çš„ç¼–ç¨‹å·¥å…·å†™ä»£ç ï¼ŒChatGPT ä¸å†æ˜¯å”¯ä¸€é€‰æ‹©ã€‚

Gemini æ˜¯è¿™ä»½æŠ¥å‘Šé‡Œæœ€å¤§çš„èµ¢å®¶ã€‚49% çš„åŒæ¯”å¢é•¿ï¼Œå…¨å¹´å¤§éƒ¨åˆ†æ—¶é—´éƒ½ä¿æŒåœ¨ä¸¤ä½æ•°ä»¥ä¸Šã€‚è°·æ­Œåœ¨ AI é¢†åŸŸè¢«å˜²è®½äº†ä¸€æ•´å¹´ï¼Œè¯´å®ƒèµ·ä¸ªå¤§æ—©èµ¶ä¸ªæ™šé›†ï¼Œä½†æµé‡æ•°æ®ä¸ä¼šè¯´è°ã€‚è°·æ­Œçš„åˆ†å‘ä¼˜åŠ¿æ­£åœ¨å‘æŒ¥ä½œç”¨ï¼šæœç´¢ã€Chromeã€Androidã€‚å½“ä½ åœ¨ Google æœç´¢æ¡†é‡Œå°±èƒ½ç›´æ¥ç”¨ Geminiï¼Œå¾ˆå¤šç”¨æˆ·å°±æ‡’å¾—å†æ‰“å¼€å¦ä¸€ä¸ªç½‘ç«™äº†ã€‚

Claude çš„æ•°æ®è®²è¿°äº†ä¸€ä¸ªâ€œè¿‡å±±è½¦â€æ•…äº‹ã€‚ä» 8 æœˆåˆ° 10 æœˆï¼Œå¢é•¿å ªç§°æƒŠè‰³ï¼š33%ã€46%ã€42%ã€34%ã€35%ã€47%ï¼Œåˆ° 10 æœˆåº•è¾¾åˆ°å³°å€¼ 56%ã€‚è¿™æ®µæ—¶é—´æ­£å¥½æ˜¯ Anthropic å¯†é›†å‘å¸ƒæ–°åŠŸèƒ½çš„çª—å£æœŸï¼ŒåŒ…æ‹¬ Claude 3.5 Sonnet å‡çº§ã€Artifacts åŠŸèƒ½ã€Computer Use ç­‰ã€‚å¼€å‘è€…ç¤¾åŒºçš„å£ç¢‘å‘é…µï¼ŒåŠ ä¸Šâ€œClaude æ¯” GPT-4 æ›´é€‚åˆå†™ä»£ç â€çš„è¯´æ³•å¹¿æ³›ä¼ æ’­ï¼Œæ¨åŠ¨äº†æµé‡æŒç»­æ”€å‡ã€‚

ç„¶åç”»é£çªå˜ã€‚11 æœˆä¸­æ—¬å¼€å§‹ï¼Œå¢é€Ÿä» 49% éª¤é™åˆ° 16%ï¼Œ12 æœˆç¨³å®šåœ¨ 12% å·¦å³ï¼Œåˆ° 1 æœˆç›´æ¥å˜æˆ -14% çš„è´Ÿå¢é•¿ã€‚ä¸€éƒ¨åˆ†æ˜¯å‡æœŸæ•ˆåº”ï¼ŒClaude çš„ç”¨æˆ·ç¾¤ä½“ä»¥å¼€å‘è€…å’Œä¸“ä¸šäººå£«ä¸ºä¸»ï¼Œå¹´åº•æ´»è·ƒåº¦æœ¬æ¥å°±ä¼šä¸‹é™ã€‚å¦ä¸€éƒ¨åˆ†å¯èƒ½æ˜¯æ–°é²œæ„Ÿæ¶ˆé€€ï¼Œé‚£äº›å› ä¸ºå¥½å¥‡è€Œå°è¯•çš„ç”¨æˆ·ï¼Œè¯•ç”¨åå›å½’äº†åŸæ¥çš„å·¥å…·ã€‚

ä½†å³ä¾¿æœ€æ–°æ•°æ®æ˜¯ -14%ï¼ŒClaude åœ¨æ•´ä¸ª 2025 å¹´çš„ç´¯è®¡è¡¨ç°ä»ç„¶æ˜¯æ‰€æœ‰ä¸»æµ AI äº§å“ä¸­æœ€äº®çœ¼çš„ä¹‹ä¸€ã€‚å®ƒçš„ç”¨æˆ·åŸºæ•°æ¯”å¹´åˆå¤§äº†å¾ˆå¤šï¼Œ-14% æ˜¯åœ¨æ›´é«˜åŸºæ•°ä¸Šçš„å›è°ƒï¼Œä¸æ˜¯äº§å“æœ¬èº«å‡ºäº†é—®é¢˜ã€‚

Manus çš„æ•…äº‹å®Œå…¨ä¸åŒï¼Œå®ƒå±•ç¤ºäº† AI Agent èµ›é“çš„æ®‹é…·ç°å®ã€‚å¹´åˆæ›¾ç»å¼•å‘è¿‡ä¸€æ³¢è®¨è®ºçƒ­æ½®ï¼Œ8 æœˆåˆè¿˜æœ‰ 25% çš„åŒæ¯”å¢é•¿ã€‚ä½†æ¥ä¸‹æ¥å°±æ˜¯æ¼«é•¿çš„ä¸‹æ»‘ï¼š2%ã€-11%ã€-19%ã€-23%ã€-17%ã€-16%â€¦â€¦åˆ° 11 æœˆæ‰å‹‰å¼ºè§¦åº•ã€‚

è¿™æ¡æ›²çº¿éå¸¸å…¸å‹ã€‚AI Agent è¿™ä¸ªæ¦‚å¿µåœ¨ 2025 å¹´è¢«ç‚’å¾—å¾ˆçƒ­ï¼Œå‡ ä¹æ¯å®¶å…¬å¸éƒ½åœ¨è®²â€œAgent æ˜¯ä¸‹ä¸€ä¸ªå¤§äº‹ä»¶â€ã€‚ä½†è½åœ°åˆ°å…·ä½“äº§å“ä¸Šï¼Œç”¨æˆ·çš„è€å¿ƒæœ‰é™ã€‚å¦‚æœ Agent ä¸èƒ½çœŸæ­£å®Œæˆå¤æ‚ä»»åŠ¡ï¼Œå¦‚æœé”™è¯¯ç‡è®©äººæŠ“ç‹‚ï¼Œå¦‚æœæ¯æ¬¡ä½¿ç”¨éƒ½éœ€è¦å¤§é‡äººå·¥å¹²é¢„ï¼Œç”¨æˆ·å¾ˆå¿«å°±ä¼šæµå¤±ã€‚

Manus æœ€è¿‘å‡ ä¸ªæœˆå¼€å§‹å›æš–ï¼š-2%ã€-1%ã€1%ï¼Œåˆ°æœ€æ–°çš„ 12%ã€‚è¿™å¯èƒ½è¯´æ˜å›¢é˜Ÿåœ¨äº§å“ä¸Šåšäº†æ”¹è¿›ï¼Œä¹Ÿå¯èƒ½è¯´æ˜ AI Agent çš„æ•´ä½“å¯ç”¨æ€§åœ¨æå‡ã€‚

æŠŠ Claude å’Œ Manus æ”¾åœ¨ä¸€èµ·çœ‹ï¼Œèƒ½å¾—å‡ºä¸€ä¸ªåˆ¤æ–­ï¼šåœ¨ AI è¿™ä¸ªèµ›é“ï¼Œâ€œæ¨¡å‹å³äº§å“â€æ¯”â€œAgent å³äº§å“â€æ›´å®¹æ˜“å»ºç«‹ç¨³å®šçš„ç”¨æˆ·åŸºç¡€ã€‚Agent çš„æ„¿æ™¯å¾ˆç¾å¥½ï¼Œä½†å®ƒå¯¹åº•å±‚èƒ½åŠ›çš„è¦æ±‚æ›´é«˜ï¼Œç”¨æˆ·çš„å®¹é”™ç©ºé—´æ›´å°ã€‚Claude å³ä¾¿ä¸‹æ»‘ï¼Œå¹´æµé‡ä»ç„¶æ˜¯æ­£çš„ï¼›Manus å¤§éƒ¨åˆ†æ—¶é—´éƒ½åœ¨è´Ÿå¢é•¿åŒºé—´æŒ£æ‰ã€‚Agent æ²¡æœ‰æœªæ¥å—ï¼Ÿå½“ç„¶ä¸æ˜¯ã€‚åªæ˜¯é‚£ä¸€å¤©æ˜¾ç„¶è¿˜æ²¡åˆ°ã€‚

å¦å¤–å‡ ä¸ªç©å®¶ï¼šGrok ä¸€è·¯ç‹‚é£™ï¼Œä» 8 æœˆçš„ 9% æ¶¨åˆ° 1 æœˆçš„ 52%ï¼Œé©¬æ–¯å…‹çš„ X å¹³å°ç»™å®ƒå¸¦æ¥äº†æµ·é‡æ›å…‰ï¼›Perplexity åœ¨ç»å†äº†å¹´ä¸­çš„é«˜é€Ÿå¢é•¿åï¼Œæœ€æ–°æ•°æ®è·Œåˆ°äº† -27%ï¼Œå¯èƒ½æ­£é¢ä¸´è°·æ­Œå’Œ OpenAI æœç´¢åŠŸèƒ½çš„å¤¹å‡»ï¼›Meta AI è™½ç„¶æœ€æ–°æ•°æ®åªæœ‰ -3% çš„å°å¹…ä¸‹æ»‘ï¼Œä½†åä¸€æœˆå’ŒåäºŒæœˆæ›¾æœ‰è¶…è¿‡ 100% çš„åŒæ¯”å¢é•¿ï¼Œè¯´æ˜ Meta æŠŠ AI æ•´åˆè¿› Facebookã€Instagramã€WhatsApp çš„ç­–ç•¥æ­£åœ¨è§æ•ˆã€‚

ã€2ã€‘AI ç¼–ç¨‹å·¥å…·ï¼šæ³¡æ²«è¿˜æ˜¯çœŸéœ€æ±‚

![](https://baoyu.io/uploads/2026-01-08-1767828925492-f56a0e99-95d5-4f08-854a-133ea643ad7d.png)

Code Completion & DevOps è¿™ä¸ªå“ç±»çš„æ•°æ®å¾ˆæœ‰æ„æ€ã€‚æ•´ä½“æ¥çœ‹ï¼Œè¿™ä¸ªèµ›é“åœ¨ç»å†äº†å»å¹´çš„å¤§å¹…ä¸‹æ»‘åï¼Œæœ€è¿‘å‡ ä¸ªæœˆå¼€å§‹ä¼ç¨³å›å‡ï¼Œ12 å‘¨å˜åŒ–ä» -31% ä¸€è·¯æ”¹å–„åˆ° +9%ã€‚

å…·ä½“åˆ°äº§å“å±‚é¢ï¼Œåˆ†åŒ–éå¸¸æ˜æ˜¾ã€‚

Lovable å¼‚å†›çªèµ·ï¼Œä»å¹´åˆçš„å¤§å¹…ä¸‹è·Œï¼ˆ-50%ï¼‰ä¸€è·¯æ¢å¤åˆ°ç°åœ¨çš„ +23%ã€‚è¿™æ˜¯ä¸€ä¸ªä¸»æ‰“â€œè‡ªç„¶è¯­è¨€ç”Ÿæˆåº”ç”¨â€çš„å·¥å…·ï¼Œå®šä½æ¯”ä¼ ç»Ÿä»£ç è¡¥å…¨æ›´é«˜ä¸€å±‚ï¼šä½ å‘Šè¯‰å®ƒæƒ³åšä»€ä¹ˆï¼Œå®ƒå¸®ä½ æŠŠæ•´ä¸ªåº”ç”¨æ­å‡ºæ¥ã€‚

Cursor ç¨³ä½äº†ã€‚è¿™ä¸ªè¢«å¼€å‘è€…ç¤¾åŒºè¿½æ§çš„ AI ç¼–è¾‘å™¨ï¼Œåœ¨ç»å†äº†ä¸ŠåŠå¹´çš„æµé‡ä¸‹æ»‘åï¼Œæœ€è¿‘ä¸‰ä¸ªæœˆä¿æŒåœ¨ 8-10% çš„æ­£å¢é•¿ã€‚æ ¸å¿ƒç”¨æˆ·ç¾¤ä¼¼ä¹å¾ˆç¨³å®šï¼Œè¯´æ˜äº§å“ç¡®å®è§£å†³äº†çœŸå®ç—›ç‚¹ã€‚

Base44 æ˜¯æ•°æ®é‡Œæœ€ç–¯ç‹‚çš„ä¸€ä¸ªï¼Œæ¶¨å¹…åŠ¨è¾„å‡ ç™¾ä¸Šåƒä¸ªç™¾åˆ†ç‚¹ã€‚ä½†è¦æ³¨æ„ï¼Œè¿™ç§çˆ†å‘å¼å¢é•¿å¾€å¾€æ˜¯å› ä¸ºåŸºæ•°å¤ªå°ï¼Œä¸èƒ½è¯´æ˜å¤ªå¤šé—®é¢˜ã€‚

Bolt çš„è¡¨ç°ä»¤äººæ‹…å¿§ï¼ŒæŒç»­ä¸‹è·Œåˆ° -39%ã€‚ä½œä¸ºæ—©æœŸæ˜æ˜Ÿäº§å“ä¹‹ä¸€ï¼Œå®ƒä¼¼ä¹æ­£åœ¨è¢«æ–°ç©å®¶å–ä»£ã€‚Windsurfï¼ˆ-6%ï¼‰ã€Tabnineï¼ˆ-25%ï¼‰ã€Cognitionï¼ˆ-22%ï¼Œå°±æ˜¯åš Devin é‚£å®¶ï¼‰çš„æµé‡éƒ½åœ¨ä¸‹æ»‘ã€‚AI ç¼–ç¨‹å·¥å…·èµ›é“çš„ç«äº‰æå…¶æ®‹é…·ï¼Œç”¨æˆ·å¿ è¯šåº¦å¾ˆä½ï¼Œä¸€æ—¦æœ‰æ›´å¥½çš„æ›¿ä»£å“å‡ºç°å°±ä¼šå¿«é€Ÿæµå¤±ã€‚

æ³¨æ„ç”±äº Similarweb ä¸»è¦ç»Ÿè®¡çš„ç½‘ç»œæµé‡ï¼Œæ‰€ä»¥è¿™é‡Œé¢ç¼ºå°‘ Claude Code å’Œ Codex Cli çš„æ•°æ®ã€‚

æ•´ä½“åˆ¤æ–­ï¼šAI ç¼–ç¨‹å·¥å…·çš„éœ€æ±‚æ˜¯çœŸå®çš„ï¼Œä½†å…·ä½“äº§å“çš„æŠ¤åŸæ²³å¾ˆæµ…ã€‚è¿™ä¸ªèµ›é“ä¼šæŒç»­æ´—ç‰Œï¼Œä»Šå¤©çš„æ˜æ˜Ÿå¯èƒ½å°±æ˜¯æ˜å¤©çš„å¼ƒå­ã€‚

ã€3ã€‘AI å†™ä½œï¼šè¢«é€šç”¨ AI åƒæ‰çš„èµ›é“

Writing & Content Generation çš„æ•°æ®å¾ˆæƒ¨ï¼Œæ•´ä½“ -10%ï¼Œå‡ ä¹æ‰€æœ‰ç©å®¶éƒ½åœ¨ä¸‹æ»‘ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767828986799-e54e49cb-1780-4f3d-a818-f68b7c32ebde.png)

æœ€æƒ¨çš„æ˜¯ Growthbarseoï¼Œç›´æ¥ä» +60% è·Œåˆ° -100%ï¼Œæµé‡å½’é›¶ã€‚è¿™æ˜¯ä¸€ä¸ª SEO å†™ä½œå·¥å…·ï¼Œæ˜¾ç„¶è¢« ChatGPT å’Œå…¶ä»–é€šç”¨ AI å½»åº•å–ä»£äº†ã€‚Jasperï¼ˆ-16%ï¼‰ã€Wordtuneï¼ˆ-16%ï¼‰ã€Writesonicï¼ˆ-17%ï¼‰è¿™äº›æ›¾ç»çš„æ˜æ˜Ÿäº§å“ï¼Œè·Œå¹…éƒ½åœ¨ 15-20% ä¹‹é—´ã€‚Writer ä» +15% éª¤è·Œåˆ° -38%ï¼ŒSurferseo ä» +4% è·Œåˆ° -23%ã€‚

å”¯ä¸€çš„äº®ç‚¹æ˜¯ Originalityï¼Œæ¶¨äº† 17%ã€‚è¿™æ˜¯ä¸€ä¸ª AI å†…å®¹æ£€æµ‹å·¥å…·ï¼Œä¸“é—¨ç”¨æ¥è¯†åˆ«æ–‡ç« æ˜¯ä¸æ˜¯ AI å†™çš„ã€‚è®½åˆºå§ï¼ŸAI å†™ä½œå·¥å…·åœ¨è¡°è½ï¼Œæ£€æµ‹ AI å†™ä½œçš„å·¥å…·åè€Œåœ¨å¢é•¿ã€‚å¸‚åœºå¯¹â€œAI ç”Ÿæˆå†…å®¹æ³›æ»¥â€çš„æ‹…å¿§æ­£åœ¨è½¬åŒ–ä¸ºçœŸå®éœ€æ±‚ã€‚

è¿™ä¸ªèµ›é“çš„æ•™è®­å¾ˆæ¸…æ™°ï¼šå¦‚æœä½ çš„äº§å“åªæ˜¯åœ¨é€šç”¨ AI å¤–é¢åŒ…äº†ä¸€å±‚å£³ï¼ŒåŠ äº†å‡ ä¸ªæ¨¡æ¿ï¼Œè¿Ÿæ—©ä¼šè¢«å¹²æ‰ã€‚ç”¨æˆ·ä¼šç›´æ¥å»ç”¨ ChatGPT æˆ– Claudeï¼Œæ²¡å¿…è¦å¤šç»•ä¸€é“ã€‚AI å†™ä½œå·¥å…·çš„å´©æºƒæ˜¯æ‰€æœ‰â€œAI å¥—å£³â€äº§å“çš„å‰è½¦ä¹‹é‰´ã€‚

ã€4ã€‘AI ç»˜å›¾ï¼šæ›¾ç»çš„é¡¶æµæ­£åœ¨é€€çƒ§

![](https://baoyu.io/uploads/2026-01-08-1767829008984-57566539-6bb3-425b-b808-c63f84a4944f.png)

Design & Image Generation è¿™ä¸ªèµ›é“çš„æ•´ä½“æ•°æ®æ˜¯ -10%ï¼Œè¿™å¯èƒ½æ˜¯æœ€è®©äººæ„å¤–çš„ã€‚è¦çŸ¥é“ï¼Œä¸¤å¹´å‰ AI ç»˜å›¾å‡ ä¹æ˜¯ç”Ÿæˆå¼ AI çš„ä»£åè¯ï¼ŒMidjourney çš„ Discord æœåŠ¡å™¨ä¸€åº¦æ˜¯å…¨çƒæœ€æ´»è·ƒçš„ç¤¾åŒºä¹‹ä¸€ã€‚

ç°åœ¨å‘¢ï¼ŸMidjourney ä» 8 æœˆçš„ +33% ä¸€è·¯è·Œåˆ° -16%ã€‚Leonardoï¼ˆ+2%ï¼‰å‹‰å¼ºæŒå¹³ï¼ŒDeepaiï¼ˆ-33%ï¼‰ã€Ideogramï¼ˆ-22%ï¼‰å¤§å¹…ä¸‹æ»‘ã€‚æ•´ä¸ªèµ›é“åœ¨è¿‡å»å…­ä¸ªæœˆæ²¡æœ‰ä¸€ä¸ªæœˆæ˜¯æ­£å¢é•¿çš„ã€‚

AI ç»˜å›¾çš„â€œç©å…·æœŸâ€å¯èƒ½å·²ç»è¿‡å»äº†ã€‚é‚£äº›å› ä¸ºå¥½å¥‡è€Œå°è¯•çš„ç”¨æˆ·å·²ç»ç¦»å¼€ï¼Œå‰©ä¸‹çš„æ˜¯çœŸæ­£æœ‰åˆ›ä½œéœ€æ±‚çš„äººç¾¤ï¼Œè€Œè¿™ä¸ªç¾¤ä½“çš„è§„æ¨¡æ¯”æƒ³è±¡ä¸­å°ã€‚å¦ä¸€ä¸ªå› ç´ æ˜¯ï¼Œé€šç”¨ AI å·¥å…·ï¼ˆChatGPTã€Claudeï¼‰ç°åœ¨éƒ½å†…ç½®äº†å›¾åƒç”Ÿæˆèƒ½åŠ›ï¼Œç”¨æˆ·ä¸éœ€è¦å†ä¸“é—¨å»è®¿é—® Midjourney çš„ç½‘ç«™ã€‚

ä¸è¿‡æœ‰ä¸€ä¸ªå¼‚ç±»ï¼šSkylum æ¶¨äº† 67%ã€‚è¿™æ˜¯ä¸€ä¸ªä¸“æ³¨äºç…§ç‰‡åæœŸå¤„ç†çš„ AI å·¥å…·ï¼Œå®šä½æ¯”â€œä»é›¶ç”Ÿæˆå›¾ç‰‡â€æ›´å®ç”¨ã€‚è¿™æš—ç¤ºäº†ä¸€ä¸ªæ–¹å‘ï¼šAI å›¾åƒå·¥å…·çš„æœªæ¥å¯èƒ½ä¸æ˜¯â€œç”Ÿæˆâ€ï¼Œè€Œæ˜¯â€œå¢å¼ºâ€ã€‚å¸®ä½ æŠŠç…§ç‰‡ä¿®å¾—æ›´å¥½çœ‹ï¼Œæ¯”å‡­ç©ºç”Ÿæˆä¸€å¼ å›¾æ›´æœ‰æŒç»­ä»·å€¼ã€‚

è¦æ³¨æ„çš„æ˜¯ï¼Œnano banana pro å…¶å®å¸¦æ¥äº†å¾ˆå¤§ä¸€æ³¢æµé‡ï¼Œè¿™æ³¢æµé‡åº”è¯¥è¢« Similarweb ç®—åœ¨ Gemini é‡Œé¢äº†ã€‚

ã€5ã€‘AI è§†é¢‘ï¼šç¨³å®šä½†åˆ†åŒ–å‰§çƒˆ

![](https://baoyu.io/uploads/2026-01-08-1767829072510-1778ccbf-f10e-4f46-9bd0-94c94e55abb2.png)

Video Generation æ•´ä½“å¢é•¿ 5%ï¼Œçœ‹èµ·æ¥è¿˜ç®—å¥åº·ï¼Œä½†å†…éƒ¨åˆ†åŒ–éå¸¸å‰§çƒˆã€‚

å¿«æ‰‹æ——ä¸‹çš„å¯çµï¼ˆKlingaiï¼‰æ˜¯æœ€å¤§èµ¢å®¶ï¼Œ+36%ã€‚è¿™ä¸ªå·¥å…·åœ¨å›½å†…å’Œæµ·å¤–éƒ½è·å¾—äº†ä¸é”™çš„å£ç¢‘ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆè¿è´¯åŠ¨ä½œè§†é¢‘æ–¹é¢ã€‚Typecast æ¶¨äº† 53%ï¼Œå®ƒä¸“æ³¨äº AI è™šæ‹Ÿäººæ’­æŠ¥ï¼Œæ‰¾åˆ°äº†ä¸€ä¸ªç›¸å¯¹å‚ç›´çš„åœºæ™¯ã€‚HeyGenï¼ˆ+8%ï¼‰å’Œ Synthesiaï¼ˆ+13%ï¼‰ä¹Ÿä¿æŒäº†æ­£å¢é•¿ï¼Œå®ƒä»¬éƒ½èšç„¦åœ¨â€œæ•°å­—äºº + è§†é¢‘â€è¿™ä¸ªä¼ä¸šçº§åº”ç”¨åœºæ™¯ã€‚

ä½† Runwayï¼Œè¿™ä¸ªä¸€åº¦è¢«è§†ä¸º AI è§†é¢‘æ ‡æ†çš„äº§å“ï¼Œè·Œäº† 32%ã€‚Captions è·Œäº† 37%ï¼ŒDescript è·Œäº† 10%ã€‚

ä¸€ä¸ªæ˜æ˜¾çš„ç°è±¡ï¼šé‚£äº›å®šä½â€œé€šç”¨è§†é¢‘ç”Ÿæˆâ€çš„å·¥å…·æ™®éè¡¨ç°ä¸ä½³ï¼Œè€Œèšç„¦ç‰¹å®šåœºæ™¯ï¼ˆæ•°å­—äººã€è™šæ‹Ÿä¸»æ’­ã€ç‰¹æ•ˆç´ æï¼‰çš„å·¥å…·åè€Œæ´»å¾—ä¸é”™ã€‚è§†é¢‘ç”Ÿæˆå¯èƒ½è¿˜æ²¡åˆ°â€œä¸€ä¸ªå·¥å…·æ‰“å¤©ä¸‹â€çš„é˜¶æ®µï¼Œå‚ç›´åœºæ™¯çš„æœºä¼šæ›´å¤§ã€‚

ã€6ã€‘å…¶ä»–å€¼å¾—å…³æ³¨çš„ä¿¡å·

![](https://baoyu.io/uploads/2026-01-08-1767829105491-59b17887-ea92-4c2c-ba8f-2ed42bfc6056.png)

éŸ³ä¹ç”Ÿæˆæ˜¯æ‰€æœ‰ AI ç»†åˆ†é¢†åŸŸé‡Œå¢é€Ÿæœ€å¿«çš„ï¼Œæ•´ä½“æ¶¨äº† 30%ã€‚Suno ä¸€éª‘ç»å°˜ï¼ˆ+46%ï¼‰ï¼Œå‡ ä¹å æ®äº†è¿™ä¸ªèµ›é“çš„åŠå£æ±Ÿå±±ã€‚è¾“å…¥å‡ å¥è¯å°±èƒ½ç”Ÿæˆå®Œæ•´çš„æ­Œæ›²ï¼ŒåŒ…æ‹¬äººå£°ã€ç¼–æ›²ã€æ··éŸ³ï¼Œè´¨é‡å·²ç»åˆ°äº†â€œèƒ½å¬â€çš„ç¨‹åº¦ã€‚å½“ç„¶ï¼Œç‰ˆæƒé—®é¢˜æ˜¯æ‚¬åœ¨å¤´ä¸Šçš„è¾¾æ‘©å…‹åˆ©æ–¯ä¹‹å‰‘ï¼ŒSuno å’Œ Udio éƒ½é¢ä¸´è¯‰è®¼ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767829094809-3453d8d5-be93-477d-adbf-30a00405bcbd.png)

è¯­éŸ³ AI ä¹Ÿåœ¨å›æš–ï¼Œæ•´ä½“æ¶¨äº† 14%ã€‚ElevenLabs ç»§ç»­é¢†è·‘ï¼ˆ+27%ï¼‰ï¼Œè¯­éŸ³å…‹éš†è´¨é‡ç¡®å®ç”©å¼€ç«äº‰å¯¹æ‰‹ä¸€å¤§æˆªï¼Œè€Œä¸”åœ¨æ’­å®¢ã€æœ‰å£°ä¹¦ã€æ¸¸æˆé…éŸ³ç­‰é¢†åŸŸæ‰¾åˆ°äº†çœŸå®çš„ä»˜è´¹åœºæ™¯ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767829120961-6dac05d5-fba2-48da-8776-03b2283eb7c4.png)

è‡ªåŠ¨åŒ–å·¥å…·é›†ä½“ä¸‹æ»‘ï¼Œn8nï¼ˆ-27%ï¼‰ã€Zapierï¼ˆ-24%ï¼‰ã€Makeï¼ˆ-11%ï¼‰éƒ½å‡ºç°äº†ä¸¤ä½æ•°ä¸‹è·Œã€‚ä¸€ä¸ªå¯èƒ½çš„è§£é‡Šæ˜¯ï¼šé€šç”¨ AI æ­£åœ¨åå™¬ä¸€éƒ¨åˆ†ç®€å•è‡ªåŠ¨åŒ–çš„éœ€æ±‚ã€‚ä»¥å‰ä½ éœ€è¦ç”¨ Zapier è¿æ¥å„ç§æœåŠ¡ï¼Œç°åœ¨ç›´æ¥è®© AI å†™æ®µä»£ç å°±æå®šäº†ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767829140072-79013626-9bad-440d-975f-d1b430a09db6.png)

AI æ—…è¡Œè§„åˆ’é›·å£°å¤§é›¨ç‚¹å°ï¼Œæ•´ä½“ -4%ã€‚Mindtrip ä» +153% æš´è·Œåˆ° -6%ï¼Œè¿™ä¸ªèµ›é“æ›¾ç»è¢«å¯„äºˆåšæœ›ï¼Œä½†æ—…è¡Œæ˜¯ä½é¢‘å†³ç­–ï¼Œè€Œä¸” Googleã€æºç¨‹è¿™äº›å·¨å¤´éƒ½åœ¨å¾€è‡ªå·±äº§å“é‡Œå¡ AI åŠŸèƒ½ï¼Œç‹¬ç«‹çš„ AI æ—…è¡Œåº”ç”¨å¾ˆéš¾æ´»ä¸‹æ¥ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767829446886-924cd19e-8e15-4232-b144-9b4c57c9a43c.png)

Browserï¼ˆæµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼‰æ•´ä½“æš´è·Œ22%ï¼ŒBrowserbaseä»+58%è·Œåˆ°-41%â€”â€”AI Agentçš„"åŸºç¡€è®¾æ–½"æ¦‚å¿µå¾ˆæ€§æ„Ÿï¼Œä½†ç¦»çœŸæ­£è¢«ç”¨èµ·æ¥è¿˜æœ‰å¾ˆé•¿çš„è·¯ï¼Œè¿™ä¸ªèµ›é“ç›®å‰æ›´å¤šæ˜¯å¼€å‘è€…åœ¨è¯•éªŒï¼Œæ™®é€šç”¨æˆ·æ ¹æœ¬ä¸çŸ¥é“å®ƒå­˜åœ¨ã€‚

ã€7ã€‘é‚£äº›â€œè¢« AI é¢ è¦†â€çš„è¡Œä¸š

æŠ¥å‘Šçš„ååŠéƒ¨åˆ†è¿½è¸ªäº†å‡ ä¸ªè¢«è®¤ä¸ºä¼šè¢« AI å†²å‡»çš„ä¼ ç»Ÿè¡Œä¸šï¼Œç»“è®ºå¯èƒ½å’Œä½ æƒ³çš„ä¸å¤ªä¸€æ ·ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767829191850-cd3713a4-4267-4dc7-8117-b2e402442574.png)

ä¼ ç»Ÿæœç´¢ï¼ˆè°·æ­Œã€å¿…åº”ç­‰ï¼‰æ•´ä½“ç¨³å®šåœ¨ -3% å·¦å³ï¼Œæ²¡æœ‰å´©ç›˜è¿¹è±¡ã€‚è°·æ­Œå‡ ä¹çº¹ä¸ä¸åŠ¨ï¼ˆ-1% åˆ° -2%ï¼‰ã€‚å¿…åº”åè€Œè·Œå¾—æ›´å‰å®³ï¼ˆ-12%ï¼‰ï¼Œè®½åˆºçš„æ˜¯è¿™æ­£æ˜¯å¾®è½¯æ•´åˆ AI æœ€æ¿€è¿›çš„äº§å“ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767829246504-3a5496d5-2c11-44c7-b164-43dc786a7b7c.png)

æ•°å­—è‡ªç”±èŒä¸šå¹³å°ï¼ˆFiverrã€Upworkï¼‰ä»å¹´ä¸­çš„ -6% åˆ° -9% ä¸€è·¯æ”¹å–„åˆ° 0%ã€‚è¿™å‡ºä¹å¾ˆå¤šäººé¢„æ–™ï¼Œå¤§å®¶ä»¥ä¸º AI ä¼šè®©è‡ªç”±èŒä¸šè€…å¤±ä¸šï¼Œä½†è‡³å°‘ä»æµé‡çœ‹ï¼Œè¿™äº›å¹³å°çš„ç”¨æˆ·å¹¶æ²¡æœ‰å¤§è§„æ¨¡æµå¤±ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767829233150-0fe93971-bee2-4ac5-ab78-f9409a53c3e9.png)

åœ¨çº¿æ•™è‚²ï¼ˆUdemyã€Courseraã€Duolingoï¼‰æ•´ä½“ä» -8% æ”¹å–„åˆ° +2%ã€‚ä¼ ç»Ÿæ•™è‚²å¹³å°å±•ç°å‡ºæ¯”é¢„æœŸæ›´å¼ºçš„éŸ§æ€§ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767829261477-a99cd555-c99f-4088-a9d3-c4cc25cd7159.png)

å›¾åº“åª’ä½“ï¼ˆShutterstockã€Gettyï¼‰æ•´ä½“ç¨³å®šåœ¨ -3% å·¦å³ï¼Œæ²¡æœ‰å› ä¸º AI å›¾åƒç”Ÿæˆå·¥å…·è€Œå´©æºƒã€‚

![](https://baoyu.io/uploads/2026-01-08-1767829276771-1767f15a-5063-4d22-8aa2-2f2c0fe307e1.png)

è®¾è®¡å¹³å°ï¼ˆCanvaã€Figmaï¼‰ä»ç„¶ä¿æŒ 15% ä»¥ä¸Šçš„æ­£å¢é•¿ï¼Œè™½ç„¶å¢é€Ÿåœ¨æ”¾ç¼“ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767829464373-8b2af69d-5382-4f85-a7c1-0e45f1048883.png)

Web & Shop Buildersï¼ˆå»ºç«™å·¥å…·ï¼‰Squarespaceï¼ˆ+19%ï¼‰å’ŒSquareï¼ˆ+17%ï¼‰é€†åŠ¿å¢é•¿ï¼ŒWixã€Shopifyã€Woocommerceé›†ä½“ä¸‹æ»‘ï¼ŒAIå»ºç«™å·¥å…·ï¼ˆLovableã€Boltï¼‰æ­£åœ¨åˆ†æµé‚£äº›"åªæƒ³å¿«é€Ÿæ­ä¸ªç½‘ç«™"çš„ç”¨æˆ·ï¼Œä½†éœ€è¦å“ç‰Œè°ƒæ€§å’Œæ·±åº¦å®šåˆ¶çš„é«˜ç«¯éœ€æ±‚åè€Œæ›´ç¨³ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767829479217-1488f1d5-2e78-4bb3-bdc9-550dd4f17323.png)

Discussion & Q&A Forumsï¼ˆè®¨è®ºè®ºå›ï¼‰Redditä¸€æç‹¬ç§€ï¼ˆ+12%ï¼‰ï¼ŒQuoraè·Œæ‰ä¸€åŠï¼ˆ-53%ï¼‰ï¼Œå½“AIèƒ½ç›´æ¥å›ç­”é—®é¢˜ï¼Œè°è¿˜å»ç¿»åˆ«äººçš„æ—§å¸–å­ï¼Ÿ

è¿™äº›æ•°æ®ç»™å‡ºä¸€ä¸ªæé†’ï¼šAI å¯¹ä¼ ç»Ÿè¡Œä¸šçš„å†²å‡»æ˜¯çœŸå®çš„ï¼Œä½†é€Ÿåº¦æ¯”åª’ä½“æ¸²æŸ“çš„è¦æ…¢å¾—å¤šã€‚â€œé¢ è¦†â€æ˜¯ä¸€ä¸ªæ¼«é•¿çš„è¿‡ç¨‹ï¼Œä¸æ˜¯ä¸€å¤œä¹‹é—´å‘ç”Ÿçš„äº‹ã€‚

ã€8ã€‘å‡ æ¡è§„å¾‹

æŠŠæ‰€æœ‰èµ›é“æ”¾åœ¨ä¸€èµ·çœ‹ï¼Œæœ‰å‡ ä¸ªè§„å¾‹æµ®ç°å‡ºæ¥ï¼š

ç¬¬ä¸€ï¼Œâ€œå·¥å…·åŒ–â€çš„ AI åº”ç”¨æ¯”â€œç©å…·åŒ–â€çš„ AI åº”ç”¨æ›´æœ‰ç”Ÿå‘½åŠ›ã€‚è¯­éŸ³ã€éŸ³ä¹è¿™ç±»è§£å†³çœŸå®ç”Ÿäº§åŠ›é—®é¢˜çš„å·¥å…·åœ¨å¢é•¿ï¼Œè€Œç»˜å›¾ã€æ—…è¡Œè§„åˆ’è¿™ç±»æ»¡è¶³ä¸€æ—¶å¥½å¥‡çš„åº”ç”¨åœ¨è¡°é€€ã€‚

ç¬¬äºŒï¼Œå‚ç›´åœºæ™¯æ¯”é€šç”¨åœºæ™¯æ›´å®¹æ˜“å»ºç«‹å£å’ã€‚AI è§†é¢‘é‡Œæ´»å¾—å¥½çš„æ˜¯æ•°å­—äººå·¥å…·ï¼ŒAI å›¾åƒé‡Œæ´»å¾—å¥½çš„æ˜¯ç…§ç‰‡å¢å¼ºå·¥å…·ï¼Œè€Œä¸æ˜¯â€œä»€ä¹ˆéƒ½èƒ½åšâ€çš„é€šç”¨ç”Ÿæˆå™¨ã€‚

ç¬¬ä¸‰ï¼Œæ‰€æœ‰â€œåŒ…è£…å±‚â€äº§å“éƒ½é¢ä¸´è¢«é€šç”¨ AI åå™¬çš„é£é™©ã€‚AI å†™ä½œå·¥å…·çš„å´©æºƒæ˜¯å‰è½¦ä¹‹é‰´ï¼Œè‡ªåŠ¨åŒ–å·¥å…·å¯èƒ½æ˜¯ä¸‹ä¸€ä¸ªã€‚

ç¬¬å››ï¼Œâ€œæ¨¡å‹å³äº§å“â€æ¯”â€œAgent å³äº§å“â€æ›´ç¨³ã€‚Claude å³ä¾¿ä¸‹æ»‘ï¼Œå…¨å¹´ä»ç„¶æ˜¯æ­£å¢é•¿ï¼›Manus å¤§éƒ¨åˆ†æ—¶é—´éƒ½åœ¨è´Ÿå¢é•¿åŒºé—´æŒ£æ‰ã€‚Agent çš„æ„¿æ™¯å¾ˆç¾å¥½ï¼Œä½†é‚£ä¸€å¤©è¿˜æ²¡åˆ°ã€‚

![](https://baoyu.io/uploads/2026-01-08-1767829837084-d80d1113-a3f8-461e-8a8b-dfa76b5850cb.png)

ã€9ã€‘æœ€å

è¿™ä»½æŠ¥å‘Šçš„æ ¸å¿ƒä¿¡æ¯å…¶å®å¾ˆç®€å•ï¼šAI è¡Œä¸šæ­£åœ¨ä»â€œæ‰€æœ‰èˆ¹åªéƒ½ä¸Šæ¶¨â€çš„æ—©æœŸç‹‚çƒ­ï¼Œè¿›å…¥â€œå„å‡­æœ¬äº‹â€çš„æ®‹é…·ç«äº‰é˜¶æ®µã€‚

ChatGPT çš„æµé‡ä¸‹æ»‘ä¸æ„å‘³ç€ AI è§é¡¶ï¼Œè€Œæ˜¯æ„å‘³ç€å¸‚åœºæ­£åœ¨åˆ†åŒ–ã€‚ç”¨æˆ·å˜å¾—æ›´æŒ‘å‰”ï¼Œå¼€å§‹ä¸ºä¸åŒä»»åŠ¡é€‰æ‹©ä¸åŒå·¥å…·ã€‚èµ¢è€…é€šåƒçš„æ ¼å±€æ²¡æœ‰å½¢æˆï¼Œåè€Œæ˜¯ç¾¤é›„å¹¶èµ·çš„å±€é¢ã€‚

å¯¹æ™®é€šç”¨æˆ·æ¥è¯´ï¼Œè¿™æ˜¯å¥½æ¶ˆæ¯ï¼Œç«äº‰æ„å‘³ç€æ›´å¤šé€‰æ‹©ã€æ›´ä½ä»·æ ¼ã€æ›´å¿«è¿­ä»£ã€‚

å¯¹ä»ä¸šè€…å’ŒæŠ•èµ„è€…æ¥è¯´ï¼Œè¿™ä»½æŠ¥å‘Šçš„ä»·å€¼åœ¨äºæä¾›äº†ä¸€ä¸ªç›¸å¯¹å®¢è§‚çš„è§†è§’ï¼Œè®©æˆ‘ä»¬ä¸è‡³äºè¢«ç¤¾äº¤åª’ä½“ä¸Šçš„ç‹‚çƒ­æˆ–æ‚²è§‚æƒ…ç»ªå¸¦åã€‚

æµé‡ä¸æ˜¯ä¸€åˆ‡ï¼Œä½†æµé‡ä¸ä¼šæ’’è°ã€‚

hidden text to trigger resize events if fonts change

---

# [äº”æ¡0108] Gemini CLI æ–°å¢ Agent Skillsï¼ŒAI ä¹Ÿèƒ½å­¦ä¸“ä¸šæŠ€èƒ½äº†ï¼
å‘å¸ƒæ—¥æœŸï¼š2026/01/08

Note:  
Gemini CLI æ›´æ–°é¢„è§ˆç‰ˆæ”¯æŒ Agent Skills  

_Note: This is an experimental feature enabled via `experimental.skills`. You can also search for â€œSkillsâ€ within the `/settings` interactive UI to toggle this and manage other skill-related settings._

Agent Skills allow you to extend Gemini CLI with specialized expertise, procedural workflows, and task-specific resources. Based on the [Agent Skills](https://agentskills.io) open standard, a â€œskillâ€ is a self-contained directory that packages instructions and assets into a discoverable capability.

Unlike general context files ([GEMINI.md](https://geminicli.com/docs/cli/gemini-md)), which provide persistent project-wide background, Skills represent **on-demand expertise**. This allows Gemini to maintain a vast library of specialized capabilitiesâ€”such as security auditing, cloud deployments, or codebase migrationsâ€”without cluttering the modelâ€™s immediate context window.

Gemini autonomously decides when to employ a skill based on your request and the skillâ€™s description. When a relevant skill is identified, the model â€œpulls inâ€ the full instructions and resources required to complete the task using the tool.`activate_skill`

* **Shared Expertise:** Package complex workflows (like a specific teamâ€™s PR review process) into a folder that anyone can use.
* **Repeatable Workflows:** Ensure complex multi-step tasks are performed consistently by providing a procedural framework.
* **Resource Bundling:** Include scripts, templates, or example data alongside instructions so the agent has everything it needs.
* **Progressive Disclosure:** Only skill metadata (name and description) is loaded initially. Detailed instructions and resources are only disclosed when the model explicitly activates the skill, saving context tokens.

Gemini CLI discovers skills from three primary locations:

1. **Project Skills** (): Project-specific skills that are typically committed to version control and shared with the team.`.gemini/skills/`
2. **User Skills** (): Personal skills available across all your projects.`~/.gemini/skills/`
3. **Extension Skills**: Skills bundled within installed [extensions](https://geminicli.com/docs/extensions).

**Precedence:** If multiple skills share the same name, higher-precedence locations override lower ones: **Project > User > Extension**.

Use the slash command to view and manage available expertise:`/skills`

* `/skills list` (default): Shows all discovered skills and their status.
* `/skills disable <name>`: Prevents a specific skill from being used.
* `/skills enable <name>`: Re-enables a disabled skill.
* `/skills reload`: Refreshes the list of discovered skills from all tiers.

_Note: `/skills disable` and `/skills enable` default to the `user` scope. Use `--scope project` to manage project-specific settings._

The command provides management utilities:`gemini skills`

Terminal window

```
# Enable/disable skills. Can use --scope to specify project or usergemini skills enable my-expertisegemini skills disable my-expertise
```

A skill is a directory containing a file at its root. This file uses YAML frontmatter for metadata and Markdown for instructions.`SKILL.md`

```
description: <what the skill does and when Gemini should use it><your instructions for how the agent should behave / use the skill>
```

* **`name`**: A unique identifier (lowercase, alphanumeric, and dashes).
* **`description`**: The most critical field. Gemini uses this to decide when the skill is relevant. Be specific about the expertise provided.
* **Body**: Everything below the second is injected as expert procedural guidance for the model.`---`

```
user asks for "feedback," a "review," or to "check" their changes.1.  **Analyze**: Review the staged changes or specific files provided. Ensure3.  **Security**: Flag any potential security vulnerabilities.4.  **Tests**: Verify that new logic has corresponding test coverage and that
```

While you can structure your skill directory however you like, the Agent Skills standard encourages these conventions:

* **`scripts/`**: Executable scripts (bash, python, node) the agent can run.
* **`references/`**: Static documentation, schemas, or example data for the agent to consult.
* **`assets/`**: Code templates, boilerplate, or binary resources.

When a skill is activated, Gemini CLI provides the model with a tree view of the entire skill directory, allowing it to discover and utilize these assets.

1. **Discovery**: At the start of a session, Gemini CLI scans the discovery tiers and injects the name and description of all enabled skills into the system prompt.
2. **Activation**: When Gemini identifies a task matching a skillâ€™s description, it calls the tool.`activate_skill`
3. **Consent**: You will see a confirmation prompt in the UI detailing the skillâ€™s name, purpose, and the directory path it will gain access to.
4. **Injection**: Upon your approval:  
   * The body and folder structure is added to the conversation history.`SKILL.md`  
   * The skillâ€™s directory is added to the agentâ€™s allowed file paths, granting it permission to read any bundled assets.
5. **Execution**: The model proceeds with the specialized expertise active. It is instructed to prioritize the skillâ€™s procedural guidance within reason.

hidden text to trigger resize events if fonts change

---

# [äº”æ¡0108] Claude Code 2.1.1 æ›´æ–°ï¼Œå¼€å‘å·¥ä½œæµå¤§å‡çº§ï¼
å‘å¸ƒæ—¥æœŸï¼š2026/01/08

Claude Code è¿­ä»£å¾ˆå¿«ï¼Œå·²ç»åˆ°äº† 2.1.1 ç‰ˆæœ¬ï¼Œè¿™æ¬¡æœ‰ä¸€å †æ›´æ–°ï¼Œä¸‰ä¸ªå€¼å¾—å…³æ³¨çš„æ›´æ–°ï¼š

1ï¼‰æŠ€èƒ½çƒ­é‡è½½ç»ˆäºæ¥äº†ã€‚æ”¹å®Œ skills æ–‡ä»¶å¤¹é‡Œçš„ä¸œè¥¿ç«‹åˆ»ç”Ÿæ•ˆï¼Œä¸ç”¨é‡å¯ session

2ï¼‰æ–°å¢ context: fork é€‰é¡¹ï¼ŒæŠ€èƒ½å’Œæ–œæ å‘½ä»¤å¯ä»¥åœ¨ç‹¬ç«‹å­æ™ºèƒ½ä½“é‡Œè·‘ï¼Œä¸æ±¡æŸ“ä¸»å¯¹è¯ä¸Šä¸‹æ–‡ã€‚é‚£äº›éœ€è¦å¤§é‡ä¸­é—´æ­¥éª¤ä½†ä½ ä¸æƒ³çœ‹å…¨è¿‡ç¨‹çš„ä»»åŠ¡ï¼Œç°åœ¨å¹²å‡€å¤šäº†

3ï¼‰å­æ™ºèƒ½ä½“ï¼ˆTask å·¥å…·ï¼‰è¢«æ‹’ç»æƒé™åä¸å†ç›´æ¥èººå¹³ï¼Œä¼šè‡ªå·±å°è¯•å…¶ä»–æ–¹æ¡ˆç»§ç»­å¹²æ´»ã€‚è¿™è®© agentic å·¥ä½œæµæ›´æœ‰éŸ§æ€§ï¼Œä¸ä¼šå› ä¸ºä¸€ä¸ªæƒé™å¡ä½æ•´ä¸ªæµç¨‹  

[Claude Code Changelog](https://twitter.com/ClaudeCodeLog) [@ClaudeCodeLog](https://twitter.com/ClaudeCodeLog) 

[ ](https://twitter.com/ClaudeCodeLog/status/2009019697459585133) 

Chat, we are so back ğŸš€ğŸš€ğŸš€ for real this time lol

Anthropic just released

Claude Code 2.1.1

109 CLI, 11 flag, and 10 prompt changes, details below.

[Posted Jan 7, 2026 at 9:49PM](https://twitter.com/ClaudeCodeLog/status/2009019697459585133) 

hidden text to trigger resize events if fonts change