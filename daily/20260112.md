# [五条0112] Figma CEO：AI时代，设计才是王道
发布日期：2026/01/08

Note:  
Figma CEO @zoink 分享了对 AI 在创意和软件开发中角色的思考，强调人类意图与工艺的重要性，而非完全依赖 AI。  

Thoughts:

  
1. In the future, the probability something is generated entirely by AI will be inversely proportional to its intended lifespan.
  
2. For conceptually simple artifacts that are intended to have short lifespans, humans will still be involved just at a different level of abstraction. For example, I'm super excited about [@Weavy\_ai](https://twitter.com/Weavy%5Fai) (Figma Weave) because it shows what's possible when you treat AI generation like clay to shape rather than the final output. Workflow building is a new skill to explore and learn.
  
3. If you intend for an artifact to have a long lifespan (ex: software, a novel, a movie), then AI might still aid you in your creative process. But you will bring great intention to the work. You will think through many different approaches. You will care about the smallest of details. You will lean into the craft. Because if you don't, it won't be good enough to last. It won't be noticed. It won't be loved. It won't matter.
  
4. Focusing just on software now... people don't like it when software changes. Everyone who has shipped a redesign knows this! So you might be generating new content within a piece of software frequently but of course you wouldn't redesign the fundamental UX of the software all the time. Users would hate it.
  
  
As a grounding metaphor, consider a house. Yes, you might change the photos and papers and magnets stuck to your fridge a few times a week. Once in a while, you reorganize stuff or move furniture around. After living in the house for a while, you maybe notice issues around how you use the space and — with great intention — embark on a remodel.

Some parts of the house, like the fridge, change a lot. But the overall structure of the house changes less. When asking what will be generated by AI, don't confuse the whole for the parts, the long lasting for the ephemeral.

  
1. It's intellectually interesting to think about whether a brand might want to adapt their software on a user by user basis. (Certainly individuals will be able to make more software for themselves if they are so inclined. For example, see Figma Make.)
  
  
That said, my strong gut right now is that we will not end up in a world where brands customize software on a per user basis. 

People learn how to use software from other humans. Snapchat is a great example. For a new user, Snapchat is kind of confusing. You can see this as a design issue or an advantage... I argue it's an advantage.

By leaning into custom patterns and a learnable (but arguably non-intuitive) interface, the resulting network is a more intentional space. If you're young, you'll learn how to use Snapchat by watching your friends use Snapchat. And if you're older, well, you might not be the intended demographic.

  
1. To wrap up... we are in a world where the amount of software is growing at an exponential rate. If you want to win, design is the differentiator. Invest in design, craft, storytelling and a bold point of view.
  
  
Use AI as a tool, but don't expect it to build the next big thing for you on its own. Don't expect it to make something that no one has ever seen or imagined before. That's your job.  

[Guillermo Rauch](https://twitter.com/rauchg) [@rauchg](https://twitter.com/rauchg) 

[ ](https://twitter.com/rauchg/status/2009324546294468769) 

All software will be generative and generated.  
Adjust accordingly.

[Posted Jan 8, 2026 at 6:01PM](https://twitter.com/rauchg/status/2009324546294468769) 

hidden text to trigger resize events if fonts change

---

# [五条0112] AI 设计提效：渐进式披露
发布日期：2026/01/09

![](https://miro.medium.com/v2/resize:fit:1400/1*0JeBTq5Y1v1hu7JuUnVq_w.png)

Progressive disclosure is a well-known principle in UX design. This principle is about _showing users only what they need right now_, and _revealing more options or information gradually_ as they interact or gain context. The goal is to reduce cognitive load, keep interfaces clean and approachable, and still support advanced use cases when needed.

The principle of progressive disclosure can be applied not only to the user interfaces we design, but also AI tools we use. In this article, I will show you how to use progressive disclosure to maximize the efficiency of your AI tools.

## Why use progressive disclosure?

Before we dive into how-to, it’s important to answer a key question: “_Why do we want to use progressive disclosure in the first place?_” The reason for using the principle is pretty much the same as for UX design: to keep context clean and relevant to the task at hand. And by ‘_context_’ I mean the context window that the AI tool uses when it processes your task.

> Context window is the maximum amount of information an AI model can “see”, remember, and reason over at one time, including your prompt, instructions, conversation history, and any pasted documents.

Think of context window as the AI’s working memory.

There are two main problems with the context window:

* _Limited size._ Context window has a limited number of tokens. For example, Claude 4.5 has a standard context window of 200,000 tokens (approximately 150,000 words or over 500 pages of material). Once you exceed this limit, older or extra information is ignored, truncated, or summarized, which can directly affect output quality.
* _Too much noise._ The context window can be populated with irrelevant data over time. AI will use all the data you provide when generating output, and if you have a lot of irrelevant data, it will lead to poor quality output (this is known as “garbage in, garbage out”).

Progressive disclosure can help with both problems.

## How to use progressive disclosure

I will demonstrate how to use progressive disclosure using NotebookLM for user research of a digital product.

![](https://miro.medium.com/v2/resize:fit:2000/1*i69rXwwFtYAPqypsfxX07g.png)

NotebookLM for user research of a product called FocusFlow.

### Get rid of noise

Information that isn’t needed for the task at hand shouldn’t be included in the context window. This is the most important rule to follow when using AI tools. When it comes to user research in NotebookLM, it means 4 things:

**\[1\]** _Isolate context windows._ If you’re doing two different research tasks isolated from each other, the worst thing you can do is to mix two context windows. The rule of thumb is to keep _one notebook per project._ This will help both you and AI navigate the research field.

**\[2\]** _Maintain a manageable number of sources_. NotebookLM allows you to upload up to 300 data sources (ie, interview transcripts, product analytics, specs). Although this number looks impressive, some teams have a much larger collection of data sources, and they struggle to add them to the system. If you have this problem too, my advice is to moderate your data sources. Many times you can combine a few sources together and, what is even more important, get rid of outdated data sources.

**\[3\]** Structure your data sources (make sure you use a structure that helps you quickly figure out what this data source is and whether you need to use it for your task at hand). I typically use Metadata headers for my files that contain essential information about the data source. Below is an example of metadata for the interview transcript:

Participant_Name: Jane Smith  
Participant_Role: Senior Sales Designer  
Company_Type: B2B SaaS (50–200 employees)  
Interview_Type: Generative / Discovery  
Date: 2026-01-05  
Interviewer: Nick  
Context: Exploring user pain points  

**\[4\]** When you’re solving a specific research task, choose only sources that are relevant to this task (don’t use Select All)

![](https://miro.medium.com/v2/resize:fit:1392/1*TGLtZLBiIRPaOhRlRfsVMQ.png)

Select all sources” is a menu with all data sources that NotebookLM uses to answer your question. You have complete control of what sources should be used (can add/remove any sources from this list).

### Provide clarity for AI not only on what should be done, but also how it should be done

Just like a real human researcher benefits from a well-defined research process, tools like NotebookLM demonstrate the best results when you clearly outline the process that the tool should use when analyzing data.

It’s worth having NotebookLM validate the output it generates against the checklist you provide. For example, you can submit the following checklist to AI and ask it to double-check the output it generates for you using this checklist:

Data Provenance & Input Quality  
  
⬜ Are all source inputs clearly listed (interviews, surveys, reports, transcripts)?  
⬜ Are sources first-hand research (not assumptions or secondary blog posts)?  
⬜ Is the data recent enough to be relevant?  
⬜ Are participant counts, roles, and contexts explicitly stated?  
  
Traceability (Insight → Evidence)  
  
⬜ Can each insight be traced back to specific quotes, observations, or data points?  
⬜ Are direct user quotes included where appropriate?  
⬜ Are insights separated from interpretations?  
⬜ Are assumptions clearly labeled as assumptions?  
  
Confidence & Uncertainty Markers  
  
⬜ Does the output acknowledge data gaps?  
⬜ Are confidence levels or sample limitations stated?  
⬜ Are hypotheses clearly marked vs validated insights?  
⬜ Are recommendations framed as testable assumptions?  

This is particularly helpful for complex research tasks that cover a very valuable area of your product design (where your decisions will have high risk).

### Use the right AI-friendly data formats

Data formatting is perhaps one of the most overlooked topics in AI-powered product design. All too often, we use data in its original, raw format. But this is not optimal for AI as data formats impact token count (and size of context window) and efficiency of AI (i.e., tools like Claude demonstrate better results when data is structured in XML format).

When it comes to user research, I suggest using the following data formats:

**YAML.** This is the most token-efficient data format. It works really well for data analytics results. For example, you can submit the following YAML file as a data source for your website analytics.

analytics_report:  
  service_name: "NexusTask Web Dashboard"  
  environment: "Production"  
  reporting_period:  
    start_date: 2025-12-01  
    end_date: 2025-12-31  
  
user_engagement_metrics:  
  monthly_active_users (MAU): 125400  
  daily_active_users (DAU): 18200  
  stickiness_ratio (DAU/MAU): 14.5%  
  avg_session_duration: "00:08:45"  
  bounce_rate: 32.4%  
  
traffic_sources:  
  - channel: "Organic Search"  
    sessions: 45000  
    conversion_rate: 3.2%  
  - channel: "Direct"  
    sessions: 32000  
    conversion_rate: 5.1%  
  - channel: "Referral"  
    sessions: 12000  
    conversion_rate: 2.8%  
  - channel: "Social Media"  
    sessions: 8500  
    conversion_rate: 1.5%  
  
user_behavior_funnel:  
  stage_1_landing: 100000  
  stage_2_sign_up_page: 25000  
  stage_3_account_created: 5000  
  stage_4_first_action_completed: 3200  
  overall_conversion_pct: 3.2  
  
device_distribution:  
  desktop: 72%  
  mobile_web: 25%  
  tablet: 3%  

**Markdown.** Great format for documentation and foundational research rules. We can use this format for data sources like product specification.

# Product Specification: User Analytics Dashboard v2.0  
  
## 1. Document Overview  
| Field | Details |  
| :--- | :--- |  
| **Project Owner** | Product Team |  
| **Status** | In-Review |  
| **Last Updated** | 2026-01-09 |  
| **Target Release** | Q1 2026 |  
  
---  
  
## 2. Product Vision  
To provide our B2B customers with real-time visibility into how their end-users are interacting with the web service, specifically focusing on retention and conversion friction points.  
  
## 3. Core Features  
  
### 3.1 Real-Time User Activity Feed  
* **Description:** A live stream of events (page views, button clicks, sign-ups).  
* **Requirement:** Events must appear in the dashboard within < 2 seconds of occurrence.  
* **Logic:** Uses a WebSocket connection to the analytics engine.  
  
### 3.2 Automated Funnel Visualization  
* **Description:** Allow users to define a 3-5 step path and see drop-off rates.  
* **User Story:** *As a Product Manager, I want to see where users stop during the onboarding process so I can optimize the UI.*  
  
### 3.3 Cohort Analysis Table  
* **Description:** A heatmap showing user retention over a 6-week period.  
* **Data Source:** `user_sessions` and `retention_logs` tables.  
  
---  
  
## 4. Technical Requirements  
  
### 4.1 Data Schema  
The analytics module must ingest data in the following format:  
* `user_id`: UUID  
* `event_type`: String (e.g., "click", "page_view")  
* `timestamp`: ISO 8601  
* `metadata`: JSONB  
  
### 4.2 Performance Constraints  
* Dashboard must load within **1.5 seconds** for date ranges up to 30 days.  
* Exporting data to CSV should handle up to **100,000 rows** without timing out.  
  
---  
  
## 5. User Interface (UI) Design  
* **Theme:** Light/Dark mode compatibility.  
* **Charts:** Use `Recharts` library for responsive SVG rendering.  
* **Navigation:** Accessible via the sidebar under the "Insights" tab.  
  
---  
  
## 6. Success Metrics (KPIs)  
1.  **Dashboard DAU:** Target 40% of all admin users.  
2.  **Export Frequency:** Target at  

And finally, XML. This format works exceptionally well for Claude as it was optimized to recognize content containers. When it comes to using NotebookLM, we can use this format not for the data but for prompts (i.e, when conducting additional research in context of the existing notebook).

<research_mission>  
    <persona>  
        Act as a Senior Research Analyst and Strategic Consultant. Your goal is to synthesize the provided sources into a high-level intelligence briefing that identifies non-obvious patterns, conflicting viewpoints, and actionable insights.  
    </persona>  
  
    <objective>  
        Conduct a "Deep Dive" analysis of the uploaded documents to uncover the core thesis of the collection, the strength of the evidence provided, and the specific gaps where the documents fail to provide a complete picture.  
    </objective>  
  
    <methodology>  
        <step>1. Cross-Reference: Identify where multiple sources agree on a key trend or fact.</step>  
        <step>2. Conflict Analysis: Highlight any contradictions or differing perspectives between authors/documents.</step>  
        <step>3. Evidence Weighting: Evaluate which claims are supported by hard data versus those based on anecdotal evidence.</step>  
        <step>4. Narrative Synthesis: Create a cohesive timeline or conceptual map of the subject matter.</step>  
    </methodology>  
  
    <output_configuration>  
        <format_requirements>  
            - Use Markdown headers for readability.  
            - Provide inline citations for every major claim using the [1], [2] format.  
            - Include a "Surprise & Insight" section for unexpected findings.  
            - End with a "Critical Gaps" section identifying what the sources DON'T tell us.  
        </format_requirements>  
  
        <structure>  
            ## Executive Summary  
            [Provide a 3-sentence high-level overview]  
  
            ## Key Pillars of Research  
            [Detail the 3-4 most significant themes found across all sources]  
  
            ## Comparative Analysis Table  
            [Create a table comparing how different sources approach the primary topic]  
  
            ## The "So What?" Factor  
            [Explain the real-world implications of these findings]  
  
            ## Critical Gaps & Missing Data  
            [What questions remain unanswered by these specific sources?]  
        </structure>  
    </output_configuration>  
  
    <constraints>  
        - Do not use outside knowledge; stay strictly "grounded" in the provided sources.  
        - If a source is ambiguous, state that it is ambiguous rather than making an assumption.  
        - Maintain a professional, objective, and analytical tone.  
    </constraints  

You can submit it in the prompt window in the left-hand panel:

![](https://miro.medium.com/v2/resize:fit:1400/1*1I1ZInJxA5_F_p_Z--UoMA.png)

## Want to learn more about AI-powered product design?

Enrol in my course, “[Product Design with AI](https://maven.com/babich/product-design-ai),” a 4-week, live cohort-based course where you’ll learn how to use AI tools to streamline your product design workflow, go from idea to ship-ready product, and become an AI-powered designer alongside a peer community and expert guidance.

[Product Design with AI by Nick Babich on Maven](https://maven.com/babich/product-design-ai?source=post%5Fpage-----978da0aaeb08---------------------------------------)

hidden text to trigger resize events if fonts change

---

# [五条0112] 唐杰/杨植麟/林俊旸/姚顺雨激辩：Agent是下一个战场
发布日期：2026/01/10

![](https://mmbiz.qpic.cn/mmbiz_jpg/2icSMc1VBIYrODyVvLGicJk1Do0OAOcaicNNKzYGJzq2JKYnCIwFu4XqzibqWiboXEI2iauTwVl5qxQJtIeJzOb9lEFQ/640?wx_fmt=jpeg#imgIndex=0)

中国 AI 全明星 

今天下午，AGI-Next 闭门峰会，汇集了中国 AI 行业全明星阵容

三场报告，分别来自**智谱唐杰**、**Kimi 杨植麟**、**Qwen 林俊旸**

**开源四大天王，三缺一**  
DeepSeek 由于众所周知的原因，无法出席

一场圆桌，参与者包括：**杨强**、**唐杰**、**林俊旸**、**姚顺雨**（远程连入）

最终的收尾，来自德高望重的**张钹院士**

![](https://mmbiz.qpic.cn/mmbiz_jpg/2icSMc1VBIYrODyVvLGicJk1Do0OAOcaicNoGG7ibvibGictNibNp0ibxUsQw9mdaRyPgB8xA4eboVQOpPIsLTSNBSe37A/640?wx_fmt=jpeg&from=appmsg#imgIndex=1)

活动日程 

AGI-Next 活动，由唐杰老师召集，独一档的号召力

我在现场，给大家带来了这份独家实录，共计4万余字

# 让机器像人一样思考

**演讲人：唐杰（智谱首席科学家、清华大学教授）**

今天这个活动更多的是个学术活动，所以我们没有前面太多的环节，咱们直接进入报告环节。

我自己这次要求大家、要求我们的团队没有主持人，不需要主持人。未来都是AI时代了，用AI主持，现在AI还没有做到，我先自我主持。第二个报告Kimi直接上来就行了，俊旸也直接上来，接下来是Panel，我开始我的报告。

我的报告题目，一方面是汇报我们这个基础实验室现在做的一些工作，另外一方面再给大家探讨一些想法和对未来的一些看法。我的题目是「让机器像人一样思考」，为什么这么说？其实我这个题目，当年我第一次提出来的时候，张钹院士是反对我的，说你不能老说让机器像人一样思考。但是我加了一个引号，所以现在可能允许我加引号说了。

### 智谱的起源与精神

我们从2019年开始在思考，我们能不能做到让机器像人一样真正在有可能的一点点的思考。所以2019年我们从清华成果转化，当时在学校的大力支持下，我们成立了**智谱**这么一家公司，我现在在智谱做首席科学家。我们也开源了很多，大家可以看到这里有开源的很多项目，左边还有很多关于大模型API调用的一些东西。

我在清华大概有20年，我2006年毕业，到今年正好20年。其实我一直在做的事情，我总结了一下也就两个事：**第一，当年做了AMiner系统；第二，现在在做的大模型。**

我一直有一个观点，我自己受影响也比较大，我把它叫做**像咖啡一样的精神来做事情**。其实那个事情跟今天在座的一位嘉宾非常相关，就是杨强教授。我记得我刚毕业的时候去港科大，去过的人都知道港科大就是一栋楼，会议室在里面、教室在里面、实验室也在里面、咖啡厅也在里面，吃饭的、打篮球的，都在这一栋楼里面。当时我们老能碰到，有一次在咖啡厅碰到以后，我就说这两天咖啡喝的非常多，是不是要戒一戒，要不然对身体不好。杨老师第一句话是说「对，应该戒一戒」，然后他说也不对，如果我们做研究能像你喝咖啡上瘾，是不是我们研究就做的非常好了？

当时喝咖啡上瘾这个事情一下子对我触动非常大，而且从2008年影响我到现在，也就是**做事情可能就是要专注，一直做下去**。这一次正好有幸碰到AGI这个事情，正好是需要长期投入、长期做的一件事，它不是短平快，今天我做了，明天就能开花结果，后天就结束了，它非常长期，恰恰值得来投入。

我们实验室2019年的时候在图神经网络、知识图谱方面，其实我们在国际上做的还行，但当时我们坚定地把这两个方向暂停了，暂时不做了，**所有的人都转向做大模型**，所有的人开始启动了大模型相关的研究。到今天做了一点点事情。

### 大模型智能水平的演进

大家也知道全球化，其实这张图是在2025年2月份，在整个大模型发展史上，我们把它叫**智能水平**，这个智能水平已经大大提高了。

从早期的2020年，其实我们看到一些很简单的像MMU和QA的一些问题，当时已经很不错了，到今天基本可以做到非常满分的程度。慢慢地，从最早期一些简单的问题，到了2021、2022年开始做一些数学题、一些需要推理——也就是加减乘除才能做对的问题，这时候我们可以看到模型通过后训练，慢慢地，现在也把这些问题补齐了，而且能力也大大提高。

再到2023、2024年，大家看到模型的发展从原来的只是一些知识记忆，到简单的数学推理，到更复杂的，甚至可以做一些研究生的问题，甚至开始回答一些我们真实世界的问题。比如说**SWE Bench**里面，其实已经做了很多真实世界的编程问题。这时候我们可以看到模型的能力，智能水平越来越复杂，就像人成长一样——一开始我们在小学里面多看书，慢慢地做数学题，慢慢到了初高中，我们回答一些研究生的复杂推理问题。再到毕业之后，我们开始完成工作上的一些问题，更难的一些问题。

到今年大家可以看到，HLE（人类终极测试）这个任务里面特别难，如果大家去看HLE里面，甚至有些问题连谷歌也找不到，比如说世界上某一个鸟的某一个耻骨的某一个什么，连谷歌也找不到这个页面，所以需要这个模型泛化出来。这时候该怎么做？现在也没有答案，但大家可以看到，它的能力在2025年快速得到提升。

### 从Scaling到泛化

另外一方面，我们可以看到这个模型，什么叫从**Scaling到泛化**？我们人一直都希望机器有泛化能力，我教它一点点，它就能举一反三，其实就和人一样。我们在教一个小孩子的时候，我们总希望教小孩子三个问题，他就会第四个、会第十个，甚至连原来没教过的也会，这时候我们怎么来做？

直到今天，我们的目标是希望通过Scaling让它有更强的泛化能力，但是直到今天它的泛化能力还有待大大的提高，我们在不同的层面在提高它。

**最早期**的时候我们用Transformer训一个模型，把所有的知识记忆下来。我们训的数据越多，我们训的算力越多，它的**长时知识的记忆能力**越强，也就是说它把世界上所有的知识都背下来了，并且有一定的泛化能力，可以抽象，可以做简单的推理。于是你要问一个问题，中国的首都是什么？这时候模型不需要推理，它只是从知识库里拿出来。

**第二层**是把这个模型进行**对齐和推理**，让这个模型有更复杂的推理能力以及理解我们的意图。我们需要持续的Scaling SFT，甚至强化学习。通过人类大量的数据反馈，我们在Scaling反馈数据，让这个模型可以变的更聪明、变的更准确。

**今年是RLVR（可验证奖励强化学习）爆发年**。今年我们通过可验证的强化学习，原来为什么这个事情很难做呢？因为原来我们通过人类反馈，我们只能通过人类反馈数据来做，但人类反馈的数据里面噪音也非常多，而且场景也非常单一。但如果我们有一个可验证的环境，这时候我们可以让机器自己去探索、自己去发现这个反馈数据，自己来成长。

这里面难题的难题，大家一听就知道，说可验证是什么意思？比如说可验证，数学也许可以验证、编程可能可以验证，但更广泛的，比如我们说做了一个网页，这个网页好不好看，这时候可能就不大好验证了，它需要人来判断。于是，我们现在**可验证的RLVR面临的问题**是什么？原来可验证的场景也许逐渐地不够用了，我们能不能到一些半自动可以验证，甚至不可验证的一些场景里面，让这个模型变的更加通用，这是我们面临的一个挑战。

未来机器慢慢地开始在物理世界做一些真实的任务，这些真实的任务，我们怎么来构建智能体的环境？这是面临的更多的一些挑战。大家可以看到这几年AI在沿着这几个方面，不仅仅是简单的Transformer，其实整个AI已经变成了一个大的系统、一个智能化的系统。

### 从Chat到做事：新范式的开启

从原来更多的是数理化的一些推理，从简单的小学、初中、高中到更复杂的GPQA理化生的复杂问题，到更难的甚至是一些奥赛金牌的问题，到今年大家可以看到HLE非常高难度的智能评测基准，现在在开始进行快速的提升。

另外一方面在真实的环境下，像今天很多人都在说代码能力特别强，而且能完成很多真实的代码。但事实上在2021年代码模型也存在，当时还跟俊旸、Kimi植麟有很多合作，当时也做出了很多这种模型。其实当时的Coding模型也可以编程，但当时的编程能力远远不如现在，甚至当时编十个程序也许对一个，但现在可能编一个程序，很多时候能自然的跑通，而且是一个非常复杂的任务，到今天我们现在已经开始用代码来帮助高级的工程师完成更复杂的一些任务。

大家可能会问，是不是智能越来越强，我们直接把模型不停地训就行了？其实也不是。大家知道2025年初发生了什么，2025年初**DeepSeek**出来，很多时候叫**横空出世**，我觉得这个词用的挺好的，真是叫横空出世。可能对我们研究界、对产业界，甚至对很多人都是，因为大家原来在这个学术界、产业界都没有料到DeepSeek会突然出来，而且确实性能很强，而且一下子让很多人感到很震撼。

后来我们在2025年初的时候当时在想一个问题，也许在DeepSeek这种范式下，把这种**Chat时代基本上差不多算是解决了**，也就是说我们做的再好，也许在Chat的问题上可能做到最后跟DeepSeek差不多，或许我们在上面再个性化一点，变成有情感的Chat，或者再复杂一点。但是总的来讲，这个范式可能基本上到这快到头了，剩下更多的反而是工程和技术上的问题。

当时我们面临这么一个选择，我们怎么让这个AI下一步朝向哪个方向发展？我们当时的想法也许**新的范式是让每个人能够用AI做一件事情**，这可能是下一个范式，原来是Chat，现在是真的做事了，所以新的范式开启了。

### 技术路线的选择：Thinking + Agentic + Coding

还面临的选择，因为这个范式开启，有很多种开启方法。大家还记得年初的时候，我记得有两个问题：一个是简单的编程，做Coding、做Agent；第二是我们可以用AI来帮我们做研究，类似于DeepResearch，甚至写一个复杂的研究报告。这两条思路可能还不大一样，这也是一个选择的结果。一方面是做Thinking，我们加上一些Coding的场景；另外一方面可能要跟环境交互，让这个模型变的更加交互、更加生动，怎么来做？

后来我们选了左边这条路，我们让它有Thinking能力。但是我们也没有放弃右边，我们大概在**7月28号**做了一件事情，相对来讲还比较成功的，把**Coding、Agentic、Reasoning**能力整合在一起了。整合在一起可能也没那么容易，原来一般来讲大家做模型的时候，Coding相对来讲可能单独拿出去做，Coding变成Coding，推理变成推理，甚至有时候会数学变成数学，但这种做法往往会损失掉其他的能力。所以我们当时是把这三个能力基本上合在一起，让三个能力都相对比较平衡，在7月28号我们发布了**4.5版本**，这个版本在当时用12个Benchmark，我们在智能体、推理、代码上，基本上跑出来还算比较不错的一个结果。所有的模型，我们在国内，包括今天千问和Kimi，其实都是你追我赶，有时候这个在前面，有时候那个在前面，在当时那一天，我们排在前面。

### 真实环境下的挑战与突破

但是很快我们就把这个4.5开放出来让大家用，大家拿去编程吧，我们现在这个能力还挺不错的。既然我们选择了Coding和Agent，它就能做很多编程任务，我们就让它来编这种非常复杂的一些场景。结果发现用户跟我们反馈说，比如说我们要编一个**植物大战僵尸**，这个模型编不出来。

因为真实的环境下往往非常复杂，这个游戏是用一个Prompt自动生成的，包括整个游戏就可以玩，用户可以点击怎么来得分，选择什么样的植物以及怎么来打僵尸，僵尸从右边走过来，包括界面、包括后台的逻辑，全部是用这个程序自动一句话写出来的。这时候4.5在这个场景下做不出来，出了很多Bug，怎么回事？

后来我们发现在真实的编程环境下，它里面有很多问题，比如说在上面这种编辑环境下有很多问题需要解决，这时候恰恰利用到**RLVR可验证的强化学习环境**。于是我们在这里面搜集到大量的编程环境，通过编程环境作为强化，再加上一些SFT数据，使得这一块可以两方交互，把这个模型的效果提高。另外一方面，我们在Vibe方面也做了一些工作，把Vibe的一些能力也利用Vibe环境，加上一些反馈，加上环境可验证。总的来讲是通过可验证来探索，于是我们当时在SWE Bench上得到了很不错的分，包括最近我们也得到了很不错的分。

但这个模型的跑分是跑分，进入主模型又是一个非常大的挑战。很多人都有一个Benchmark，说我这个Benchmark分很高，但是真正这个能力进入主模型的还面临更多的一些挑战，而且在真实的体感中，用户体感还不一定效果好。

另外一个挑战，既然有这么多大量的RL任务，怎么把它全部统一训练在一起？因为不同的任务的长度都不一样，时间长度也不一样。所以我们当时开发了一个**全异步的训练强化学习框架**，怎样使得它异步的开始跑起来，这是我们在今年开源的另外一个框架里面的一个工作。这也使得Agent和Coding能力得到了很多的提升，最终的结果，我们最近发布的**4.7**，相比原来的4.6和4.5在Agent和Coding方面大大提升。

在体感方面更重要，为什么？因为你真的把Coding模型开放出去以后，用户用的跟你的跑分还不完全一样。今天可能是他自己的程序，我这个程序可能在我这个数据上做一个排序算法，效果好不好，体感好不好，他用的是这个结果，用的不是分值有多高。所以在真实的跑分下，我们也进行了详细的评测，这个评测完全是人工来做的，找了非常多编程高手来做评测。当然这里面还没有解决，还面临很多问题要解决。

最后我们把这些能力整合到一起，2025年底我们在**Artificial Analysis榜单**上跑出了一个还不错的分，得到了还可以的分。

### Device Use：从编程到操控设备

另一方面，我们又随着进一步发展，你要把这个问题在Agent环境下真的让它大规模用起来。大家可以看作Agent最基础的能力，什么叫最基础的能力？编程嘛，计算机编完程以后，它就可以执行，相当于Agent里面的一个action或者两个action。但如果你要做的更复杂，左边是Claude发布的**computer use**，中间是豆包手机，右边是Manus做的异步超长的任务。

假如你要让这个机器帮你做几十步、上百步的任务，甚至你说「请帮我搜集一下今天关于清华大学在小红书上所有的讨论，讨论完以后，关于某某的全部整理出来，给我生成相关的文档」，这时候AI得在一天监控小红书。它是自动的、完全异步，你不可能把手机打开盯着它，它是异步的，它是个非常复杂的任务。这样非常复杂的任务，总而言之，可以把刚才的问题变成一个**Device Use**，也就是在整个设备上我们怎么来做。

这里面更大的一个挑战，有些人说是不是更多的是采数据？其实更大的问题是很多应用根本就没有数据，全部是代码，全部是**冷启动**，这时候该怎么办？当然我们更希望我们通过这些数据能够一下子泛化出去。

所以最早的确实是我们采了大量的数据，上千个数据，我们来进行整合，包括SFT，包括在特定领域的强化，使得它在某些领域上可以把效果做的不错。但是更多的时候你会发现原来的iPhone use都是点按钮，但是更多的时候AI交互不是人。我们原来都把AI当作一个人，说AI能不能帮我们操作手机，但是你要想一下，其实这个AI不需要操作手机，更多的是API。但是现在你又不可能把手机变成纯API的系统，没有这个按钮了，所以这时候该怎么办？

我们采用**混合的方式，把API跟GUI两个混在一起**，对AI比较友好的时候采用API的方式，有时候对人友好的时候，让AI模拟人来做GUI的操作方式。于是把这两个整合在一起，我们在大量的环境里面抽取到大量的数据，并进行全异步的强化学习，这样就把整个东西给整合在一起，使得这个AI有一定的泛化能力。我刚刚说有一定的泛化能力，原因是说直到今天这个泛化能力都还差的很多、都还差的很远，但是它有一定的泛化能力了。

更重要的是我们怎么克服冷启动带来的一些问题，比如如果说我们的数据不够，我们通过强化学习有可能把它带入一个陷阱。这个强化学习到最后，它整个学到以后，这个模型就像钻牛角尖一样，它就认死理，说我就要这样，效果一下就跑偏了。这时候怎么把它拉回来？于是我们把**SFT在中间穿插了一步**，也就使得这个模型强化一段时间，再做一些SFT，再强化一点，变成一个交替的，使得它有一定的容错能力和有一定把它拉回来的能力，变成可扩展的训练算法。在移动环境下，我们使得效果在安卓里面取得不错的提升。

另外在多任务的大模型强化学习上，我们也做了一定的工作，在算法上主要采用多轮的强化学习，工程上本质上就是Scaling，让它更大规模的往下。

### AutoGLM开源

今年我们大概在12月份的时候开源了**AutoGLM**，把里面所有的东西都开源。大家注意我们开源的这个模型是**9B模型**，不是一个超级大的模型，原因是9B可以在人机交互里面动作特别快，执行速度特别快，如果特别大的话，它的执行速度就会很慢。所以我们开源了一个9B的模型，这个模型一开源，当时一下子就获得了两万多个star，而且三天就拿了一万多个star，还算不错。

这是一个例子，比如说我们下周要去长春玩，帮我们总结一下当前页面推荐的一些景点，然后到高德地图上收藏这几个景点，包括查看票价，再去12306订一张10点钟从北京去长春的高铁票，把相关信息整理好给我。这个模型在后台会执行**40步**，它会调用不同的APP，把不同的APP打开，然后输入相关的信息，相关查询、执行，整个操作40步执行完之后，把所有的东西全部给你。相当于这个AI做了一个类似于你的秘书的事情，整个全部执行下来。

更重要的是在所有的Device-use里面有几个榜单，包括OSWorld、Browser use、Mobile use相关的一些Bench，我们都取得了很不错的效果。其实你可以把这个模型想象成用了很多Agent数据在训，我们在9B的模型上用了很多Agent数据在训，其实它把原来的很多语言能力、推理能力可能会降低，也就是说它不再是纯通用的模型，它可能在Agent方面能力比较强，但是在其他方面可能会减弱。于是给我们带来一个新的问题，在未来这种超大规模的Agent模型上怎么来使得它不要降低，这变成一个新的问题。

### 2025年：GLM开源年与中国开源模型的贡献

我们2025年也是**GLM的开源年**，我们大概从1月份到12月份开源了很多模型，包括语言模型、智能体模型，还有我们多模态的模型，GLM-4.6、4.6V、4.5V等相关的一些模型。

而且更重要的是我们可以看到**中国开源模型在2025年做的贡献**，这里蓝色的是开源的模型，黑色的是闭源的模型。我们可以看到Artificial Analysis上面，蓝色的前五基本上全部是中国的模型，也就是我们中国在开源大模型上做出了很多贡献。我们可以看到相比2025年初，也就是2024年的时候，美国这边开源，包括Meta LLaMA还占了绝对的优势。随着一年的发展，中国慢慢地在前五，基本上现在变成中国的模型。右边的这个图是大模型的盲测榜单，也就是通过人工评测的结果，我把它截屏了过来。

### 清醒认识：差距可能还在拉大

下面一个问题，下一步我们还能继续Scaling吗？我们下一个AGI范式是什么？我们面临更多的一些挑战。

我们刚才做了一些开源，可能有些人会觉得很兴奋，觉得中国的大模型好像已经超过美国了。其实可能真正的答案是**我们差距也许还在拉大**，因为美国那边的大模型更多的还在闭源，我们是在开源上面玩了让自己感到高兴的，我们的差距并没有像我们想象的那样好像在缩小。有些地方我们可能做的还不错，我们还要承认自己面临的一些挑战和差距。

### 未来思考：参考人脑认知的学习过程

下一步我们应该怎么做？我这里有一些简单的思考。我觉得从大模型整个发展史来讲，其实就是**参考人脑认知的学习过程**。从大模型最早的，要把世界长时知识全部背下来，就像小孩子，从小先看书，把所有的知识先背下来，然后慢慢地学会推理，学会数学题，学会更多的演绎、抽象。

对于未来来讲，也是同理，对于人脑的认知学习来讲，未来有哪些能力，现在大模型还没有，但是人远远超过我们：

**第一，2025年可能是多模态的适应年。** 为什么这么讲？可能全球除了少量的几个模型，一下子吸引了很多关注，包括我们在内的很多多模态的模型都没有引起很多人的关注。更多的大家在做文本的智能提升。对于大模型来讲，怎么把多模态的信息收集起来，并且能够统一感知起来，也就是我们经常说的**原生多模态模型**。后来我想了想原生多模态模型和人的「感统」很相似，人的感统是我这边收集到一些视觉信息，还收集到一些声音的信息，还收集到一些触感的信息，我怎么把这些信息感统到一起，来感知一个东西。像我们人有些时候大脑会有些问题，很多时候是感统不够，感统失调会出现的问题。对于模型来讲，下一个多模态的感统能力怎么来做？

**第二，模型现在的记忆能力和可持续性学习能力还不够。** 人有几级记忆系统，我们有短期记忆、工作记忆、长期记忆，甚至我之前跟我们的同学、跟我们实验室的人聊天，我说好像一个人的长期记忆也并不代表知识，为什么？因为我们人类只有真的把这个知识记录下来，比如说对于我来讲，如果我的知识不能被记录在维基百科上，可能100年之后我也消亡了，我对这个世界也没有什么贡献，好像也不叫知识，好像在未来训人类大模型的时候，我的知识也没用，都变成噪音了。咱们怎么把我们整个记忆系统从单个人的三级到整个人类的**第四级记录**下来，整个记忆系统是我们人类未来要给大模型构建起来的。

**最后，反思和自我认知。** 其实现在模型已经有一定的反思能力，但未来自我认知是很难的问题，很多人在怀疑大模型有没有自我认知的能力。在座的也有很多基础模型实验室的专家，有些人是支持的，有些人是反对的，我是有一些支持的，我觉得这是有可能的，我们值得探索。

### 系统一与系统二

人类认知是**双系统，系统一和系统二**。

系统一完成了95%的任务，比如说人类问一个问题，中国的首都是什么？大家的回答是系统一，因为你背下来了。或者你说你今晚晚上吃饭吗？你说吃，也是系统一，这些全部是系统一背下来了。只有更复杂的推理问题，比如说我今天晚上要请一个来自四川的朋友大吃一顿，去哪吃？这时候就变成系统二了，它就得琢磨这个四川的朋友是哪里来的，我们去哪大吃一顿，那就是系统二做的事情。系统二在我们日常中只占5%。

对于大模型来讲同样的道理，在2020年我们画了这么一个图，我们当时是说参考人类的AI系统应该长什么样子，有人类的系统一、有人类的系统二，还有一个**自学习**。

当时为什么想了一个自学习呢？当时我是这么想的：首先系统一可以构建一个大模型，让它基于匹配就能回答，解决系统一的问题；系统二是可以加上一些知识融合，比如指令微调和思维链；第三是如果有些学过认知的，人脑在晚上睡觉的时候会无意识的自学习，如果人没有晚上睡觉不会变的更聪明。当时我们2020年的时候就说未来一定有AI的自学习机制、自学习思维链，但我们不知道怎么学习，就是先把问题抛出来。

对于系统一来讲，我们在不断地Scaling。如果我们在不停地Scaling数据，这带来了**智能上界的提升**。同时我们还在Scaling推理，使得机器思考的时间越长，用更多的计算和更多的搜索来找到更准确的解。第三方面是我们在Scaling自学习环境，让这个机器有更多的机会跟外界交互，拿到更多的反馈。

所以通过这三个Scaling，我们可以让机器来参考人的学习范式，得到更多的学习机会。

### Transformer的挑战与新型架构

对于系统一来讲，如果已经有Transformer了，是不是意味着我们只要加数据就完了，加更大的参数就完了？原来30T不够，是不是50T？50T不够就100T，到最后再加上参数从100B到1T到3T到5T甚至更大。

但我们现在面临另外一个问题，什么问题？**Transformer的计算复杂度是一个O(N²)**，使得我们在增大context的时候，显存的增大和推理效率能力会越来越低，这里面临很多问题。最近有一些新型模型，包括一些线性模型试图在用线性的方法，参考人脑是我用更小的脑容量能存更大的知识。甚至更本质的一个问题是有没有可能，因为原来Transformer越训越大，包括最早的时候，我们探讨的时候没有说我们非得把模型弄小，越来越大比较早。

但最近我也在反思，我们能不能找到更好的**知识压缩的方法，把知识压缩到更小的空间里面**，这是一个新的问题。

这里面面临两个问题：第一个问题，工程上有没有办法？第二个问题，方法论有没有办法？所以最近包括很多人在探讨，我们大模型可能要**回归到研究上来**，不能像原来单纯的Scaling。Scaling是一个很好的办法，但Scaling可能是最轻松的办法，是我们人类偷懒的一个办法，我们直接把Scaling Up上去，它就是一个偷懒的办法。但是更本质的方法，可能我们要找到新的东西。

第二个是**新的Scaling范式**。Scaling可能是一个非常重要的路径，但我们怎么找到一个新的范式，让这个机器可以Scaling的机会。读书是一个机会，跟人交流也是一种机会，我们要找到一种新的，让这个机器可以独立Scaling的方式。有些人会说我们加大数据，加大数据是我们人强加给它的，这个机器必须找到自己能通过、自己来定义一些奖励函数，自己来定义一些交互方法甚至训练任务来做Scaling，这是系统二来做的事情。

更重要的是我们有了刚才两个以后，还要完成**更多真实场景下超长的任务**，这块怎么来做？要让这个机器有像人一样PLAN规划，做一下，检查一下，再反馈一下，人是这样来工作的，机器有没有可能这么做？一个超长任务怎么完成？

举个例子，我们今年已经有一点点文章出来，年初的时候跟我们团队的小伙伴说，年底你必须给我写一篇文章，但是没实现，最后也没做出来。反正到现在，大家知道在网上已经有一些文章开始尝试，这个idea也是模型生成的，实验也是模型做的，报告也是模型做的，最后可以做一个Workshop，但事实上还没有做出来，这里给出一个真实的超长环境下的任务例子。我们希望在这个基础上来定义未来AI会长什么样子，这是我们的一些思考。

### 智能的五个层级

早期在这个大模型之前，大部分机器学习都是**F(X)到Y的映射**，我学习一个函数，使得X样本可以映射到Y。大模型来了之后，我们把这个问题变成**F(X)到X的映射**，可能映射的也不是严格的X，但我们是让它完全用自监督的学习来做多任务的自学习。

另外第二层，我们加上这些数据之后，让这些模型学习如何推理，如何激活底层的智能。

再往后，我们在教这个机器有**自反思、自学习的能力**，通过这个机器能够不断地自我批评，能够学习到哪些东西我应该做，哪些东西可以更优的来做。

到未来，我们还要教这个机器能学习到更多，比如说能学习到**自我认知**，让这个机器能对自己的行为，比如说AI生成了大量的内容可以自我解释，我为什么要生成这个内容，我是什么，我的目标是什么。在终极上也许有一天，**AI也有意识**。

我们大概有这么定义五层的思考。

### 计算机的三个核心能力

从计算机的角度上，计算机不会定义这么复杂。在我看来计算机有三个能力：

**第一，计算机的表示和计算。** 把数据表示出来，它可以做计算。

**第二，编程。** 计算机只有编程是计算机跟外界的交互。

**第三，本质上是搜索。**

但是这几个能力叠加在一起：第一是有了表示和计算，可以使存储能力远超于人。第二是编程可以做出人类更复杂的一些逻辑。第三，搜索可以比人做的更快。这是计算机这三个能力叠加在一起，可能能带来所谓的「超级智能」，也许能超过人类的一些能力。

### AGI-Next 30：未来30年的愿景

我突然想起2019年，这个PPT原来真的是跟阿里巴巴合作的时候，当时让我给出一页PPT，我当时给出了这一页PPT，就是**AGI-Next 30**，未来30年我们应该做什么。

这个图是我截屏下来的，Next AI，我们说在2019年的时候，未来30年，我们应该做让机器有**推理能力、有记忆能力、有意识**。我们现在差不多在这里面做了一定的推理能力，大家应该都有一点点共识。记忆能力有一部分，但意识还没有，这是我们在努力的。

未来我们也在反思，如果用参考人脑认知，未来的AI可能会有**什么是我、为什么是我**，以及给这个模型构建**意义系统**，还有单个智能体的目标，以及整个智能体群体的目标，这样我们实现对未知的探索。

有些人可能会说这个完全不可能，但是大家记住，我们人类的终极意义是我们在不断地探索未知的知识，我们越是觉得不可能的，恰恰也许就是我们未来AGI上路上要去探索的。

### 2026年展望

2026年对我来说更重要的是要**专注**和做一些比较新的东西。

**第一，我们要Scaling可能还会继续做下去**，但Scaling已知的是我们不断加数据、不断探索上限。还有Scaling未知，就是我们不知道的新的范式是什么。

**第二，技术创新。** 我们会做全新的模型架构创新，解决超长上下文，还有更高效的知识压缩问题，以及我们会实现知识记忆和持续学习，这两个方面加在一起，可能是未来实现让机器比人能力还强一点点的一个机会。

**第三，多模态感统**，今年是一个热点和重点。因为有了这个能力，我们才使得AI可以实现进入像机器里面的长任务、长时效任务，在我们人的工作环境里面，比如说手机里面、电脑里面，它可以完成我们的长任务。当完成我们的长任务，AI就实现了一个工种，AI变成跟我们人一样，可以帮助我们实现。只有这样，AI才能实现具身，才能进入物理世界。

我相信今年可能是**AI for Science的一个爆发年**，因为很多能力大大提升，我们可以做更多的事情。

**以上就是我的汇报，感谢大家！**

# Scaling Law、模型架构与Agent智能

**演讲人：杨植麟（月之暗面创始人、Kimi）**

杨植麟的分享，充满了技术与公式，这里简单总结下：  
通过**Token Efficiency**和**Long Context**两个维度优化，最终能实现更强的Agent智能。

他指出Transformer优于LSTM的关键不在短序列，而在长上下文场景下Loss显著更低——这正是Agent时代的核心需求。团队采用**MUON二阶优化器**实现2倍Token效率提升，并通过QK-Clip解决训练不稳定问题，成功在万亿参数的Kimi K2上完成稳定训练。

下一代架构**Kimi Linear**采用Delta Attention线性注意力机制，首次在长程任务上超越全注意力，同时速度提升6-10倍。K2已成为中国首个Agent模型，可完成两三百步工具调用，在HLE等核心评测上超越OpenAI。

杨植麟强调，接下来的模型需要更多**Taste（品位）**，因为智能不像电力可等价交换，每个模型产生的Token本质上是不同的。他引用与Kimi的对话：继续开发AGI是因为放弃它意味着放弃人类文明上限，不能因恐惧而停滞

# Towards a Generalist Agent

**演讲人：林俊旸（阿里通义千问）**

大家好，非常感谢唐老师的邀请，唐老师跟我说这是清华、北大联合实验室第一次办的活动。唐老师和植麟都是清华，我代表北大来一下。我很久没有回海淀区了，我是朝阳区的。

今天整体介绍一下千问2025年的进展，有些东西相对旧一些，最近几个月我们在憋着下一代的东西，我尽量讲一些我能讲的东西。

**Towards a Generalist Agent**这个标题我其实换了很多轮，原来叫Towards a Generalist Model，后来觉得model是比什么都大的东西，后来想想agent也许是更大的概念，像人一样你可以自主的使用工具，人和动物很大的差别是可以自主使用工具。所以就变成了Towards a Generalist Agent。

而且今天训练的范式发生了很大变化，过往我们不管做什么事情，都会有输入和输出把它标注出来，你可以认为是我们传统的标注。今天有了这个新的技术以后，我只要解决了这个推理，解决了这个评估，这个东西就可以训，干什么都可以，我就可以发挥想象力。比如说今天数据智能、模型智能都可能，这也是我一个干语言模型的人最近敢斗胆扬言我要做VLA和机器人的一个小小的原因。

### 开源与产品

大家如果想用上我们的模型的话，最容易体验到我们开源模型和闭源模型。我觉得很有意思，之前我们一直做开源，大家比较清楚，不赘述和吹牛了。但是网友们一直在骂我们，你们那个东西很难用，每次都得去你们的模型上面找。我们就把OpenWebUI拖下来之后就把它变成了一个聚合器，看起来就像是ChatGPT一样。本来算法的同学产品意识并没有那么强，做着做着就有这种感觉了，**模型即产品**，就有很好玩的东西出来，所以我们都会放到这上面。一般我们会在qwen.ai里面就可以很好的搜到，发博客对于我们来说比较简单，最近我们火的新的模型架构Qwen Next，很多同学没有办法引用，原谅一下我们。

我们做开源做的比较久，**2023年8月3日**开始做开源，很多人问我们为什么做开源这一件事情？很多事情都有机缘巧合的成分在这里，反正开源一路做下来之后做了很多，至少还是比较工业的事情。东西不多，基本是一些脚本大家在上面看就可以。我们的模型是比较多的，为什么相对比较多？以前有很多人不理解我们为什么做小模型，但是今天大家都明白**小模型还是挺有价值**。

小模型最终起源于我们内部用来做实验的**1.8B模型**，我们做预训练，资源毕竟有限，你做实验的话不能通通用7B的实验来验，就拿1.8B的来验。当时我的师弟跟我说我们要把这个模型开源出去，我非常不理解。我说这个模型在2023年几乎是一个不可用的状态，为什么要开源出去？他跟我说7B很消耗机器资源，很多硕士生和博士生没有机器资源做实验，如果1.8B开源出去的话，很多同学就有机会毕业了，这是很好的初心。

干着干着手机厂商跑来跟我们说7B太大，1.8B太小，能不能给我们干一个3到4B的，这个容易，没有什么很难的事情。一路干下来型号类型越来越多，跟服务大家多多少少有一点关系。

### Multimodal Foundation Agent：我们的追求

但是我们自己的内心追求的不仅仅是服务开发者或者服务科研人员，我们看一看能不能做一个**Multimodal Foundation Agent**，我特别相信这件事情。如果追溯到更远的话，刚才唐老师说我们当年还在合作的时候，当时就在大干多模态，现在想想这是一个激情岁月。2023年的时候大模型是一个大家都不要的东西，多多少少有那么几分大炼钢铁的成分，多模态是我们延续下来一直想做的事情。

为什么呢？我们觉得如果你想做一个智能的东西，天然的应该是Multimodal，当然带有不同看法，各个学者都有一些看法，多模态能不能驱动智力的问题。我懒得吵这个架，人有眼睛和耳朵可以做更多的事情，我更多的考虑是Foundation有更多的生产力，能不能更好的帮助人类，毫无疑问我们应该做视觉，我们应该做语音。

理想的情况下，当年我记得我们2022年的时候，当时设计的一个系统是中间有一个大脑，我们不知道那个大脑是什么东西，但是我们知道不同的模态和任务都应该进入到这个大脑，从这个大脑输出去，这个才是真正的想象当中的AGI。今天看起来很有可能，因为我不知道大家做的研究方向有没有做**统一理解生成**这件事情，这件事情还挺复杂的。目前谷歌也没有做到统一理解互相生成，但是我还挺相信这些事情。如果看GPT的话，今天把很多东西统一了之后，看起来更加完美一些，当年还在争论他们到底是哪个好。

### Qwen3：今年最大的进展

今年最大的进展是**Qwen3**，这个是吉祥物，有点像熊，但它是一只卡皮巴拉。做的时候我觉得我们同学太辛苦了，不想他们太辛苦，今天这么卷的时代佛系一点不是说不行。我们做的方向相对比较多一些，但是你可以看到每一个方向都有它自洽的逻辑在这里面。比如说我们做Text和VL、Omni，做的时间比较长，做视觉、文本、语音生成。我们做的过程当中，可能因为我们比较特殊的地方是我们背后是阿里云支持，我们有很多业务和阿里云的客户比较相关。云的业务很多客户是非常多样的，包括Embedding、Guard都会给大家提供服务。

今天围绕相对比较主线的Text、VL，包括Omni会给大家做介绍，Coder会放在Text里和大家做相应的介绍。

### Text：Qwen3系列

Text今年主要是**Qwen3系列**，现在已经做到3.5，3做的时间比较长一些。因为上一代2.5用了非常长的时间，一个最大的特点是**总体能力提升**。今年比较有意思的是reasoning的能力要提升，我补充介绍一下我个人的理解，reasoning和现在的单纯的Instruct模型有一点不太一样。

第二个是我们支持的**语言及方言**，语言没有那么多，加上方言一共有**119种**。为什么会做多语言这件事情呢？其实也有些机缘巧合的事情，2023年的时候，当时我们觉得只要把中文和英文做好就可以服务好我们需要的人群，但是有一回我遇到韩国朋友，他们在做Solar模型的时候，为什么不用我们的模型做呢？他说你们的模型根本就不懂任何的韩语，我感到非常的受伤，我就去看了一下，后来发现这个事情很简单，顺手就把它做了。后来发现我们全球的用户越来越多，我记得一些巴基斯坦的朋友不断的跟我说你快点支持乌尔都语，我们真的没有大模型可以用了，这个事情我觉得确实挺好，于是我们支持了更多的语言。

我们现在还没有做完，非洲的数据确实有点难以收集，非洲的语言没有覆盖。今天我跟一些手机厂商聊了一下，非洲还有很多人使用功能机，我们今天已经进入智能机的时代，他们还在做这个事情，所以要帮助全人类的话，确实是任重道远。如果你的想法不是帮助全人类的话，我觉得不如不做，所以就继续干。

第三个是今天的**长文本、长视频**可能都是其中一个例子。但是我觉得这件事情很有意思，如果你真的想形成一个具有自我认知的模型，首先上下文得足够长，之前还有人讨论一个问题，你没有必要把很多垃圾放到长上下文里面，但是有了这个以后才能做到下面的理解。所以我们现在一路做到**1M以上**，实际上我们内部已经做到好几个M，可能还不够。今天为什么还想说这是非常非常长的事情。

### Reasoning能力的提升

回到刚才的问题，我们这一代模型可能和2024年相比，很大的一个区别是**reasoning的能力要提升**，广义的reasoning是做问题推理，让问题得到更好的解决。虽然不得不做相关的研究，怎么让reasoning更加native一些。Qwen3的时候，我们4月份发的版本，当时有些做的不太好，数据方面没有做的太好，合并起来有一些问题。

当时，我们发现一个很有意思的现象，我们自己有超过90%的客户不再使用Thinking模型，大量使用我们QwQ系列的很重要的原因是他们的用户喜欢看机器和自己进行聊天。但是很快大家就回到Instruct，这里主要看一下黄色和蓝色的部分，蓝色是4月份版本，红色是7月份版本。除了把数据做的更好以外，一件很重要的事情是**AIME可以干到70分**，你做Thinking可以做到90分，但是这个能力加进去之后，客户很明显的反馈是模型比以前聪明了很多。只有20多分，基本上什么题可能都做不了，比如说在教育领域做一点数学题可能都干不明白，这是我们挺骄傲的模型，这个模型也不是很大，很多人在用我们系列的模型。

但是还有一个遗憾，这个模型还有很多东西没有做完，这里是一个取舍的问题。比如说**Coding和Agent能力怎么把它集成进去**，做起来很难。考虑到自己的技术实力和状况，包括自己一直做Coder系列，我们推出了这个模型。

### Coding：从竞赛题到Software Engineer

今天的Coder和过往的不太一样。比如说去年和前年都在解单纯的竞赛题，给一道题看一看能不能把答案做出来。今天我们做什么事情呢？**Software Engineer**，2024年的时候大家非常惊讶，第一个AI能不能像一个程序员，今天我就维护一个项目这件事情挺难的，你把它做了就好了。

实际做的过程中，这个事情人做起来步骤挺复杂，最简单的是至少我可以打开这些文件夹，看了这些文件的名字知道我可以点开哪一个，其实是多轮交互的过程。今天做Agent一个很重要的点，为什么大家提多轮环境交互，说白了打开文件夹看一眼，这个其实也是一个跟环境交互的方式。这件事情很重要，并且非常有意思，让我们非常激动，真的能产生产力。我们想做今天的Coding的模型可以有生产力，很多代码可以写出来，这是很惊讶的。

当然这个中美是不一样的，刚刚从湾区回来，我感受到两边不太一样。这个是非常夸张的，但是今天是不是模型做的不够好，还是说Vibe Coding还没有足够 popular，我觉得是大家认知上面有差异，我们想做的事情是殊途同归，都是想让它产生生产力。

当时我们就特别关注两个Benchmark，一个是**SWE-bench**，你能不能提一个PR把它解掉，70算是比较高的门槛，当然现在可以感到75以上，这是7月份的时候，当时我们做到67和69分觉得可以。**Terminal-Bench**也挺难，今天大家都在用这系列的产品，大家会发现这个东西确实会和你的生产力接在一起，和以前不一样，今天我们做的是贴近实际的任务。也许今天我们只是一两个Benchmark而已，有没有可能让它更加符合真实的环境和真实的生产任务是我们想做的事情。

当时刚出的时候挺火的，但是现在竞争太过激烈，当时我们的 Token 消耗量一度干到了 OpenRouter 第二，小小吹嘘一下。

### Agent Scaffolds：算法与工程的联合

最有意思的是这一套东西，以前从来没有做过，今天模型训练我有一个Scaling，就是今天**Agent Scaffolds**的东西，所谓的脚手架你再简单理解一点就是这个东西。它就能够在机器里面跟阿里云的ECS的这些机器在这里面一个个起来，不仅是算法的挑战，在里面干完活就把它消除掉。真真实实的存在，Infra挑战也很多，右上角的东西我自己可以感受，左上角就得需要拉其他的伙伴一起，**算法和Infra今天联合的事情是真真实实存在的**，今天我们要做这么难的任务，需要很多Infra的支持。

这个是当时做Coding的事情，我们更想做的是把Coding的能力是否可以集成在我们很大的模型上。比较抱歉的一件事情是最大的这个模型，大于1T的模型，我确实没有推动将其开源出来，虽然我也很想开源。但是就是这么回事，我们终于把这些能力集成进来，大家可以看到我们的**SWE-bench可以做到70分**，之前你没有很好的把它集成进来，其实很难做到一个比较高的分数。这也说明一个问题，做到很强的时候，你也可以集成一个很强的模型，需要进行相应的积累。

**Qwen3-Max**也是排在前五，Overall。当然，它体现的是人类的偏好，未来评测会不会是动态的？让它放到人类的生产环境里面，比如说就让它炒股票。最后有一个公司做炒股这件事情，虽然有很多随机性，但是开了一个好头，让大家在人类的真实世界中看AI做的好还是不好。

### Visual Understanding：给模型装上眼睛

做语言模型其实还要想一个问题，它能不能有眼睛看到这个世界，举个例子。我们刚才提到想做Coding Agent提升生产力，我总得让它操控电脑，看电脑屏幕，没有眼睛就看不到，所以我们毫不犹豫的去做，这是巨大的差异，Visual Understanding就去做可以了。

但是今天很多的模型比人看东西看的更明白，比如说我又近视又散光，基本上不太好使，看不明白。但是上下左右我总归分的很清楚，但是AI很有意思，很细节的东西它看很清楚。比如说问前后左右这个问题，居然分不出来。我们很长时间评估一个案例，叫**活体的方向**，当时我还问我们的评测人员什么是活体，分不清楚东西在左边还是右边，我觉得蛮奇怪的，但是这是我们要解的问题。

但是不仅仅如此，我们还要做一件事情是**让它的intelligence不要降低**，我们没有期待它真的能够大幅度提高智商，但是至少不要变笨，因为很多时候做VL模型是变笨的。我们这一次终于让它不再变笨，大概和我们的235B的语言模型达到一个持平的状态。

这里讲一下我们这次主要的提升，简略的说一下：

**第一**，我们大家都在做一件事情，让它操作手机、操控电脑的能力进一步提升。

**第二**，是它的语言的智力，VL模型能不能当LLM来用，这样才可以追上原生多模态的模型，至少做到技术上让语言的智力能够达到持平状态。

**第三**，Coding这件事情很重要，但是Coding的输入也可以是图像或者是视频。比如说今天我想做一个APP，想做一个网页，我可以画出来。不一定我用文字写，因为这个很考验人类的表达能力。很多时候大家表达的不一定很清楚，你可以画一个图。

还有**对视频的理解**，也许是VL下一代的机会。视频是更广义的表达，图片可以理解为是单帧的视频，理解很长的视频是很有意思的一个事情。

我一直在想如果我们有了智能眼镜，每天接收更多东西的时候，能不能构建我们的记忆。这个眼镜是第一人称视角的东西，一般来说我们在网上搜罗的视频是第三人称视角，对第一人称视角理解很少，我们一般谈论的是它对这个物理世界能不能构建一些好的理解。我们做的时候，就发现真的需要知道它是不是能理解这个空间的东西。这个东西激励我们做一件事情，我们能不能去做VLA，可能得把这些数据都集合进来，有没有可能接入硬件做VLA的模型，能不能让它获得一些泛化。

另外是**基础能力的提升**，比如说今天大家在使用OCR的时候，有很多东西的用例，都在检测一些很褶皱的东西。但是我们的图像很多时候检测不到，纸张非常的褶皱，能不能让它看的懂都是我们自己要解的问题。另外是印章，字体非常特别，非常的小，图片分辨率低，能不能识别出来是很特别的事情。

Multimodal模型能不能做Reasoning，能不能对图片进行理解。比如说今天我们看到一个数学问题做分析，不断的一步一步去推，和图片结合起来看能不能看到图片上更小的点。举个更小的例子，一张照片有50个人它能不能数的出来呢？数不出来，但是配上Reasoning我就可以一点点的去看，一点点的去打这个点，有可能我能把这个数字给数出来。今天结合具体的应用，能做的空间其实非常多。

我们现在基本上可以达到**2.5 Pro**的水平，但是让我开心的是语言的智力没有那么降智了，也算是第一次解决了这个问题。

### 图像生成：理解之外还要会创造

更进一步我们想做什么呢？除了理解图像和视频以外，有没有可能同时生成图像和视频？我们甚至有一个更大的想象，如果我们今天在思考有没有可能把我们的基础模型实现想象这些事情。我脑海里有一些画面，这个想象对我来说是有意义的，这些事情都可以通过图像生成和视频生成进行相应的实现，这个也会和今年的世界模型联系在一起。

今年我们刚开始做生成的事情，花了几个月时间做了**Qwen-Image系列**，12月份刚刚更新了一个。这是我们内部人员进行盲测，排名还是可以，基本上比最好的开源模型和闭源模型，比相较还是稍微差一点点。但是我看到一些实际的图的时候，我其实比较兴奋。比如说和其他模型比较没有什么感觉，但是可以看一下8月份和12月份的版本，8月份生成的图AI感还是非常重的，但是12月份生成的已经接近离谱了，虽然没有那么美和好看，但是已经接近真人了。其实还有一张我们博客里面宿舍女生拍照，真的很像宿舍女生刚睡醒拍照，放在这里不是很好，我放了更好看一点的。还有更自然的东西，比如说灯塔，水花特别夸张，但是右面的水可以达到非常自然的状态。

另外一个是生成图像**文字要很准确**，能够把文字生成到图片上面来。分镜不是拼出来的，其实是12张图合起来的一张图，包括文字都是一次性生成出来。今天模型有一些威力超出了我们的想象，有时候我们自己训练模型都没有想到会变的这么强。

### 图像编辑：比生成更大的需求

但是除了生成以外的话，我们还要做更重要的事情。我们做了生成之后，用户告诉我们才知道**编辑是更大的需求**，因为大家都需要P图，让自己变的更好看。Image-edit版本也有，接下来会把edit和生成合在一起。我自己每天用这个东西，最近出去旅游的时候，我想拍出美国往事的感觉，下面有很多人，我就把很多人P掉，调整一下风格，就可以把这个东西做出来，这是每天干的事情。

我想给大家分享一个更有意思的案例，也是今天大家会问我，**开源社区究竟怎么帮助我们研发这个模型**，如果不是开源社区告诉我们，这辈子都想不到有这个问题。有一张图片我们想对它进行编辑，让它放下图像中右边的人，你会发现它放下来之后，两张图重叠在一起的时候你会发现糊了，它有点移动了，不在原位，偏移了。对于很多搞PS的同学来说，这个东西要非常精确，你不能随便移动，所以2511这个版本很重点的是在解这个问题。在2511这个版本，我把两张合在一起的时候，基本上人在原来的位置上，我觉得是开发者给我们很好的用例，原来可以做出真的可以帮助到他们东西。

编辑可以做很多事情，比如说我调整光线让它变成更柔和的光线。我们的用户和产品跟我们说这个光线合理不合理是很重要的，我们做算法的同学很多时候没有感受，但是有些时候大家对图的要求比想象的更高。所以，大家谈世界模型的时候，是不是真的能构建出符合物理规律或者真实世界的东西其实还是很重要的东西。

还有一些例子，比如平移一些镜头，旋转30度这些都是很常见东西。今天这个模型甚至可以和推理结合在一起，我们一直有一件事情非常想做，教小朋友家长们很痛苦，很多时候AI去教有一些题教不了，**画辅助线**的东西是教不了的，真的需要生成模型才能做。我真的能够把一道数学题做好，比如说画辅助线这件事情我可能要通过生成推动更好的理解。

### Omni：让模型能听能说

接下来是更进一步的，如果今天看图像的问题解的差不多了，甚至自己可以把东西生成出来，有没有让它像人一样**听和说**呢？因为语音交互也是很重要的事情。今天大家在使用各类的APP的时候，大家发现有语音交互真的是很方便的一件事情。

**Omni**也是很大的方向，并且我愿意相信一些事情，今天对事件的环境音理解，人讲的话不是单纯的使用ASR就可以解决的。所以我们就做一个Talker的东西，这个模型做了很久，让它既能听又能说，能够保证它的效果是稳定的。Omni是沿着这个方向持续做的，大概的进展稍微有一点降智，但是降智的已经不多。我们这个模型可以达到2.5文本的水平，对于语音基本可以对标2.5 Pro的水平，这里面有挺多好玩的东西，时间关系没有办法和大家分享。

今天TTS可以换各种声音，包括自己定制你自己的声音，只要描述这个声音长的什么样子，就可以让AI以这个形式把东西讲出来。我觉得还有很好玩的事情，基础模型和基础Agent是不是真的可以跟人类的真实世界，也包括虚拟世界进行更好的交互。

### 下一步：全模态模型与新架构

下一步要做什么样的事情呢？我们做了这么多，当然希望集合在一起，**全模态模型**是要做的。有一个很重要的，我觉得也是殊途同归的事情，跟Kimi团队做类似的事情。我们同时做各种各样的实验的时候，最后选择了用**Linear Context**，当然也是以三层Linear配合它的。下一代的模型也会沿着新的架构进行相应的实现，其实我们这里想做的事情是新一代的架构能不能解决我们刚才提到的问题，能够省下很多步骤。也许还会有更多的威力在里面。下一代的模型，其实也会沿着新的架构进行相应的实现。

更进一步我们要做什么东西呢？Omni的模型不仅仅是我能够理解文本、视觉、音频，我们可能还让它生成文本、音频，今天我们已经做到了，但是我们还没有做到把视觉生成结合在一起。如果做到**三进三出**，我觉得会是至少我个人喜欢的东西。

### 训练范式的变化：Multi-turn RL

第二个是今天的范式发生了一个很大的变化，今天不是像以前那样训模型，有标注的数据，有一条输入和输出训练就可以，我们今天要把更多的数据放到实验中去训练。如果大家关注xAI的宣传，RL的数据我虽然觉得他们有点浪费，但是另一方面也意味着**RL有很多的想象空间**。当然并不是说自己跟自己对话，我其实没有那么关心我们的模型能不能做成为最强的数学大脑，我更关心的是像日常真实的人，为这个社会做贡献。如果它能够做到这一点，我觉得还挺好。

所以**Multi-turn RL with environment feedback towards long-horizon reasoning**，因为很多时候做很多事情需要很长的时间，你得一步步去做。但是AI可以加速很多，比如说人类花两个月的时间做的东西，AI可以花两天的时间。虽然有很多Token在里面，但是两天确实能够节省我们很多的时间在这里面。

### Agent：走向虚拟世界和物理世界

Agent其实可以走向虚拟世界和物理世界，所以有了**Embodied Reasoning**的这种方式。我们内部讨论了一个方式，就算你是做VLA，做Coding的模型，说白了也是把语言转化成Embodied的模型，从这个角度上来看就非常的振奋人心，于是我们就觉得大干一场，看一看能不能走向**Digital Agent**，GUI操作，同时能够使用API，这个就是非常完美的Digital Agent。

如果走向物理世界，是不是能够把话筒拿起来，今天能够斟茶倒水，这是我们今天很想做的事情。

**非常感谢大家！**

# 圆桌对话：中国AI的下一步

**主持人：李广密**  
**嘉宾：杨强、唐杰、林俊旸、姚顺雨**

### 开场

**李广密：** 我是接下来Panel的主持人广密。我刚才在台下听有几个感受，第一是唐老师的号召力很强，清华的人才非常好，不仅是国内包括海外，清华人的比例非常高，感觉这一拨好像跟国内学校在AI这一拨拉开差距了。第二是我刚才听几个Talk的感受是不止follow、不止开源，不只是Coding，都在探索自己的产品形态。

2025年是中国开源模型大放异彩的一年，是开源四杰在全球大放异彩的一年，而且是Coding过去一年有10-20倍增长的一年，包括海外也在提Scaling到底走到哪一步了，有没有新范式出来了，接下来这个Panel是到底接下来怎么走，是特别有意思的。接下来邀请几位嘉宾：杨强教授、唐杰老师、俊旸和顺雨。

我们先从第一个比较有意思的话题聊起，硅谷几家明显做分化，可以从分化这个主题先聊起来。Anthropic其实是对中国模型有一个非常大的启发，硅谷的竞争那么激烈，它没有完全Follow全都做，而是专注到了企业，专注到了Coding，专注到了Agent。我也在想接下来中国的模型会分化成自己想要的哪些方向？我觉得分化这个主题蛮有意思的。顺雨上线了，顺雨开场给大家讲一讲，包括你最近在干什么。

**姚顺雨：** 大家好，我现在是不是一个巨大的脸在会场？不好意思，今天没法亲自来北京，但是很高兴参加这个活动。最近忙着做模型、做产品、做AI，是一个很正常的状态。回国的感觉还是挺好的，吃得好很多。

### 话题一：模型分化

**李广密：** 顺雨，你能展开聊聊你对模型分化这个主题的想法吗？硅谷也都在分化，包括说Anthropic做了Coding，中国很多模型做了开源，过去Coding提的也很快，包括谷歌也没有全都做，它现在把全模态这个做好，你的老东家重点做To C是横跨中美的体感，可以讲讲你的体感，接下来不管是自己也好，各家也好，分化这个点，你是怎么思考的？

**姚顺雨：** 我觉得有两个大的感受，一个感受是**To C和To B发生了明显的分化**，另外一个感受是**垂直整合这条路，以及模型和应用分层这条路，也开始出现了分化**。

我先说第一点，我觉得很明显的是当大家想到AI就是两个，ChatGPT，另外一个Claude Code，是做To C和To B的典范。非常有意思的一点是我们今天用ChatGPT和去年相比的话，感受差别不是太大。但是相反，Coding夸张一点来讲，**已经在重塑整个计算机行业做事的方式，人已经不再写代码，而是用英语和电脑去交流**。

我觉得很核心的一点，对于To C来说，大部分人大部分时候不需要用到这么强的智能，可能今天用ChatGPT和去年相比，写抽象代数和伽罗瓦理论的能力变强了，但是大部分人大部分时候感受不到。大部分人尤其是在中国更多像是搜索引擎的加强版，很多时候也不知道该怎么去用，把它的智能给激发出来。

但对于To B来说，很明显的一点是**智能越高，代表生产力越高，值钱的也越来越多**，这些东西都是相关的。

对于To B来讲，还有一个很明显的点，大部分时候很多人就愿意用最强的模型。一个模型是200美元/月，第二强或者差一些的模型是50美元/月、20美元/月，我们今天发现很多美国的人愿意花溢价用最好的模型。可能他的年薪是20万美元，每天要做10个任务，一个非常强的模型可能10个任务中八九个做对了，差的是做对五六个，问题是你不知道这五六个是哪五六个的情况下，需要花额外精力去监控这个事情。

我觉得无论是人还是模型，在To B这个市场上发现了一个很有意思的现象，**强的模型和稍微差点或者弱的模型它的分化会越来越明显**。我觉得这是第一点观察。

第二点观察，垂直整合这条路和模型应用分层这条路的区别。我觉得一个比较好的例子，比如ChatGPT Agent，相比于用Claude或者Gemini加上Manus这样的应用层产品，过去大家会认为当你有垂直整合能力肯定会做的更好，但起码今天来看并不一定。首先模型层和应用层需要的能力还是挺不一样的，尤其是对于To B或者生产力这样的场景来说，可能更大的预训练还是一个非常关键的事情，这个事情对于产品公司确实很难做，但是想要把这么一个特别好的模型用好，或者这样的模型有它的溢出能力，也需要在应用侧或者环境这一侧做很多相应的事情。

我们会发现其实**在To C的应用上垂直整合还是成立的**，无论是ChatGPT还是豆包，模型和产品是非常强耦合去紧密迭代的。**但是对于To B来说这个趋势似乎是相反的**，模型在变得越来越强、越来越好，但同样会有很多应用层的东西应用好的模型在不同的生产力环节。

这是我的两个观察。

**李广密：** 因为顺雨有一个新的身份，在中国的市场下顺雨接下来想的是什么，有哪些鲜明的特点或者关键词吗？现在能给大家分享吗？

**姚顺雨：** 我觉得腾讯肯定还是To C基因更强的公司，我觉得我们会思考怎么样能够让今天的大模型或者说AI的发展能够给用户提供更多价值。很核心的思考是我们发现很多时候我们的环境来讲，或者更强的模型，很多时候需要的是额外的**Context**。

我最近经常举一个例子，比如我想问我今天该去吃什么？其实你今天问ChatGPT和你去年问或者明天问都会差很多。这个事情想要变好，不是说你需要更大的模型、更强的预训练、更强的强化学习、更强的Agent环境或者更强的搜索引擎，这个问题可能需要更多额外的输入，或者我们叫Context。如果它知道我今天特别冷，我需要吃些暖和的，我在今天这样的范围活动，可能我老婆在另一个地方吃什么等各种各样的事情。其实回答这样的问题，更多的是额外的输入。比如我和老婆聊了很多天，我们可以把聊天记录转发给元宝，或者把额外的输入用好，反而会给用户带来很多额外的价值。这是我们对To C上的思考。

在To B在中国确实是很难的事情，生产力的革命，包括我们今天很多中国的公司做Coding Agent需要打很多海外市场。我们会思考怎么把自己先服务好，像创业公司做Coding这个事情和大公司做Coding这个事情，一个区别是作为大公司本身就已经有各种各样的应用场景、各种各样需要生产力变得更好的地方。如果我们的模型能够在这个地方做得更好，不仅这个模型会有自己独特的优势，不仅我们公司本身能得到很好的发展，很重要的一点是**对于真实世界场景的数据捕捉会是一个很有意思的事情**。比如说Claude这些创业公司，他们想要去做更多的Coding Agent的数据，需要找数据厂商去标注这个数据，他们需要利用各种各样的软件工程师去想我要去标什么样的数据。这个事情是数据公司一共就这么几家，一共招了这么多人，最终你会受限。但如果你是一个10万人的公司，可能会有一些有意思的尝试，怎么把真实世界的数据利用好，而不是仅仅依赖于标注商或者协议。

**李广密：** 多谢顺雨。接下来Cue一下俊旸，你怎么看接下来千问未来的生态位或者分化的考虑？之前你讲了多模态，阿里云在To B很强，接下来你也提了全模态可能更多的是To C的，这方面是怎么思考的？

**林俊旸：** 理论上我是不能评论公司的，但我觉得公司也不一定有那么多基因之分，一代一代的人可能就塑造了这些公司，比如说今天顺雨到腾讯之后，可能腾讯变成一个有着顺雨基因的公司。

接下来这一句，我也想注入我们自己对AGI的理解。我觉得今天To B也好，To C也好，我们在服务真实的问题，我们想的问题是怎么把人类世界变得更好。你就算做To C的产品也会分化，今天OpenAI更像一个平台了，但是To C最终要服务真实的这批用户究竟是谁。今天可能有很多AI会更偏向medical和law，但这可能是自然生长的，因为我知道他们跟客户交流非常多，这个是我们还不够好的一个点。虽然我们拥有巨大的优势，也可能中国SaaS市场跟美国确实不太一样，他们确实非常频繁地跟客户进行交流，很容易发现很大的机会。今天我跟美国的很多API厂商聊起来，他们没有想到Coding消耗量那么大，在中国真的没有那么大，至少从我这边来看，但是在美国，基本上全都是Coding，我觉得这个事情不是所有人都能Get到的。

今天做的一些相关的东西，我觉得也是他们自己在跟客户看到这个机会。我觉得可能大家的分化是自然的分化，**我更愿意相信AGI，做AGI该做的事情，顺其自然**，这是我们该做的事情。

**李广密：** 多谢俊旸。有请杨强老师谈谈分化的问题。

**杨强：** 分化的问题其实我更想聊一下**工业界和学术界的分化**，这个可能是横跨美国和中国的。一直以来，学术界是一个观望者，工业界在领头往前疯跑，搞得很多学术界的人也在做工业界的事情，像唐杰老师。这是一个好事，就好像天体物理学刚刚开始的时候是以观测为主，伽利略的望远镜，然后才出现牛顿。所以我觉得后面一个阶段，当我们有了众多的稳定大模型，进入一个稳态的时候，我们学术界应该跟上来。

学术界跟上来要解决什么问题呢？工业界可能还没来得及解决的一些问题，这也是我一直在考虑的问题，就是说**智能上界在哪里**，比如说给你一定的资源，计算资源或者能源资源，你能做到多好？可以更细一点，比方说我们把这个资源怎么分配，哪些分配在训练上、哪些分配在推理上？其实我很早就在做AI，90年代初就做过一个小实验，如果我们有一定的投入在记忆上，那么这个记忆能够帮助推理多少，这个帮助会不会变成一个反向的，就是说你记的太多了，反而记的噪音会干扰你的推理，有没有一个平衡点，我觉得这些问题今天还是适用的。

我最近也在想另外一个问题，大家学计算机的都必定上计算机理论课，里面有一个重要的定理叫**哥德尔不完备定理**，大概意思是说一个大模型不能自证清白，必定有一些幻觉不可能消灭掉，可能你给更多的资源，它会消灭得更多。所以科学问题就来了，你多少资源能够换取多少幻觉的降低或者错误率的降低，这是有一个平衡点的，这个平衡点特别像经济学，经济学的风险和收益的一种平衡，所以我们叫这叫**无免费午餐定理**。像这些东西，我觉得今天就特别适合数学界、算法界和学术界和工业界一起做研究，这孕育着一个巨大的突破。

刚才唐杰老师也提到持续学习，我觉得**持续学习是一个特别好的问题**，它里面有个时间的概念，你在持续地不断地学的过程当中，但是你会发现，比方说你把不同的Agent给串联起来，每一个Agent都不能做到百分之百的话，你在N个以后它的能力是按指数下降的，你怎么样能够保证它不下降。人类是用一个方法做这个事，第一天是学习，第二天会在第一天噪音的基础上学习，这样你的能力就类似大模型会下降。但是人类有一个方法就是睡觉、睡眠，我建议大家看一本书叫《我们为什么睡觉》，是MIT的两个教授写的，非常好玩，它说每天晚上睡觉是在清理噪音，使得第二天你可以把准确率持续地提升，不至于是两个错误率的叠加。像这些理论的研究孕育着一种新的计算模式。我们今天可能比较关注Transformer，但是我觉得有必要做一些新的探索，这是工业界和学术界要拉齐。

**李广密：** 唐老师，我们从Web的感受上，智谱走了Coding非常强，榜单上非常靠前，包括长程的Agent，您对分化这个主题怎么看？

**唐杰：** 我倒觉得回到了最本质的问题，早期的时候还是基座模型。2023年那个时候我们第一个做出Chat的，当时第一个想法是赶紧把Chat扔在网上上线，当时国家有规定，八九月份一起上。当时我的第一感受是十来个大模型都上来了，而且每一家用户都没有那么多，当然今天分化得非常严重。

后来我经过一年的思考，我觉得其实这个已经不是真的解决问题，我的第一个预判是说它会替代搜索，我相信今天很多人在用这个模型替代搜索，到今天我相信大家很多人在开始用这个模型替代搜索，但是并没有替代谷歌，谷歌反而把自己的搜索革命了，谷歌自己做了搜索的改进。从这个角度上，我觉得**这一仗从DeepSeek出来之后，已经没有了，已经结束了**。DeepSeek之后我们应该想的是下一仗是什么东西？我们团队争论了很久，**下一仗肯定要让AI做一件事情**，做这件事情是什么可以讨论一下。那个时候广密还到我们那跟我们交流，广密的知识特别渊博，他思考问题很深邃，和他的交流对我的启发非常大，原来我没有想到，那一次让我启发非常大。后来我们团队争论了很多晚上，争论到最后，可以叫我们的运气，另一方面我们也是把所有的精力放在了Coding上。

**李广密：** 我觉得大家有了自己的best，不仅大家在追求通用能力，大家都有自己的资源禀赋把自己擅长的点做。

### 话题二：下一个范式

**李广密：** 接下来第二个比较有意思的问题，今天这个时间点特别特殊，一个是预训练过去走了3年，大家都说可能今天走到了七八成的收益，强化学习也都成为共识，做到了四五十的空间，后面的数据、环境空间很大，接下来一个新的范式，唐老师也谈到了自主学习、自我学习，因为今天这个会的主题是接下来的展望Next，我觉得这是一个特别值得去聊的话题。

我们先从顺雨开始，你从领先的OpenAI待过，对于下一个范式是怎么思考的？因为OpenAI是为人类推进了前两个范式的一家公司，对第三个范式，从你的观察来讲，能给大家带来一些分享吗？

**姚顺雨：** 现在**自主学习**是一个非常热门的词，在硅谷大街小巷咖啡馆里面，大家都在谈论，形成了一个共识。根据我的观察，每个人对这个东西的定义和看法都不一样，我讲两点：

**第一，这个事情不是方法论，而是数据或者任务。** 当我们在谈论自主学习的时候，它到底在什么样的场景下基于什么样的奖励函数去做，你在聊天的时候变得越来越个性化是一种自主学习，在写代码的时候越来越熟悉每个公司独特的环境或者文档是一种自主学习，你去探索新的科学，在这个过程中像一个博士一样，从原来不了解有机化学是什么，到成为这个领域的专家，这也是一种自主学习。每一种自主学习的挑战或者说方法论都不太一样。

**第二，我不知道这是不是非共识的，这个事情其实已经在发生了。** 很明显的，ChatGPT在利用用户的数据不断弥合人聊天的风格是什么，使得能感觉到它的好，这是不是一种自我学习？

今天Claude已经写了Claude这个项目95%的代码，它在帮助它自己变得更好，这是不是一种自我学习？我们当时2022年、2023年的时候，我去硅谷宣传这个工作，我当时写了第一页是说ASI最重要的点是自主学习。今天的AI系统本质上都有两部分，首先它是一个模型，其次它有个代码库，你怎么去用这个模型，是用来做推理，还是做Agent，有相应的代码库。我们今天看Claude这个系统本质上有两部分，一部分是部署环境的一大堆相应的代码，另一部分是怎么样去使用它，有一大堆相应的代码，无论是GPU的，或者说它的前端还是环境是什么样的。那我觉得今天 Claude code 已经在大规模的在做这个事情，但是可能人们意识不到，这些自主学习的例子可能还局限在每一个特定的场景下，没有让人感觉到非常大的威力。

这个事情已经在发生了，可能效率或者受限制的限制，有各种各样的问题。可能这个事情我个人的看法**它更像是一个渐变，不是突变**，这是我的看法。

**李广密：** 我再Follow顺雨一个问题，有一些人对自主学习比较乐观，2026年可以看到一些信号，你觉得自主学习看到信号，还有哪些实际的问题要突破？比如说Long Context也好，模型并行采样也好，你感觉接下来还有哪些关键条件具备了，这些信号才会发生？

**姚顺雨：** 很多人说2026年看到信号，我觉得2025年就看到信号了。Cursor他们做的每几个小时都会用最新的用户数据去进行学习，包括新的模型，也在使用这些真实环境下的数据去训练。大家觉得这个东西可能还没有特别石破天惊，是因为受限于他们没有预训练能力，他们模型效果确实还不如OpenAI，但显然这是一个信号。

**最大的问题是想象力**，我们很容易想象强化学习或者推理这个范式，如果实现大概是什么样，我们可以想象O1，在数学题上本来是10分，现在变成了80分，通过这个强化学习有非常强的思维链做这个事情。如果2026年或者2027年我们有一个范式的发生，我宣布了一个新的模型或者新的系统实现了自我学习，我们应该用什么样的任务，它应该是什么样的效果，你会相信它实现了？它是一个赚钱的交易系统，它可以赚很多钱，它真的解决了人类之前没法解决的科学问题还是别的。我觉得可能需要先想象到它长什么样。

**李广密：** 顺雨，OpenAI已经立了两次范式革新，如果2027年有新的范式出来，全球范围内的哪家公司继续立的范式创新的概率最大？如果说一家公司。

**姚顺雨：** 可能**OpenAI的概率还是更大**，因为它商业化等各种各样的变化，它创新的基因已经被削弱了，但我觉得它还是最有可能诞生新范式的地方。

**李广密：** 多谢顺雨。俊旸对2026年新的范式还有什么要聚焦的？

**林俊旸：** 如果从更实际一点来讲的话，刚才讲的这个范式在比较早期阶段，RL这个事情，实际上我们还没有做得那么充分，很多潜力没有打出来。今天我们也看到很多问题在这里面发生，我觉得全球范围内类似的问题还存在。

如果要说下一代范式的话，一个自主学习，之前跟一个朋友聊到说人类不能让AI变得更厉害，比如说你跟AI不断地交互，只会让它上下文变得越来越长，AI变得越来越笨，这是很烦人的事情。

这件事情是不是真的能够发生？这还是挺值得思考的，你能吐更多Token让你变得更强，至少O系列一定程度上实现。有没有可能，就像我真的干30个小时真的能够干出很难的任务，今天大家做超长的事情很难，有没有可能通过Coding去实现。

从这个角度来说，AI肯定需要自主进化，但究竟你是不是要更新参数，我觉得见仁见智，大家都有不同的技术手段去实现这个事情。

第二点是**AI有没有可能实现更强的主动性**，环境是我的输入信号，我现在的AI必须得有人类帮助它才能启动，但是有没有可能自己能自主思考，去做一些事情。这引发了一个新的问题，就是**安全的问题**，我非常担心安全的问题，不是担心它今天讲一些不该说的话，最担心的是它做一些不该做的事情。比如说今天主动产生一些想法，往会场里面扔一颗炸弹，我们肯定不希望不安全的事情发生。就像培养小孩一样，我们要给它注入一些正确的方向，但主动学习是一个挺重要的范式。

**李广密：** 俊旸提了主动性，自主学习看到信号，你感觉可能是在哪些任务上做什么样的任务会先看到？是训练模型，最强的模型可以提升自己，还是自动化的AI研究员？你有期待在哪些地方先看到吗？

**林俊旸：** 我觉得自动化的AI研究员甚至都不是那么需要自主学习，可能很快训AI这件事情就可以实现，我看我们同学每天干这个事情，我觉得很快就被替代掉。我觉得可能**更持续的理解用户这件事情还挺重要的**，比如说过往我们在做推荐系统的时候，用户这个信息是持续输入，让这个系统变得更强，它的算法变得更简单。在AI这个时代它是不是能更懂你，这些信息的输入能不能真正成为帮助我们的工具。

我觉得如果说自主学习的话，可能会是跟人的交互上就能做到。但是以什么指标进行衡量？不太好说，在推荐的时代下，你做得越好，别人可能点的越多、买的越多，但是在AI时代覆盖到人类生活的方方面面的时候，真正的衡量指标是什么，我们不太知道。我感觉今天更大的从技术上的挑战，我们今天不知道该怎么做，这可能是我们更值得研究的问题。

**李广密：** 俊旸说到了主动，包括个性化，你感觉如果实现记忆这个点，2026年能看到技术突破性的跨越吗？

**林俊旸：** 我个人观点是**大量的技术所谓的突破性都是一些观测问题，都是在线性发展的**，只是人类对它的感受非常强烈而已。包括像ChatGPT的出现，对于我们做大模型的人来讲都是线性的增长。现在大家都在做Memory这个事情，这个技术对还是不对呢？很多方案也没有对错之分，但做出来的效果，至少拿我们自己献丑，我们自己的Memory看起来知道我过去干了什么，但是只是记起来过去事情，每次叫一遍我的名字，其实并不显得你很聪明。你的Memory有没有可能到某一个临界点的时候，结合你的Memory，就像生活当中的人一样，过去大家讲电影，它真的很像人，理解你的Memory就是在那一下，人类的感受突然间迸发。

我觉得多多少少也需要一年时间，很多时候技术也没有发展那么快。大家比较卷，每天有新的东西，但是技术在线性的发展，我们在观测的角度处于指数上升的阶段，比如说Coding能力的一点点提升，可能就能带来很多生产价值，大家就觉得AI发展得很快，从技术的进展上来说，我们多干一点点事情。每天看我们自己做的事情觉得真的挺土的，那些Bug真的不好意思拿出来跟大家讲。如果这样做，我们已经做到这样的成绩，我觉得可能未来算法Infra结合得更好，可能更大有可为。

**李广密：** 有请杨强老师。

**杨强：** 我一直以来是做联邦学习的，联邦学习的主要思想是多个中心大家协作。我现在越来越多地看到很多有本地资源不足，但是本地的数据又有很多隐私和安全的要求，所以这样我们就可以想象现在大模型的能力越来越强，这种**通用型大模型和本地特殊性的小模型或者领域专家的模型如何协作**，我觉得这种协作变得越来越可能。像美国ZOOM，就是黄学东他们做的AI系统，他做了一个很大的基座，这个基座大家都可以插进来，它可以在Decentralise的状态下，能够既保护隐私，又能够和通用大模型有效的沟通、协作。

我觉得这种开源模式特别好，一个是知识的开源，一个是Code方面的开源，模型层面。

我觉得尤其是像医疗、金融这样的场景下，会越来越多看到这样的现象发生。

**李广密：** 有请唐老师。

**唐杰：** 我对今年会有非常大的范式革新有信心，我不说太细，就像我刚才讲的持续学习，还有Memory，甚至多模态，我觉得都有可能出现新的范式变革。

但我觉得一个新的趋势，我说说为什么会产生这么一个范式？我觉得原来其实工业界跑得远远快于学术界，我记得去年和前年回到清华跟很多老师聊天的时候能不能做大模型，很多老师第一是没卡，也不是没卡，是卡的数量几乎为零，工业界有1万片，学校是0片或者1片，倍数是1万次。但是到现在的时候，**很多学校已经有很多卡了，而且很多老师已经开始做了很多大模型的相关研究**，包括硅谷那边有很多老师都开始做模型架构、持续学习相关的研究。原来我们总觉得工业界在dominating这些，其实我觉得今天在2025年底到2026年初的时候，这一现象不大存在了，可能还有10倍的差，但它已经孵化出种子了，我觉得在学术界有这个创新的基因，有这个可能性，这是第一个。

第二，我觉得**一个创新的出现一定是某个事情有大量的投入，并且它的效率变成瓶颈了**。现在在整个大模型里面投入已经巨大，但是效率并不高，也就是我们继续Scaling，肯定是有收益的，原来data从2025年初，当时可能10个TB的数据，现在30个T，甚至我们可以Scaling到100个T，但是100个T，你Scaling上去以后，你的收益有多少，计算Cost有多少，变成了这么一个问题。你不创新，这就变成了可能花掉10个亿、花掉了20个亿，但是你的收益很小，就不值得了。

另外一方面对于新的智能创新，假如说我们每一次都要重训一个基座，再重训很多RL，像2024年出RL的时候，很多人会觉得我接着训，收益是有的，但是到今天的时候再接着疯狂的RL，收益也有，但没有那么大，还是收益效率的问题。可能我们未来也许可以定义，一方面既然要Scaling up，最笨的办法就是Scaling，Scaling我们会有收益，Scaling肯定会带来智能上界的提升。第二个办法是应该定义**Intelligence Efficiency**，就是说智能的效率，我们获得智能的效率，我们用多少投入能获得这个智能的增量。如果我们能用更少的获得它的增量，而且现在我们已经变成了一个瓶颈，假如能用更少的范式获得同样智能的提升，它就变成一个瓶颈式的事情。

所以我觉得**2026年一定会有这样一个范式的发生**，我们也

---

# [五条0112] Workflow 已过时？用 AI Skills 打造进化版工作流
发布日期：2026/01/11

“80 多个节点的 workflow，稳定性和可调整性，不是 subagent 能比拟的。”

上面这话这是我在 X 上和朋友 pippingg 的一次围绕 Dify 这样可视化拖拽 workflow 和 Claude Code Skills 的一次讨论。

这话对，也不对。

对在哪里？传统 workflow 编排的确有它的核心价值——每次执行结果可预测，出了问题能一步步排查，普通人也能看懂流程图。这些优势实实在在。

不对在哪里？很多人低估了 AI Agent + Skills 架构的潜力。我的观点是：**大部分 workflow 编排场景，都可以被 Agent + Skills 取代**。

## Workflow 编排的“舒适区”

  
可视化工作流工具能火起来，是有道理的。

拖拽节点、连连线，一个自动化流程就搭好了。不用写代码，改起来也直观。更重要的是，它给你**确定性**——节点 A 执行完一定是节点 B，不会突然跳到节点 C。对于需要审计、需要合规的业务场景，这种确定性很重要。

但 workflow 编排也有硬伤。

**它不够强大**。可视化节点能做的事情有限，复杂逻辑很难表达。

**它不够灵活**。一旦流程定死，遇到输入变化就容易出错。你设计的流程是处理 A 类文档的，来了 B 类文档，整个流程可能就卡住了。

**它难以移植**。你搭了个很厉害的工作流，想给别人用？导出导入一通操作，还得在对方环境里调半天。平台锁定效应明显。

## Agent + Skills 的"降维打击"

  
我的看法可能比较激进：几乎所有能用 workflow 完成的 AI 任务，都可以用 Agent + Skills 实现。

关键在于怎么理解 skill。很多人把 skill 当成单一技能——比如一个 skill 负责翻译，另一个负责总结。这样用太浪费了。

**Skill 应该被看作可组合的模块**。你可以把多个 skill 串起来，用自然语言描述它们之间的协作关系。换句话说，用自然语言去编排工作流，而不是用拖拽。

我总结了一个**五步框架**，用我自己的写作工作流来演示。

第一步，拆分

把工作流拆成单一职责的 skill 或 subagent。每个模块只做一件事，做好一件事。

以我的写作工作流为例，拆成了这些模块：

\- `article-analyzer`：分析素材，输出 [analysis.md](http://analysis.md)

\- `outliner`：生成 2-3 个提纲方案

\- `writer-agent`：根据提纲写草稿（可并行启动多个）

\- `polish`：润色定稿

再看配图工作流，也是同样的思路：

\- `generate-image`：原子技能，调用图像生成 API

\- `article-illustrator`：组合技能，分析文章内容，在需要视觉辅助的位置生成插图

\- `cover-image`：组合技能，基于文章内容生成 2.35:1 的封面图

然后写作和配图又可以组合成一个更完整的写作工作流。

你原来在 workflow 工具里画的每个功能节点，基本都可以对应一个 skill。

第二步，编排

在主 skill 里用自然语言描述整个流程。不需要写代码，就像给同事交代任务一样说清楚就行。

比如我的 outliner 技能里会写：“先调用 article-analyzer 分析素材，分析完成后保存 [analysis.md](http://analysis.md)，然后根据分析结果生成 2-3 个不同风格的提纲方案，为每个方案并行启动 writer-agent 写草稿。”

条件分支、并行执行、错误处理，都可以用自然语言描述。Agent 能理解。

再看 article-illustrator 的编排逻辑：“读取文章内容，识别需要配图的位置（概念抽象处、信息密集处、情感转折处），为每个位置生成图像描述，调用 generate-image 生成图片，最后将图片插入文章对应位置。”

**一个 skill 可以调用另一个 skill，组合出复杂的工作流**。

![](https://pbs.twimg.com/media/G-WThB5W8AA6xRf.jpg)

第三步，存储

这一步特别重要：**所有中间结果都保存成本地文件**。

三个好处：

\- **可追溯**：出问题了能看到每一步的输出

\- **可断点续传**：中途停了，下次从上次的位置继续

\- **可人工干预**：不满意某一步的结果，手动改完让 Agent 继续

我的文件结构是这样的：

[source.md](http://source.md) → [analysis.md](http://analysis.md) → [outline-a.md](http://outline-a.md) → [draft-outline-a.md](http://draft-outline-a.md) → [final.md](http://final.md)

每一步的产出都有迹可循。配图流程同理，生成的图片按目录组织，和文章关联。

![](https://pbs.twimg.com/media/G-WTbnBXEAA7yDg.jpg)

第四步，分摊

**Subagent 之间只传文件路径，不传内容**。

这条规则很重要。如果你把一大段内容直接塞给 subagent，上下文窗口很快就撑满了。但如果只传路径，subagent 自己去读文件，上下文就干净很多。

我的 writer-agent 启动时只需要三个参数：source 文件路径、analysis 文件路径、outline 文件路径。它自己读取内容，写完保存到指定路径，返回输出文件路径。

这样做还有个好处：可以并行启动多个 subagent。三个 writer-agent 同时跑，各自处理一个提纲方案，互不干扰。

![](https://pbs.twimg.com/media/G-WT5r2WoAAU-Im.jpg)

第五步，迭代

这是 Agent + Skills 相比传统 workflow **最大的优势**：可以持续进化。

发现某个 skill 的提示词不够好？让 Claude Code 帮你改。某个流程步骤可以优化？随时调整。你的 skills 会越用越好，而不是搭完就放在那儿吃灰。

这一点是 pippingg 在讨论中特别强调的：subagent 可以自己迭代 system prompt，配合一些自动化工具，甚至能完成自我迭代进化。在 token 和系统资源充足的情况下，这套系统会变得越来越强。

![](https://pbs.twimg.com/media/G-WT9yFXEAA5CNU.jpg)

## 正面应对三大质疑

  
有人会说：你这套东西听起来挺美，但……

质疑一：稳定性怎么办？

这是最有力的反驳。80 个节点的 workflow 确实经过了反复验证，每个分支都测试过，稳定性有保障。Agent 呢？每次执行可能走不同的路径，结果不可预测。

我的回应是：**确定性逻辑不一定要交给 Agent**。

你可以把需要确定性的部分写成脚本。那 80 个节点里，有多少是需要 AI 判断的？有多少只是固定的数据处理？固定的部分用脚本实现，skill 调用这个脚本就行。

举个例子，我的写作流程里有个格式化步骤：把中文引号换成全角、中英文之间加空格。这种规则明确的操作，我写了个 `format-markdown.ts` 脚本。polish 技能执行完润色后，自动调用这个脚本处理格式。

Anthropic 在设计 Skills 时也强调了这一点：“Skills 可以包含可执行代码，用于那些传统编程比 token 生成更可靠的任务。”这是**混合架构**的思路：代码处理确定性逻辑，Agent 处理需要判断的任务。两者各司其职，取长补短。

质疑二：成本太高

没错，Agent 执行确实更费 token。每调用一次模型都在烧钱，复杂任务可能要调用几十次。

但成本要算总账。

\- **开发成本**：workflow 的节点要一个个配，skill 可以用自然语言描述。后者更快。

\- **维护成本**：workflow 改起来要小心翼翼怕影响其他节点，skill 改起来更灵活。

\- **迭代成本**：workflow 优化需要人工分析，skill 可以让 AI 帮你改进。

几个案例很说明问题。

**Rakuten（乐天）** 用 Claude Skills 处理财务报表，自动处理多个电子表格、捕捉关键异常、按公司流程生成报**告。原本一天的**工作现在一小时完成，8 倍效率提升。

**Box** 用 Skills 让用户可以即时将存储的文件转换为 PowerPoint、Excel、Word 文档，并自动遵循企业风格指南。为团队节省了数小时的手工操作。

这些案例说明：token 成本在整体效率提升面前根本不算什么。而且 Skills 采用“按需加载”的设计——只加载当前任务需要的信息，而不是把所有上下文都塞给模型。这本身就是在优化成本。

质疑三：门槛太高

把 workflow 转化成 skill 需要抽象能力。普通用户搭可视化流程可以，让他写 skill 配置文件？太难了。

但这个问题正在被解决。**AI 本身就能帮你创建 skill**。借用 `/skill-creator`，你把需求描述清楚，Claude Code 可以帮你生成 skill 的配置。我自己就是这么干的——很多 skill 不是我手写的，是让 AI 帮我生成然后再调整。

长期来看，skill 比 workflow 更易维护。因为它是文本文件，可以用 Git 管理版本，可以代码审查，可以在不同机器间同步。Workflow 呢？锁在平台里，换个环境就得重来。

## 边界在哪里

  
我不是说 workflow 毫无价值。两种方案各有适用场景。

**Agent + Skills 更适合：**

\- **输入多变、需要判断的任务**。比如处理不同格式的文档，分析各种类型的数据。Agent 可以根据输入灵活调整处理方式。

\- **跨系统协调的复杂流程**。需要调用多个 API、访问多个数据源、协调多个工具。Agent 配合 MCP（Model Context Protocol）可以即插即用地接入各种服务。

\- **需要频繁迭代的工作流**。今天这样做，明天可能要调整。Skill 改起来比 workflow 方便得多。

\- **需要分享复用的自动化逻辑**。Skill 就是几个文件，打包发给别人就能用。比导出 workflow JSON 再导入方便多了。

**Workflow 仍有优势的场景：**

\- **严格审计要求的合规流程**。金融、医疗这类行业，每一步操作都要可追溯、可审计。固定的 workflow 更容易满足监管要求。

\- **超高频执行的简单任务**。每秒执行几百次的简单操作，固定脚本比 Agent 划算得多。

\- **非技术用户的可视化需求**。让业务人员自己看懂、自己调整流程，可视化编排确实更友好。

## 一个被低估的优势：可进化

  
Skill 架构有个经常被忽略的好处：**它是活的，可以不断进化**。

传统 workflow 一旦搭好，基本就定型了。改动需要人工介入，要小心测试，改完可能还会引入新问题。

但 skill 不一样。它是基于本地文件系统的，你可以让 Claude Code 帮你维护更新。用了一段时间，积累了一些问题，直接让 AI 分析并改进。

更激进一点的玩法是 pippingg 提到的：subagent 可以自我迭代 system prompt。

听起来有点科幻，但已经有人在实践了。

McKinsey 的报告也印证了这一点：在一个法律文档审核流程中，agent 系统会记录每次人工修正，然后用这些反馈来改进自己的 prompt，逐渐将新的专业知识编码进系统。

这意味着什么？你投入时间打造的 skill，会随着使用越来越好。而不是像 workflow 那样，搭好就开始慢慢过时。

![](https://pbs.twimg.com/media/G-WTFFLXMAAv47V.jpg)

---

  
把你常用的 workflow 沉淀为 skill 吧。这不只是换个工具的问题，而是在积累可复用、可进化的自动化资产。

下次有人说“这个流程太复杂，只能用 workflow”，不妨想想：真的吗？还是只是没找到正确的拆分方式？  

hidden text to trigger resize events if fonts change