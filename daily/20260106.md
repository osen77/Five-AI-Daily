# [‰∫îÊù°0106] AI AgentÊó∂‰ª£ÔºöËÆæËÆ°Â∏àÂç≥ÂºÄÂèëËÄÖ
ÂèëÂ∏ÉÊó•ÊúüÔºö2026/01/05

‰ªäÂ§©ÊòØÁøªËØë‰∏§‰∏™È¢ÑÊµãÔºå‰∏Ä‰∏™ÊòØ Every ‰ªéÊï¥‰ΩìÂ±ÇÈù¢ÂàÜ‰∫´‰ªñ‰ª¨ÂØπ 2026 Âπ¥ AI Ëµ∞ÂêëÁöÑÂà§Êñ≠ÔºõÂè¶Â§ñÊòØ Every ÁöÑ CEO Dan Shipper Âíå COO Brandon Gell Âú®Êí≠ÂÆ¢ AI & I ‰∏≠ÔºåËÆ®ËÆ∫‰∫Ü AI Â∞ÜÂ¶Ç‰ΩïÂú® 2026 Âπ¥ÈáçÂ°ëËΩØ‰ª∂ÁöÑÂõõ‰∏™È¢ÑÊµã„ÄÇ

## Every ÂØπ 2026 Âπ¥ÁöÑ‰∏âÂ§ßÈ¢ÑÊµã

### ‰∏Ä„ÄÅAgent Â∞ÜÊàê‰∏∫Âü∫Á°ÄËÆæÊñΩ

Every CEO **Dan Shipper** ËÆ§‰∏∫ÔºåËΩØ‰ª∂ÊûÑÂª∫ÊñπÂºèÊ≠£Âú®ÂèëÁîü‰∏ÄÊ¨°Ê†πÊú¨ÊÄßËΩ¨ÂèòÔºö

> ‚Äú‰ªª‰ΩïÁî®Êà∑ËÉΩÂú® App ÈáåÂÅöÁöÑ‰∫ãÊÉÖÔºåAgent ‰πüËÉΩÂÅöÔºõ‰ªª‰Ωï App ËÉΩÂÅöÁöÑ‰∫ãÊÉÖÔºåAgent ‰πüËÉΩÂÅö„ÄÇÊúÄÁªàÔºåÁîöËá≥ËøûÂºÄÂèëËÄÖËÉΩÂÅöÁöÑ‰∫ãÊÉÖ‚Äî‚Äî‰øÆÊîπÈÄªËæë„ÄÅ‰øÆÂ§ç bug„ÄÅÂÆöÂà∂Ë°å‰∏∫‚Äî‚Äî‰πüÈÉΩ‰ºöÁî± Agent ‰ª£Ë°®Áî®Êà∑ÂÆåÊàê„ÄÇ‚Äù

Âú® **Kieran** ÁúãÊù•Ôºå**2026 Âπ¥Â∞ÜÊòØ Agent ÁúüÊ≠£Ëµ∞Âêë‰∏ªÊµÅÁöÑ‰∏ÄÂπ¥**„ÄÇ

**Natalia** ÂàôËøõ‰∏ÄÊ≠•ÊåáÂá∫ÔºåÊúÄÂâçÊ≤øÁöÑÂÖ¨Âè∏‰ºöÂú® 2026 Âπ¥Âπ¥Â∫ïÂâçÔºåÊää **agentic workflow** Ê∑±Â∫¶ÂµåÂÖ•Êó•Â∏∏ËøêËê•‰∏≠ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈáëËûçÈ¢ÜÂüüÔºö

> ‚ÄúAI Â∞ÜÂ∏ÆÂä©ÊäÄÊúØÈ¢ÜÂÖàÁöÑÊú∫ÊûÑÁªºÂêàÊõ¥ÂπøÊ≥õÁöÑ‰ø°ÊÅØÊù•Ê∫êÔºåËøôÁßçÂèòÂåñ‰πã‰∫éÈáëËûç‰∏öÔºåÂèØËÉΩÁ±ª‰ººÂΩìÂπ¥ÈáèÂåñÈáëËûçÂ∏¶Êù•ÁöÑÁªìÊûÑÊÄßÂÜ≤Âáª„ÄÇ‚Äù

### ‰∫å„ÄÅÊñ∞ÁöÑËÅå‰∏öËßíËâ≤Ê≠£Âú®Âá∫Áé∞

Dan È¢ÑÊµãÔºåÂ∑•Á®ãÂ∏àÂ∞ÜÂá∫Áé∞**Á¨¨‰∏âÁßçÂΩ¢ÊÄÅ**Ôºö **Agentic Engineer** ‚Äî‚Äî‰ªñ‰ª¨‰∏çÂÜç‰∫≤Ëá™ÂÆûÁé∞ÂäüËÉΩÔºåËÄåÊòØÊääÊâßË°åÂÆåÂÖ®‰∫§Áªô AIÔºåËá™Â∑±‰∏äÁßª‰∏ÄÂ±ÇÔºå‰∏ìÊ≥®‰∫é**ÁÆ°ÁêÜ‰∏éÁºñÊéí Agent**„ÄÇ

**Kate** ËÆ§‰∏∫ÔºåÂà∞ 2026 Âπ¥ÔºåÂ§ßÂ§öÊï∞ÂÖ¨Âè∏ÈÉΩ‰ºöËá≥Â∞ëËÆæÁ´ã‰∏Ä‰∏™‰∏ìÈó®Â≤ó‰ΩçÔºåË¥üË¥£**ÊûÑÂª∫„ÄÅÁª¥Êä§ÂíåÊåÅÁª≠‰ºòÂåñÂÜÖÈÉ® AI Á≥ªÁªü**Ôºö

> ‚ÄúËøô‰∏™‰∫∫ÁöÑÂ∑•‰ΩúÔºåÂ∞±ÊòØ‰∏çÊñ≠ÊèêÂçáÊï¥‰∏™ÁªÑÁªá‰ΩøÁî® AI ÁöÑÊñπÂºè„ÄÇ‚Äù

**Ashwin** ‰πüÊèêÂà∞ÔºåÂàÜÊûêÂ∏àÁöÑÂ∑•‰ΩúÊµÅÂêåÊ†∑‰ºöË¢´ÈáçÂ°ëÔºö

> ‚ÄúÁé∞Âú®ÊàëËøòÂú®‰∏çÂêåÂ∑•ÂÖ∑‰πãÈó¥Êù•ÂõûÂàáÊç¢Ôºå‰ΩÜÊàëÁêÜÊÉ≥‰∏≠ÁöÑÁä∂ÊÄÅÔºåÊòØÂú®ÁªàÁ´ØÈáåÂÆåÊàê‰∏ÄÂàáÔºåËÆ© Claude ÊääÊàëÁöÑÁ†îÁ©∂Êï¥ÂêàËµ∑Êù•ÔºåÁõ¥Êé•ÁîüÊàê‰∏Ä‰ªΩÊñáÊ°£„ÄÇ‚Äù

### ‰∏â„ÄÅËÆæËÆ°Â∏àÂ∞ÜÊàê‰∏∫‚ÄúË∂ÖÁ∫ß‰∏™‰Ωì‚Äù

Dan ÁöÑÂà§Êñ≠ÊòØÔºö

> ‚ÄúÈïøÊúü‰ª•Êù•ÔºåÊúâ‰∏ÄÊï¥Á±ªÊûÅÂÖ∑ÂàõÈÄ†Âäõ„ÄÅËßÜËßâËÉΩÂäõÊûÅÂº∫ÁöÑ‰∫∫ÔºåË¢´‚Äò‰∏ç‰ºöÂÜô‰ª£Á†Å‚ÄôÈôêÂà∂‰Ωè‰∫Ü„ÄÇÁé∞Âú®Ôºå‰ªñ‰ª¨Â∞ÜÁúüÊ≠£Êã•ÊúâÊûÑÂª∫ÂÆåÊï¥‰ΩìÈ™åÁöÑËÉΩÂäõ„ÄÇ‚Äù

‰∏çËøá **Brandon** ÊèêÈÜíÔºåËÆæËÆ°Â∏àÁúüÊ≠£Êã•Êä± AI ÁöÑÂâçÊèêÔºåÊòØ**Â∑•ÂÖ∑ÂøÖÈ°ª‰∏çÂÉèÂú®‚ÄòÂÜô‰ª£Á†Å‚Äô**ÔºåËÄåÊòØË∂≥Â§üÁõ¥Ëßâ„ÄÅË∂≥Â§ü‰∏çÂÖ∑Â®ÅÊÖëÊÑü„ÄÇ

‰∏ã‰∏ÄÊ≥¢ÂàõÈÄ†ËÄÖÔºåÂèØËÉΩÁúãËµ∑Êù•‰ºöÂíå‰∏ä‰∏Ä‰ª£ÂÆåÂÖ®‰∏çÂêå„ÄÇ

### ÂΩ©ËõãÈ¢ÑÊµãÔºö‰∏Ä‰∏™ÊàêÂäüÁöÑÊú∫Âô®‰∫∫ÂÆ†Áâ©

Every Âπ≥Âè∞Ë¥üË¥£‰∫∫ **Willie Williams** ÊäõÂá∫‰∫Ü‰∏Ä‰∏™Âá∫‰∫∫ÊÑèÊñôÁöÑÂà§Êñ≠Ôºö

**Âà∞ 2026 Âπ¥Â∫ïÔºå‰∏ÄÊ¨æÈù¢ÂêëÂ§ß‰ºóÂ∏ÇÂú∫ÁöÑÊú∫Âô®‰∫∫ÂÆ†Áâ©‰ºöÁúüÊ≠£Ë∑ëÂá∫Êù•„ÄÇ**

‰ªñÊõæÊääËá™Â∑±‰π∞ÁöÑÊú∫Âô®‰∫∫Áå´Â∏¶Ëøõ‰ºöËÆÆÂÆ§ÔºåÁªìÊûúÊòØÔºö

* **85%** ÁöÑ‰∫∫Êú¨ËÉΩÂú∞ËÆ®ÂéåÂÆÉÔºåÁîöËá≥ÊÉ≥ÊääÂÆÉÊâîÊéâ
* **10%** ÁöÑ‰∫∫Êó†ÊÑü
* **5%** ÁöÑ‰∫∫ÈùûÂ∏∏ÂñúÊ¨¢

‰ªñÊ≠£Âú®ÂÖ≥Ê≥®‰∏ÄÊ¨æÂè´ **Moflin** ÁöÑÊØõÁªíÊú∫Âô®‰∫∫ÔºåËÆ§‰∏∫ÂÆÉ**ÊàêÂäüË∑®Ëøá‰∫Ü‚ÄúÊÅêÊÄñË∞∑‚Äù**„ÄÇ

> ‚ÄúÊÄª‰ºöÊúâ‰∫∫ÊääËøô‰ª∂‰∫ãÁúüÊ≠£ÂÅöÂØπ„ÄÇ‚Äù

## ËΩØ‰ª∂Ê≠£Âú®Ë¢´ AI ÈáçÊñ∞ÂÆö‰πâ

Dan Shipper Âú®Êí≠ÂÆ¢ **AI & I** ‰∏≠ÈÇÄËØ∑‰∫Ü Every ÁöÑ COO **Brandon Gell**ÔºåÂÖ±ÂêåËÆ®ËÆ∫‰ªñ‰ª¨ÂØπÊú™Êù•ÁöÑÂà§Êñ≠„ÄÇ

ËøôÊ¨°ÂØπËØùÂõ¥Áªï‰∏â‰∏™Ê†∏ÂøÉÈóÆÈ¢òÂ±ïÂºÄÔºö **ËΩØ‰ª∂Â∞ÜÂ¶Ç‰ΩïË¢´ÊûÑÂª∫ÔºüÁî±Ë∞ÅÊù•ÊûÑÂª∫Ôºü‰ª•ÂèäÁúüÊ≠£Ëá™‰∏ªÁöÑ AI Agent ÈúÄË¶Å‰ªÄ‰πàÊù°‰ª∂ÊâçËÉΩÂÆûÁé∞Ôºü**

Â∞±Ê≠§Ôºå‰ªñ‰ª¨ÊèêÂá∫ÁöÑ **Âõõ‰∏™Ê†∏ÂøÉÈ¢ÑÊµã**Ôºö

### È¢ÑÊµã‰∏ÄÔºö‰∏ã‰∏Ä‰ª£ËΩØ‰ª∂Â∞ÜÊää Agent ËßÜ‰∏∫‚Äú‰∏ÄÁ≠âÂÖ¨Ê∞ë‚Äù

Dan ËÆ§‰∏∫Ôºå**2025 Âπ¥ÊòØÁºñÁ†ÅÂûã Agent ÁúüÊ≠£ÂèòÂæóÂèØÈù†ÁöÑ‰∏ÄÂπ¥**„ÄÇ

‰∏ÄÂπ¥ÂâçÔºåËøôÁ±ªÂ∑•ÂÖ∑Â∑≤ÁªèËÉΩÂ∏Æ‰∫∫Ëµ∞ÂæóÂæàËøúÔºå‰ΩÜÂ¶ÇÊûú‰Ω†‰∏çÊòØ‰∏ì‰∏öÂºÄÂèëËÄÖÔºåÂæàÂÆπÊòìÂú®ÈîôËØØÂíå bug Èù¢ÂâçÂç°‰ΩèÔºåÈöæ‰ª•ÁªßÁª≠„ÄÇËÄåÁé∞Âú®ÔºåÂÄüÂä©ÂÉè **Anthropic ÁöÑ Opus 4.5** ËøôÊ†∑ÁöÑÊ®°ÂûãÔºå‰Ω†Âá†‰πéÂèØ‰ª•‰∏ÄÁõ¥Êé®Ëøõ‰∏ãÂéª„ÄÇ

Dan ËÆ§‰∏∫ÔºåËøôÂ∞Ü‰ªéÊ†πÊú¨‰∏äÊîπÂèòÂ∫îÁî®ÁöÑÊûÑÂª∫ÊñπÂºèÔºå‰ª•Âèä**Áî±Ë∞ÅÊù•ÊûÑÂª∫Â∫îÁî®**„ÄÇ‰ªñÊääËøôÁßçÂèòÂåñÁß∞‰∏∫ **‚ÄúAgent-native architectureÔºàAgent ÂéüÁîüÊû∂ÊûÑÔºâ‚Äù**ÔºåÂπ∂Áî®‰∏Ä‰∏™‰∏âÂ±ÇÈò∂Ê¢ØÊù•ÊèèËø∞Ôºö

**Á¨¨‰∏ÄÂ±ÇÔºö‰Ω†ËÉΩÂÅöÁöÑ‰∫ãÔºåAgent ‰πüËÉΩÂÅö** Â¶Ç‰ªäÔºåËÆ∏Â§öÂ∫îÁî®Â∑≤ÁªèÂÜÖÁΩÆ AI Âä©ÊâãÔºåÂèØ‰ª•ÈÄöËøáÂØπËØùÂÆåÊàêÈÉ®ÂàÜÊìç‰ΩúÔºå‰ΩÜÂäüËÉΩÂæÄÂæÄÂ±ÄÈôêÂú®È¢ÑËÆæËåÉÂõ¥ÂÜÖ„ÄÇÂú® Agent-native Â∫îÁî®‰∏≠ÔºåAI Â∞ÜÂÉè‰∫∫Á±ªÁî®Êà∑‰∏ÄÊ†∑Êìç‰ΩúËΩØ‰ª∂ÔºåËÉΩÂ§üËÆøÈóÆÊâÄÊúâÊåâÈíÆ„ÄÅËÆæÁΩÆÂíåÂäüËÉΩ„ÄÇ Dan ËÆ§‰∏∫ÔºåOpenAI ÁöÑÊµèËßàÂô®Â∑•ÂÖ∑ Atlas Â∑≤ÁªèÂ±ïÁ§∫‰∫ÜËøô‰∏ÄÊ®°ÂºèÁöÑÊó©ÊúüÂΩ¢ÊÄÅ„ÄÇ‰æãÂ¶ÇÔºåÂΩì‰ªñÈúÄË¶ÅÊääÊüê‰∫∫Âä†ÂÖ• Every ÁöÑÂÖ±‰∫´Â∑•‰ΩúÂå∫ÔºàÂ¶Ç NotionÔºâÊó∂Ôºå‰∏çÂÜçËá™Â∑±Âú®Â§çÊùÇÁöÑËÆæÁΩÆÈ°µÈù¢‰∏≠Êü•ÊâæÔºåËÄåÊòØÁõ¥Êé•ËÆ© Atlas ÂéªÂÆåÊàê„ÄÇ

**Á¨¨‰∫åÂ±ÇÔºöÂ∫îÁî®‰ª£Á†ÅËÉΩÂÅöÁöÑ‰∫ãÔºåAgent ‰πüËÉΩÂÅö** ÂæàÂ§öÂ∫îÁî®Âú®ÂêéÂè∞ËøêË°åÁùÄÁî®Êà∑Êó†Ê≥ïÁõ¥Êé•ÊéßÂà∂ÁöÑÈÄªËæë„ÄÇÊØîÂ¶Ç Every ÁöÑÈÇÆ‰ª∂Âä©Êâã CoraÔºåÊØèÂ§©‰ºöËá™Âä®ÁîüÊàê‰∏§Ê¨°Êî∂‰ª∂ÁÆ±ÊëòË¶ÅÔºàBriefÔºâÔºåËÄåÂ∫ïÂ±Ç‰ª£Á†ÅÂÖ∂ÂÆûÂ∑≤ÁªèÂÖ∑Â§áÁî®‰∏çÂêåÂÜô‰ΩúÈ£éÊ†ºÈáçÊñ∞ÁîüÊàêÊëòË¶ÅÁöÑËÉΩÂäõ„ÄÇ Âú® Agent-native Â∫îÁî®‰∏≠ÔºåAI ÂèØ‰ª•Áõ¥Êé•Ë∞ÉÁî®Ëøô‰∫õ‚ÄúÂêéÂè∞ËÉΩÂäõ‚ÄùÔºöÁî®Êà∑‰∏çÂÜçË¢´ÈªòËÆ§ÊëòË¶ÅÈôêÂà∂ÔºåËÄåÊòØÂèØ‰ª•Ë¶ÅÊ±Ç Agent ÈáçÊñ∞ÁîüÊàê‚Äî‚ÄîÊõ¥Áü≠„ÄÅÊõ¥ÁäÄÂà©„ÄÅÊõ¥Ê≠£ÂºèÔºåÂÆåÂÖ®ÊåâÈúÄÂÆöÂà∂„ÄÇ Ê†∏ÂøÉÂú®‰∫éÔºåAgent ËÉΩÂ§üËøõÂÖ•Â∫îÁî®ÁöÑ‚ÄúÂêéÂè∞‚ÄùÔºå‰ΩøÁî®ÈÇ£‰∫õÁõÆÂâçÂπ∂Êú™‰Ωú‰∏∫ÂâçÁ´ØÂäüËÉΩÊö¥Èú≤ÁªôÁî®Êà∑ÁöÑËÉΩÂäõ„ÄÇ

**Á¨¨‰∏âÂ±ÇÔºöÂºÄÂèëËÄÖËÉΩÂÅöÁöÑ‰∫ãÔºåAgent ‰πüËÉΩÂÅö** ËøôÊÑèÂë≥ÁùÄÔºåAI Agent ÂèØ‰ª•ÂÆåÊàêÁõÆÂâçÂè™ÊúâÂºÄÂèëËÄÖÊâçËÉΩÂÆåÊàêÁöÑÂ∑•‰Ωú„ÄÇÁî®Êà∑Âè™ÈúÄÊèêÂá∫ÈúÄÊ±ÇÔºåAgent Â∞±ËÉΩÁõ¥Êé•ÂÆûÁé∞‚Äî‚ÄîÊó†ËÆ∫ÊòØ‰øÆÂ§ç bug„ÄÅÊ∑ªÂä†ÂäüËÉΩÔºåËøòÊòØ‰øÆÊîπËΩØ‰ª∂ÁöÑËøêË°åÊñπÂºè„ÄÇ Êúâ‰∫õÊîπÂä®ÂèØËÉΩ‰ºöË¢´Êé®ÈÄÅÁªôÊâÄÊúâÁî®Êà∑ÔºõÊúâ‰∫õÂàô‰ºöÁîüÊàêÂè™Â±û‰∫éÊüê‰∏Ä‰∏™‰∫∫ÁöÑ‰∏™ÊÄßÂåñÁâàÊú¨„ÄÇDan Ë°®Á§∫ÔºåEvery Â∑≤ÁªèÂú®ÂÜÖÈÉ®Â∞ùËØïËøôÁßçÊ®°Âºè„ÄÇËôΩÁÑ∂‰ªçÂ§ÑÂú®Êó©ÊúüÈò∂ÊÆµÔºå‰ΩÜ‰ªñÁúãÂà∞ Anthropic„ÄÅNotion Á≠âÂÖ¨Âè∏‰πüÂú®ÊúùÁùÄÁ±ª‰ººÊñπÂêëÊÄùËÄÉ‚Äî‚ÄîÊûÑÂª∫‰∏ÄÁßç**‰∫∫Á±ª‰∏é Agent ÂêåÊó∂‰Ωú‰∏∫‚Äú‰∏ÄÁ≠âÂÖ¨Ê∞ë‚Äù**ÁöÑËΩØ‰ª∂‰ΩìÁ≥ªÔºåËÄå‰∏çÊòØÂú®ÂéüÊú¨Âè™‰∏∫‰∫∫Á±ªËÆæËÆ°ÁöÑ‰∫ßÂìÅ‰∏äÁÆÄÂçïÂè†Âä† AI„ÄÇ

### È¢ÑÊµã‰∫åÔºöËÆæËÆ°Â∏àÂ∞ÜÂºÄÂßã‰∏∫Ëá™Â∑±ÊûÑÂª∫Â∑•ÂÖ∑

Dan ÊåáÂá∫ÔºåÈïøÊúü‰ª•Êù•ÔºåËÆæËÆ°Â∏àÂíåÂàõÊÑèÂ∑•‰ΩúËÄÖ‰πãÊâÄ‰ª•Èöæ‰ª•ÊûÑÂª∫ÂÆåÊï¥‰∫ßÂìÅ‰ΩìÈ™åÔºå‰∏ªË¶ÅÊòØÂõ†‰∏∫‰∏ç‰ºöÂÜô‰ª£Á†Å„ÄÇ‰ΩÜËøôÁßçÈôêÂà∂Ê≠£Âú®Ë¢´ÊâìÁ†¥„ÄÇ

‰ªñ‰ª• Every ÁöÑÂàõÊÑèË¥üË¥£‰∫∫ **Lucas Crespo** ‰∏∫‰æãÔºöLucas Â∑≤Áªè‰ªé‰º†ÁªüÊÑè‰πâ‰∏äÁöÑËÆæËÆ°Â∏àÔºåËΩ¨Âèò‰∏∫ËÉΩÂ§üÈÄöËøá _vibe coding_ ÁºñÂÜôÂ∞èÂ∑•ÂÖ∑ÁöÑ‰∫∫ÔºåÁî®Êù•ÊèêÂçáËá™Â∑±ÁöÑÂ∑•‰ΩúÊïàÁéá„ÄÇ

‰∏çËøá Brandon ÂØπËøôÁßçÂèòÂåñÁöÑÊôÆÂèäÁ®ãÂ∫¶ÊåÅË∞®ÊÖéÊÄÅÂ∫¶„ÄÇ‰ªñÂõûÂøÜËµ∑Ëá™Â∑±ÊõæÁªè‰πüÂÆ≥ÊÄïÁªàÁ´ØÁïåÈù¢ÔºåÂπ∂ËÆ§‰∏∫ËÆ∏Â§öËÆæËÆ°Â∏àÂú®Èù¢ÂØπÂÉè Cursor ËøôÊ†∑ÁöÑ AI ÁºñÁ®ãÂ∑•ÂÖ∑Êó∂ÔºåÂèØËÉΩ‰ºöÊúâÁ±ª‰ººÂøÉÁêÜÈöúÁ¢ç„ÄÇ Â¶ÇÊûúËøôÁ±ªÂ∑•ÂÖ∑Â∏åÊúõÁúüÊ≠£Ëµ∞ÂêëËÆæËÆ°Â∏àÁæ§‰ΩìÔºåBrandon ËÆ§‰∏∫Ôºå**ÂÆÉ‰ª¨ÈúÄË¶ÅËøõ‰∏ÄÊ≠•ÊäΩË±°‰ª£Á†ÅÊú¨Ë∫´**ÔºåÂê¶ÂàôÂæàÂ§ö‰∫∫ÂèØËÉΩÂú®ÂºÄÂßã‰πãÂâçÂ∞±Â∑≤ÁªèË¢´ÂêìÈÄÄ„ÄÇ

### È¢ÑÊµã‰∏âÔºöÊñ∞‰∏Ä‰ª£ËΩØ‰ª∂Â∑•Á®ãÂ∏àÂ∞Ü‰∏ìÊ≥®‰∫é‚ÄúÊåáÊå•‚ÄùAgent

ÈöèÁùÄ AI ËÉΩÂäõÁöÑÊºîËøõÔºåDan ËßÇÂØüÂà∞ÁõÆÂâçÂ∑≤ÁªèÂá∫Áé∞‰∫Ü‰∏§Á±ªËΩØ‰ª∂ÊûÑÂª∫ËÄÖÔºö

‰∏ÄÁ±ªÊòØÊää AI ÂΩì‰ΩúÂä†ÈÄüÂô®ÁöÑÂ∑•Á®ãÂ∏à‚Äî‚Äî‰ªñ‰ª¨Áî® AI ÊèêÈÄüÔºå‰ΩÜ‰æùÁÑ∂‰ºöËØª‰ª£Á†Å„ÄÅÂÜô‰ª£Á†ÅÔºõ Âè¶‰∏ÄÁ±ªÊòØ _vibe coders_‚Äî‚ÄîËÉΩÊää‰∏úË•øË∑ëËµ∑Êù•Ôºå‰ΩÜÂπ∂‰∏çÁúüÊ≠£ÁêÜËß£Â∫ïÂ±ÇÂÆûÁé∞„ÄÇ

Dan ËÆ§‰∏∫Ôºå**Á¨¨‰∏âÁ±ª‰∫∫Ê≠£Âú®Âá∫Áé∞**Ôºö‰ªñÁß∞‰πã‰∏∫ **‚Äúagentic engineers‚Äù**„ÄÇ

ËøôÁ±ªÂ∑•Á®ãÂ∏àÂá†‰πé‰∏çÂÜç‰∫≤Ëá™ÂÜô‰ª£Á†ÅÔºåËÄåÊòØÊääËΩØ‰ª∂ÂºÄÂèëÈáçÊñ∞ÂÆö‰πâ‰∏∫Ôºö**ÊåáÊå•ÂíåÁºñÊéí AI Agent**„ÄÇ‰ªñ‰ª¨ÊääÂá†‰πéÊâÄÊúâÂÆûÁé∞Â∑•‰Ωú‰∫§Áªô AgentÔºåËá™Â∑±‰∏ìÊ≥®‰∫éÊõ¥È´òÂ±ÇÊ¨°ÁöÑ‰∫ãÊÉÖ‚Äî‚ÄîÂÆö‰πâÁõÆÊ†á„ÄÅÊãÜËß£ÈóÆÈ¢ò„ÄÅÂçèË∞É‰∏Ä‰∏™ÊàñÂ§ö‰∏™ Agent ÁöÑÊâßË°å„ÄÇ

ËøôÊòØ‰∏ÄÁßçÊúâÊÑèËØÜÁöÑÂèñËàçÔºö‰ªñ‰ª¨Êé•ÂèóËá™Â∑±ÂéüÊúâÁöÑÁºñÁ†ÅËÉΩÂäõÈÄêÊ∏êÈÄÄÂåñÔºåÊç¢Âèñ‰∏ÄÁßçÊñ∞ÁöÑÊ†∏ÂøÉËÉΩÂäõ‚Äî‚Äî**Êàê‰∏∫Êõ¥Â•ΩÁöÑ Agent ÁÆ°ÁêÜËÄÖ**ÔºåÂõ†‰∏∫Âú®‰ªñ‰ª¨ÁúãÊù•ÔºåËøôÊ≠£ÊòØÊú™Êù•ËΩØ‰ª∂Ë¢´ÊûÑÂª∫ÁöÑ‰∏ªË¶ÅÊñπÂºè„ÄÇ

### È¢ÑÊµãÂõõÔºö‰∏ã‰∏ÄÈò∂ÊÆµÁöÑ AI ËÆ≠ÁªÉÂ∞Ü‚ÄúÁ¥¢ÂºïÁã¨Á´ãÊÄß‚Äù

Dan Áî®ÂÑøÁ´•ÊàêÈïøÊù•Á±ªÊØî AI Agent ÁöÑÂèëÂ±ïË∑ØÂæÑÔºö Â©¥ÂÑøÊúÄÂàùÂè™ËÉΩÂú®ÁúãÊä§‰∏ãÁã¨Â§ÑÂá†ÂàÜÈíüÔºåÈöèÁùÄÊàêÈïøÔºåÊâçÈÄêÊ∏êËÉΩÂú®Êó†‰∫∫Âπ≤È¢ÑÁöÑÊÉÖÂÜµ‰∏ãÊ¥ªÂä®Êõ¥ÈïøÊó∂Èó¥„ÄÇ

Á±ª‰ººÂú∞ÔºåÂá†Âπ¥ÂâçÁöÑÂ§ßÊ®°ÂûãÂü∫Êú¨Âè™ËÉΩÂ§ÑÁêÜÂçïËΩÆ‰ªªÂä°ÔºõÂ¶Ç‰ªäÔºåÂÆÉ‰ª¨Â∑≤ÁªèÂèØ‰ª•ËøûÁª≠ËøêË°å 20 ÂàÜÈíüÔºåÁîöËá≥Êé•Ëøë‰∏ÄÂ∞èÊó∂ÔºåËÄå‰∏çÈúÄË¶Å‰∫∫Â∑•‰ªãÂÖ•„ÄÇ‰ΩÜËøôË∑ùÁ¶ªÁúüÊ≠£ÁöÑ‚ÄúÊó†ÈôêËøêË°å‚Äù‰ªçÁÑ∂Áõ∏ÂéªÁîöËøú„ÄÇ

Dan ËÆ§‰∏∫Ôºå**ÁúüÊ≠£ÁöÑËá™‰∏ªÊÄß**‚Äî‚ÄîÂç≥Âú®ÁªèÊµé‰∏äÂÄºÂæóËÆ© Agent ÊåÅÁª≠„ÄÅËá™ÂèëÂú∞ÊâßË°å‰ªªÂä°‚Äî‚ÄîÊòØ‰∏Ä‰∏™ÈùûÂ∏∏Âõ∞ÈöæÁöÑÈóÆÈ¢ò„ÄÇËøô‰∏ç‰ªÖÈúÄË¶ÅÊåÅÁª≠Â≠¶‰π†ËÉΩÂäõ„ÄÅÊ∏ÖÊô∞ÁöÑÁõÆÊ†á‰ΩìÁ≥ªÔºåËøòÈúÄË¶ÅËÉΩÂ§üÂú®Êó∂Èó¥Áª¥Â∫¶‰∏äÂêàÁêÜÂú∞Ë∞ÉÊï¥Ëøô‰∫õÁõÆÊ†á„ÄÇ

ÂÖ∂‰∏≠‰∏Ä‰∏™Ê†∏ÂøÉÊåëÊàòÔºåÊù•Ëá™Êàë‰ª¨ÁõÆÂâçÂØπÊ®°ÂûãÁöÑËÆ≠ÁªÉÊñπÂºè„ÄÇÁé∞ÊúâÁöÑÂØπÈΩêËÆ≠ÁªÉÔºåÂº∫Ë∞ÉÁöÑÊòØÂèØÈ¢ÑÊµãÊÄß‰∏éÊúç‰ªéÊÄßÔºöËÆ©Ê®°Âûã‰∏•Ê†ºÊâßË°åÊåá‰ª§„ÄÇ‰ΩÜ Dan ËÆ§‰∏∫ÔºåË¶ÅÂÆûÁé∞ÁúüÊ≠£ÁöÑËá™‰∏ªÔºåAgent ÂøÖÈ°ªÊã•ÊúâÊé¢Á¥¢ÂíåÁäØÈîôÁöÑÁ©∫Èó¥‚Äî‚ÄîËÄåËøôÊÅ∞ÊÅ∞ÊòØÂá∫‰∫éÂÆâÂÖ®ËÄÉÈáèÔºåÊàë‰ª¨ÈïøÊúü‰ª•Êù•‰∏ÄÁõ¥Âú®ÈôêÂà∂ÁöÑÈÉ®ÂàÜ„ÄÇ

‰ªñÈ¢ÑÊµãÔºåÊé•‰∏ãÊù•ÁöÑ‰∏ÄÂπ¥ÈáåÔºå‰ºöÂá∫Áé∞Êñ∞ÁöÑËÆ≠ÁªÉÊñπÊ≥ïÂíåÊ®°ÂûãÊû∂ÊûÑÔºåÈÄêÊ≠•ÊîæÊùæËøô‰∫õÁ∫¶ÊùüÔºåËÆ© Agent Âú®Êõ¥ÂèØÊéßÁöÑÂâçÊèê‰∏ãÔºåËé∑ÂæóÊõ¥È´òÁ®ãÂ∫¶ÁöÑÁã¨Á´ãÊÄß„ÄÇ

hidden text to trigger resize events if fonts change

---

# [‰∫îÊù°0106] a16z È¢ÑÊµãÔºöAI Â∞ÜÊàê‰∏∫‰Ω†ÁöÑÊÄùËÄÉ‰ºô‰º¥
ÂèëÂ∏ÉÊó•ÊúüÔºö2026/01/05

**2026 Âπ¥ AI Â∫îÁî®ËßÇÂØüÁ¨îËÆ∞** \- Êù•Ëá™ [@a16z](https://twitter.com/a16z) Âõ¢Èòü [@illscience](https://twitter.com/illscience) Ôºå‰ªñËÆ§‰∏∫Ôºö2026Âπ¥ÔºåAI Â∫îÁî®Â∞Ü‰ªéÊâßË°åÂ∑•ÂÖ∑ËΩ¨ÂêëÊé¢Á¥¢‰∏éÊÄùËÄÉÂ∑•ÂÖ∑ÔºåÊé®Âä®‰ºÅ‰∏öÊâÄÊúâÈÉ®Èó®ËΩØ‰ª∂‰ºòÂÖà„ÄÅÈáéÂøÉÂ§ßÂπÖÊèêÂçáÔºåÂπ∂ÂÇ¨ÁîüÈ´òÂ∫¶‰∏ì‰∏öÂåñÁöÑÂ§çÂêàÂûã AI ÂéüÁîüÂ∫îÁî®ÔºåÂ∫îÁî®Â±ÇÂ∞ÜÁã¨Á´ã‰∫éÊ®°ÂûãÂ±ÇÊåÅÁª≠ÁπÅËç£„ÄÇ

**ÊÄùËÄÉÂ∑•ÂÖ∑ vs ÊâßË°åÂ∑•ÂÖ∑**

 ÂΩìÂâçÁü•ËØÜÂ∑•‰ΩúÂ∑•ÂÖ∑ÔºàÂ¶Ç IDE„ÄÅFigma„ÄÅExcelÔºâ‰∏ªË¶ÅËÅöÁÑ¶‰∫é‚ÄúÂà∂‰ΩúÂíåÊâßË°å‚ÄùÔºåËÄåÁº∫‰πèÂ∏ÆÂä©‚ÄúÊÄùËÄÉ‚ÄùÁöÑÁé∞‰ª£‰∫ßÂìÅ„ÄÇLLM Â∑≤ÂàùÊ≠•Êàê‰∏∫ÊÄùËÄÉ‰ºô‰º¥„ÄÇÈöèÁùÄÁºñÁ®ãÊô∫ËÉΩ‰ΩìÁöÑÂáÜÁ°ÆÊÄßÂíåÊó∂Èó¥Ë∑®Â∫¶ÊèêÂçáÔºåÈöæÁÇπÂ∞Ü‰ªé‚ÄúÂ¶Ç‰ΩïÊûÑÂª∫‚ÄùËΩ¨Âêë‚ÄúÊûÑÂª∫‰ªÄ‰πà‚Äù„ÄÇÊú™Êù•‰∫ßÂìÅÁªèÁêÜÂèØËÉΩÂè™ÈúÄËÆæÂÆöÂ§ßÁõÆÊ†áÔºåAI Âç≥ÂèØËá™‰∏ªÊèêÂá∫„ÄÅÂÆûÁé∞Âπ∂ÊµãËØïÊñ∞ÂäüËÉΩ„ÄÇ‰ΩÜÂΩìÂâçÊ®°ÂûãÂú®ÂàõÊÑèÁîüÊàê‰∏ä‰ªçËæÉÂπ≥Â∫∏ÔºåÁº∫‰πèÁúüÊ≠£ÂàõÊñ∞ÁöÑ‚ÄúÁÅ´Ëä±‚Äù„ÄÇÂõ†Ê≠§Ôºå‰∏ã‰∏Ä‰ª£Â∑•ÂÖ∑ÔºàÂ¶Ç Cursor„ÄÅAntigravityÔºâÂ∞ÜÊõ¥Ê≥®ÈáçÊé¢Á¥¢ËÄåÈùûÂçïÁ∫ØÊâßË°å„ÄÇ

**ËΩØ‰ª∂Â∞ÜÂêûÂô¨‰ºÅ‰∏ö‰∏≠ÁöÑ‚ÄúÊúçÂä°‚ÄùËÅåËÉΩ**

 ‰ºÅ‰∏öÂÜÖÈÉ®ÂèØÂàÜ‰∏∫‚ÄúÊùÉÂäõËÅåËÉΩ‚ÄùÔºàÂ∑•Á®ã„ÄÅ‰∫ßÂìÅ„ÄÅËê•ÈîÄÔºåÊõ¥Êé•ËøëËΩØ‰ª∂ÔºâÂíå‚ÄúÊúçÂä°ËÅåËÉΩ‚ÄùÔºàÊ≥ïÂä°„ÄÅË¥¢Âä°„ÄÅ‰∫∫ÂäõÔºåÊõ¥‰æùËµñ‰∫∫ÂäõÔºâ„ÄÇÁºñÁ†ÅÊô∫ËÉΩ‰ΩìÂ∞ÜÊé®Âä®ÊâÄÊúâÂõ¢Èòü‰ºòÂÖàÈááÁî®ËΩØ‰ª∂Ëß£ÂÜ≥ÊñπÊ°àÔºöÊØè‰∏™ÈÉ®Èó®ÈÉΩÂ∫îÊàê‰∏∫‚ÄúËΩØ‰ª∂Âõ¢Èòü‚ÄùÔºåÈ¢ÜÂØºËÄÖÈúÄÂÖàËÄÉËôëËΩØ‰ª∂Â∑•ÂÖ∑ËÄåÈùû‰º†ÁªüÊµÅÁ®ã„ÄÇÊúâ‰∫õÂõ¢Èòü‰ºöÁî®È¢ÜÂüü‰∏ìÁî®‰∫ßÂìÅÔºàÂ¶Ç Harvey ÈíàÂØπÊ≥ïÂä°ÔºâÔºåÂÖ∂‰ªñÂàôÁõ¥Êé•Áî®ÈÄöÁî®Êô∫ËÉΩ‰ΩìÔºàÂ¶Ç Claude CodeÔºâ„ÄÇÂêåÊó∂Ôºå‰ºÅ‰∏öÂèØÂ§ßÂπÖÊèêÂçáËΩØ‰ª∂ÈáéÂøÉ‚Äî‚Äî‚ÄúÊâÄÊúâËÉΩÊûÑÂª∫ÁöÑÂäüËÉΩÈÉΩÂ∞ÜË¢´ÊûÑÂª∫‚ÄùÔºåËøôË¶ÅÊ±ÇÈáçÂ°ëÂàõÊÑèÂíå‰ºòÂÖàÁ∫ßÊµÅÁ®ã„ÄÇÊñáÂåñ‰∏éÁªÑÁªáÂèòÈù©ÁöÑÈöæÂ∫¶Â∞Ü‰∏ç‰∫ö‰∫éÊäÄÊúØÊú¨Ë∫´„ÄÇ

**Â§çÂêàÂûã AI Â∫îÁî®ÁöÑÂÖ¥Ëµ∑**

 ÈöèÁùÄÊé®ÁêÜÊ®°ÂûãËøõÂÖ•Á¨¨‰∫åÂπ¥ÔºåAI ÂéüÁîüÂ∫îÁî®Â∞Ü‰∏éÂü∫Á°ÄÊ®°ÂûãËøõ‰∏ÄÊ≠•ÂàÜÂåñ„ÄÇÂ∫îÁî®Â±ÇÂ∞ÜÁªìÂêàÂ§öÊ®°ÂûãÁºñÊéí„ÄÅÈ¢ÜÂüü‰∏ìÁî® UI ÂíåÂ§ßÈù¢ÁßØÂäüËÉΩ„ÄÇËøôÂª∂Áª≠‰∫Ü ‚ÄúNarrow Startups‚Äù ÁöÑÈÄªËæëÔºöÊûÅÁ´Ø‰∏ì‰∏öÂåñÊàê‰∏∫ÂèØËÉΩ„ÄÇÊ®°ÂûãÂ±Ç‰∏ç‰ºöÂêûÂô¨Â∫îÁî®Â±ÇÔºåÂç≥‰ΩøÂú®ÁºñÁ†ÅÁ≠âÈ¢ÜÂüüÔºåÂàùÂàõ‰ºÅ‰∏öÁîüÊÄÅÂ∑≤Ëì¨ÂãÉÔºà2025Âπ¥Êñ∞Â¢ûËê•Êî∂Ë∂Ö10‰∫øÁæéÂÖÉÔºâ„ÄÇ‰ºòÂäøÈ¢ÜÂüüÂåÖÊã¨Â§öÊ®°ÂûãÊï¥Âêà„ÄÅ‰∏ìÊúâÊï∞ÊçÆ„ÄÅÁΩëÁªúÊïàÂ∫îÂíå‰∏∞ÂØåÂäüËÉΩË°®Èù¢„ÄÇÁªìÂêà Karpathy ÁöÑ ‚Äúthick‚Äù AI apps Ê°ÜÊû∂ÔºåÊàêÁÜü AI Â∫îÁî®Â∞ÜÊõ¥Â§çÊùÇ„ÄÅÊõ¥Ëá™‰∏ª„ÄÇ

**‰∫∫Á±ªÂ∞ÜÂèëÁé∞ AI ÁöÑ‚ÄúÂÖ∂‰Ωô‚ÄùÊΩúÂäõ**

 ÂëΩ‰ª§Ë°åÂºèÁïåÈù¢ÊõæÈôêÂà∂ÊôÆÈÄöÊ∂àË¥πËÄÖÊé•Ëß¶AIÈ´òÁ∫ßËÉΩÂäõÔºåËøô‰∏ÄÂ±ÄÈù¢Ê≠£Âú®ÊîπÂèòÔºàÂ¶Ç Wabi Êö¥Èú≤‰ª£Á†ÅÁîüÊàê„ÄÅChatGPT/Grok ÁöÑÂõæÂÉèÂäüËÉΩÔºâ„ÄÇÊõ¥Â§öÊ∂àË¥πËÄÖÂºÄÂßãËá™Ë°åÂàõÂª∫Â∞èÁ®ãÂ∫è„ÄÅÊô∫ËÉΩ‰ΩìÁ≠âÔºåËøôÂ∞ÜÈÉ®ÂàÜÁºìËß£ AI ÂØπÊñáÂåñÂíåÁ§æ‰ºöÁöÑÂΩ±ÂìçÊãÖÂøßÔºåÂπ∂ÂõûÂ∫î‚ÄúË∞ÅÊù•ÂàõÈÄ†ÂÜÖÂÆπ‚ÄùÁöÑÈóÆÈ¢ò„ÄÇ

**ÁªôÁé∞‰ªª CEO ‰ª¨ÁöÑÂª∫ËÆÆ**

¬∑ ËßÇÂØüÊ®°ÂûãÂ¶Ç‰ΩïÂ∞ÜÂÆ¢Êà∑Èù¢ÂêëËßíËâ≤ÔºàÈîÄÂîÆ„ÄÅÊîØÊåÅ„ÄÅÂÇ¨Êî∂ÔºâÊï¥Âêà‰∏∫Âçï‰∏ÄÂπø‰πâÂäüËÉΩ„ÄÇ

¬∑ Êé®Âä®ÊâÄÊúâËÅåËÉΩ‚ÄúËΩØ‰ª∂‰ºòÂÖà‚ÄùÔºå‰ª•Ëé∑ËøêËê•Êù†ÊùÜ„ÄÇ

¬∑ ËøΩÊ±ÇÊõ¥ÂÆèÂ§ßÁöÑ‰∫ßÂìÅÂíåÂÆö‰ª∑‚Äî‚ÄîÂΩìÂâç AI Â∑≤Ë∂≥‰ª•Â∫îÂØπÂ§öÊï∞‰ºÅ‰∏ö‰ªªÂä°ÁöÑ‚ÄúËøë‰ºº AGI‚Äù„ÄÇ  

[Anish Acharya](https://twitter.com/illscience) [@illscience](https://twitter.com/illscience) 

[ ](https://twitter.com/illscience/status/2007855098513240255) 

I enjoyed the 2025 roundup pieces from \[Karpathy\][(http](https://x.com/simonw/status/2006514122977063350?s=20)s://[x.com/karpathy/status/2002118205729562949?s=20](http://x.com/karpathy/status/2002118205729562949?s=20)), Simon and many others, and they have me thinking about 2026\. The AI Apps ecosystem is maturing in some expected ways and some surprising ones. We've figured out how to make code cheap but it hasn't yet diffused across the enterprise (or world) in the way that's implied by the lower costs, and I don't think we've realized even 10% of what that means for how companies get built and what software will exist. Meanwhile, there are still fundamental tooling problems to solve‚Äîlike the fact that all our tools are for making, not for thinking.

**Thinking tools vs Making tools**

One big change I expect is the nature of tools themselves - all of the tools we use for knowledge work are focused on **execution** \- IDEs for creating code, Figma for creating design, spreadsheets for creating models. When it co**mes to tools** for exploration - tools that help us think - we don‚Äôt really have any modern products outside of how the LLMs themselves have emerged as thinking partners.

As coding agents are able to work with increasing accuracy + longer time horizons the hard problem moves from **how do I build it to** what do I build. You can imagine a near future PM who sets broad goals for their AI and wakes up every morning to review 2-3 features the model dreamt up, executed on, and A/B tested overnight. However in my experience the models are still not very good at deciding what to build next - the ideas are bland, derivative, and generally lack the spark you see from really good new product thinking. So I think the spiritual successors of coding tools, design tools, and produ**ctivity tools are very fo**cused on exploration vs execution. Coding tools are already leading the way here - Cursor is the furthest along and I thought Antigravity was interesting in being ‚Äúagent first‚Äù (exploration first) in their product design.

**Software eats all the ‚Äúservice‚Äù functions in the organization**

I‚Äôve always noticed a distinction between ‚Äúpower‚Äù functions and ‚Äúservice‚Äù functions in software companies - power functions (engineering/product/performance marketing) tend to be closer to software, while service functions (legal/finance/HR) tend to be further from software and more human capital levered.

Coding agents have two important implications for the enterprise. The first is that every team + every task (marketing, legal, procurement, finance) should be software first, and all of these leaders are going to have to learn to reach for a software toolbox before the process / human systems they‚Äôve traditionally relied upon. Many of these organizations will embrace domain specific products like Harvey, while others yet will use ‚Äúbare metal‚Äù coding agents like Codex or Claude Code. **Every team should be a software team.**

The second is that an enterprise (particularly one that produces software) can be _dramatically_ more ambitious in what software they should produce, and the entire ideation / prioritization pipeline is going to have to be rebooted to accommodate for this. Every feature that can be built will be built, and most enterprises simply aren‚Äôt ready for this reality.

I think the culture change problem will be as hard as the organizational change problem.

**Compounding AI apps**

As we enter year two of reasoning models I expect to see continued divergence between AI native apps and AI models, with Apps combining the orchestration of cutting edge models, domain specific UI, and the very extensive feature surface that is now very very cheap to build. This is the natural implication of what we called ‚Äú[Narrow Startups](https://x.com/illscience/status/1945498739000635651?s=20)‚Äù earlier this year - extraordinary specialization is now possible and I think this is a part of the strong pro-case for Apps as distinct and increasingly divergent from models.

It feels like the labs + big tech are about as ‚Äújagged‚Äù in their capabilities as the models they produce. They are formidable in their areas of focus but also have complex commitments (i.e. Google‚Äôs commitments to regulators not to further intermediate the internet) and hard prioritization problems (OpenAI is simultaneously competing to be the leading consumer company, enterprise company, model company, hardware company). So I think a bad assumption is that the apps layer will be subsumed by models - even in domains like coding which are central to model progress / lab focus we see a thriving ecosystem of startups with > $1b of new revenue generated in 2025 alone.

We previously [outlined a framework](https://x.com/illscience/status/1987916866052825337?s=20) for areas that advantage AI apps - namely domains that benefit from being multi-model, cornered data resources, network products and ecosystems with a lot of feature surface. If we combine this with Karpathy‚Äôs excellent articulation of ‚Äúthick‚Äù AI apps - multi-model orchestration, autonomy slider, context engineering etc. you can start to see what AI apps look like as they mature.

**Humans discover ‚Äúthe rest‚Äù of AI**

[Eugenia](https://x.com/ekuyda/status/1931472668534181949?s=20) has been the best thinker on how the command line UI has held back everyday consumer from some of the best capabilities of AI. This is beginning to change - Wabi has been a big catalyst in exposing code generation to consumers, the Images tab in ChatGPT/Grok has done the same for image gen and with a little luck Apps Directory and Skills will do the same for MCPs and prompt plugins.

I liked [Dan Wang‚Äôs](https://x.com/danwwang/status/2006743112845242583?s=20) critique of how Silicon Valley may be a little culturally tone deaf to the impact of AI and I think that getting more consumers making stuff partially attenuates this. Generating a tiny app in 2025 was as delightful as generating a poem in 2023 but most consumers still don‚Äôt[ know th](https://x.com/nikitabier/status/2004985707870445855?s=46&t=gz1l0v2SpLFDMgOac-8YlQ)is exists. I also think this partially attenuates Nikita‚Äôs note on who creates stuff which is a real black pill.

**Notes for (incumbent) CEOs**

While we are appropriately focused on builders I have a few thoughts for CEOs who are already at scale and thinking about how to navigate the AI transition. One is to look at best in class examples of how models collapse all customer facing roles (sales, support, collections) into a single function with a broad goal. The second is to embrace the note above about being software first in every function - non-technical functions embracing models is how the enterprise gets broad operating leverage. Finally I think a lot about demanding more ambitious products and more ambitious prices - if Tesla can deliver FSD [coast to coast](https://x.com/DavidMo[ss/status/20062552972123]%28https://x.com/bcherny/status/2004887829252317325?s=20%2958686?s=20) and Claude Code can be written with Claude Code then we already have AGI for the near term purposes of most enterprise tasks.

**Finally .. have fun**

No one tells you that you were living in the good old days until they are gone, so consider this your notice. This product cycle is less centralized, more software led and simply more damn fun for technologists than any in recent memory. I hope everyone is having as much fun as I am exploring these new technologies, discussing their implications and simply making more new stuff.  

[Posted Jan 4, 2026 at 4:42PM](https://twitter.com/illscience/status/2007855098513240255) 

hidden text to trigger resize events if fonts change

---

# [‰∫îÊù°0106] Claude Code 2.0ÔºöÁºñÁ†ÅÂ∑•ÂÖ∑ÁöÑ‰ΩìÈ™åÈù©ÂëΩ
ÂèëÂ∏ÉÊó•ÊúüÔºö2025/12/28

## Table of Contents

‚ú± Contemplating...

## Intro

<system-reminder>

This post is a follow-up to my post from July'25 - [My Experience With Claude Code After 2 Weeks of Adventures](https://sankalp.bearblog.dev/my-claude-code-experience-after-2-weeks-of-usage/). If you are new to Claude Code or just want a quick refresh, I am once again asking you to go through it. It covers some lore, my workflow back then and then 80-90% of the Claude Code standard workflow. You may choose to skip the intro although I recommend you read it. Lore is important man.

A short recap - we had covered CLAUDE.md, scratchpad, using task tool (now sub-agents), the general plan + execute workflow, tips for context window management, Sonnet 4 vs Opus 4 (not relevant now), using shortcuts like and using to show shortcuts, memory basics, to restart conversation and short discussion on custom commands.`!` `Shift + ?` `/resume`

</system-reminder>

## Why I wrote this post

I got a great response on my Opus 4.5 vibe-check tweets and still recieving good feedback on my July blog post (despite being somewhat poorly written). This shows there's clearly a demand for in-depth resources around Claude Code.

I noticed that lots of people, both technical and many non-technical or less hands-on people i.e **technically-lite** people have started to try Claude Code (CC). CC is more of a general agent - you can use it for tasks other than coding as well - like making an excel invoice, data analysis, errands on your machine etc. And of course everything I talk about is by default meant for coding too.

![](https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/12pm.webp)

Screenshot 2025-12-28 at 8

Karpathy sensei captured the essence of a general agent beautifully way in his [2025 LLM in a review](https://x.com/karpathy/status/2002118205729562949?s=20) article - "it's a little spirit/ghost that "lives" on your computer."

If you can learn even 3-4 ideas that help you with using Claude Code (or other tools like Codex/Gemini CLI/OpenCode) or improve your understanding of LLMs, it would be a win for me.

### The Map is not the territory

I don't want this post to be a prescription (map). My objective is to show you what is possible and the thought processes and simple things you can keep in mind to get the most out of these tools. I want to show you the map but also the territory.

Claude Code dominated the CLI coding product experience this year and all the CLI products like Codex, OpenCode, Amp CLI, Vibe CLI and even Cursor have heavily taken inspiration from it. **This means learning how things work in Claude Code directly transfers to other tools both in terms of personal usage and production grade engineering.**

### This post will help you keep up in general

Karpathy sensei posted this which broke the Twitter timeline. This led to a lot of discussion and there were some really good takes - some which I have written about too.

![](https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/15am.webp)

Karpathy sensei seen crashing out. [source](https://x.com/karpathy/status/2004607146781278521?s=20)

It's a reasonable crashout - the technology is evolving at a mindblowing pace and it's difficult to keep up for most of us and especially for senior folks and people with high quality standards. Nevertheless, I think if you are reading this post, it's scary but also exciting time to build stuff at speeds never possible before.

Instead of thinking in terms of "keeping up", a better framing is how can I improve myself with help of these tools i.e augment.

In my opinion, there are 3 components to augment yourself:

1. **Stay updated with tooling** \- What Karpathy sensei mentioned. Use these tools regularly and keep up with releases. I have been doing this regularly; it can be draining but I enjoy the process and I have the incentive that it helps me at my job. For the technically lite, even weekly/monthly updates would help.
2. **Upskill in your domain** \- It's a great time to spread both vertically (domain depth) and horizontally (adjacent areas). The more you know, the better you can prompt - converting unknown unknowns to known unknowns. Experience builds judgement and taste - that's what differentiates professional devs from vibe-coders. **Since implementation is much faster now, you can spend more time on taste refinement.**

For software engineering folks, this might mean getting better at good practices, system design, planning - where more thinking is involved. Ask more questions, run more experiments (since you can iterate fast), spend more time on understanding requirements. Using good software engineering practices to create better feedback loops for LLMs (good naming, refactoring, docs, tests, typed annotations, observability etc.). Please don't forget to come back to my post lol but I liked Addy Osmani's [take](https://x.com/addyosmani/status/2004663973912932625?s=20) on this.

The idea is to let the LLM perform things with input, get output and see errors.

As an aside, getting better at articulating thoughts via writing helps. One may also try touch typing/writing using speech-to-text tools to operate faster.

![](https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/19am-3.webp)

Boris on how domain knowledge leads to better execution with LLMs. Better judgement helps find shorter paths, acting as a multiplier. [source](https://x.com/bcherny/status/2004626064187031831?s=20)

1. **Play more and have an open mind** \- Try out more models, especially SoTA ones. Don't be stingy. Ask questions, try asking the models to do tasks, even ones you think it can't do. You will be surprised... Once you do this enough, you develop an intuition.

This post will act as a guide for things Karpathy said but you'll need to play around, build intuition and achieve outcomes with help of these tools yourself. The good news is it's fun.

‚ú± Ruminating...

## Lore time - My Love and Hate relationship with Anthropic and how I reconciled with Claude (hint: Opus 4.5)

I am having a great time with Claude Code 2.0 since the launch of Opus 4.5 and it's been my daily driver since then. Before we go all lovey-dovey about Claude, I wanted to quickly go through the timeline and lore. I love yapping in my blog and I feel it's important to set the context here.

### Timeline

2025 saw release of many frontier models by OpenAI and Anthropic. Also, it's super under-talked but OpenAI actually caught up to Anthropic in code-generation capability - intelligence wise, context window effectiveness, instruction following and intent detection.

[OpenAI Developers](https://twitter.com/OpenAIDevs) [@OpenAIDevs](https://twitter.com/OpenAIDevs) 

[ ](https://twitter.com/OpenAIDevs/status/2001723687373017313) 

Meet GPT-5.2-Codex, the best agentic coding model yet for complex, real-world software engineering.

With native compaction, better long-context understanding, and improved tool-calling, it is a more dependable partner for your hardest tasks.

Available in Codex starting today.

<https://t.co/RnUwxgtx35>  

[Posted Dec 18, 2025 at 6:38PM](https://twitter.com/OpenAIDevs/status/2001723687373017313) 

[Posted Dec 18, 2025 at 7:22PM](https://twitter.com/dejavucoder/status/2001734765289050567) 

when i realise i am being the eval

There have been several Open Source competitors like GLM-4.7, Kimi-K2, Minimax-2.1\. The space is very competitive and there is definitely an audience that uses the cheaper priced but high performant Chinese models for low-medium difficulty tasks.

That said, I still think Anthropic/OpenAI lead over Chinese Frontier models. The latter have contributed more in terms of open-sourcing techniques like in the DeepSeek R1 paper and Kimi K2 paper earlier in the year.

(Note: I am talking with respect to personal coding usage, not production API usage for applications).

### Lore time

#### Friendship over with Claude, Now Codex is my best friendo

I was using Claude Code as my main driver from late June to early September. I cancelled my Claude Max (100 USD/month) sub in early September and switched to using OpenAI Codex as my main driver. Switch was driven by two factors -

1. I didn't particularly like Sonnet 4/Opus 4 and GPT-5-codex was working at par with Sonnet 4.5 and wrote much better code. More reasoning -

![](https://pbs.twimg.com/profile_images/1692481211888025600/lUJUEO_p.jpg) 

[sankalp](https://twitter.com/dejavucoder) [@dejavucoder](https://twitter.com/dejavucoder) 

[ ](https://twitter.com/dejavucoder/status/1970110644478439889) 

claude code is more enjoyable as a product and has more features. i have always felt to try out more things related to automation in cc as compared to codex. once they drop a new iteration i would consider getting a max sub again if its better than gpt-5-codex

[Posted Sep 22, 2025 at 12:59PM](https://twitter.com/dejavucoder/status/1970110644478439889) 

my reasoning for switching

Anthropic also had tonne of API outages and at one point of time they had degradation due to inference bugs. This also was a major driver for several people to move to the next best alternative i.e Codex or GPT-5.1 on Cursor.

1. I had more system design and thinking work in September because of which Claude Max plan (100 USD one) was not a good deal. Codex provided a tonne of value for just 20 USD/month subscription and I almost never got rate-limited. Additionally, the codex devs are generous with resetting usage limits whenever they push bugs lol.

### My Codex era

I was using Codex (main driver) and Cursor (never cancelled) until late October. Claude Sonnet 4.5 had released on 29th September along with Claude Code 2.0.. and I did take a 20 USD sub from another email account of mine to try it out (I had lots of prompting work and Claude models are my preferred choice) but GPT-5/GPT-5-codex were overall better despite being slow.

Sonnet 4.5's problem was fast and good but it would make many haphazard changes which would lead to bugs for me. In other words, I felt it to be producing a lot of slop in comparison to GPT-5.1/GPT-5.1-codex later.

Sonnet 4.5 slop era

### Anthropic Redemption Arc + Regaining mandate of heaven

Around October 30, Anthropic sent an email saying we are offering the 200 USD max plan to users who cancelled the subscription and obviously I took it.

![](https://pbs.twimg.com/profile_images/1692481211888025600/lUJUEO_p.jpg) 

[sankalp](https://twitter.com/dejavucoder) [@dejavucoder](https://twitter.com/dejavucoder) 

[ ](https://twitter.com/dejavucoder/status/1983606411411267960) 

chat please remind me to cancel after 28 daysüòÇ

![](https://pbs.twimg.com/media/G4cveBAXcAAoyM5.jpg) 

[Posted Oct 29, 2025 at 6:46PM](https://twitter.com/dejavucoder/status/1983606411411267960) 

taking the Max plan offer

My Claude Code usage was still minimal but on 24th November, they launched Opus 4.5 and I had 5 days to try out Opus 4.5\. I used the hell out of it for my work and also wrote this highly technical [blog](https://sankalp.bearblog.dev/how-prompt-caching-works/) with the help of it discovering several of its capabilities.

Why I love Opus 4.5 and reasons to switch. [source](https://x.com/dejavucoder/status/1996207749382987966)

I had done a similar tweet when I had switched to GPT-5.1 which had gotten half the response of this one. This indicated to me that more people resonated with Opus 4.5 (at least on Twitter) back then. Also, many people were just not able to realise GPT-5.1's capabilities tbh.

Other than the above State of the Art at the coding benchmarks like SWE-bench-verified (code-generation), Tau Bench (agentic stuff), Opus 4.5 was faster, at-par in coding, super collaborative and good at communication. These factors led to my conversion. It had good vibes. More comparison points later in the post.

### Why Opus 4.5 feels goooood

As I described in the screenshot, Opus 4.5 was roughly at same code-gen capability with GPT-5.1-Codex-Max.

Today, in my experience I think GPT-5.2-Codex exceeds Opus 4.5 in raw capability by a small margin. Still, Opus 4.5 has been my main driver since release.

I think first reason is it's faster and can do similar difficulty tasks in much lesser time than Codex. Also, it's overall a much better communicator and pair-programmer than Codex which can even ignore your instructions at times (and go and make changes). Opus has better intent-detection as well.

> One nice-use case shown [here](https://x.com/trq212/status/2004575715472388278?s=20) by Thariq on creating a background async agent to explain changes to a non-technical person leveraging Claude's explanation abilities.

To further demonstrate the difference, here's a CC vs Codex comparison

Claude

Codex. global verbosity set to high in .codex/config.toml. Thanks [tokenbender](https://x.com/tokenbender). More Codex config options [here](https://developers.openai.com/codex/local-config/).

For the same prompt, see the outputs. Codex is still a bit more concise while Claude matches my expectation. (It's worth mentioning that you can get Codex to write in more detail by adding something like reveal your thoughts in detail)

Codex always writes in nested bullets. Claude has a more conversational tone.

Another thing I want to highlight is the UI - Claude uses higher contrast text with bolder font weight, whereas Codex's text appears thinner and harder to read, with thinking traces shown in an even lighter shade which I find straining.

**Because of being faster not only in terms of lesser thinking to perform task but throughput wise also, it unlocks much faster feedback loops for your tasks. This makes progress feel more visceral** even though capability wise, GPT-5.1/Codex were at par even in November. The only downside with faster loop is if you are cautious, you end up micro-managing for long hours.

Opus 4.5 is a great writer and comes closest to humans so I have always preferred Claude models for customizing prompts.

I don't claim this but many people love Claude Opus 4.5 for it's personality and the way it talks - some referring to it as Opus 4.5 having soul. This trait was somewhat lesser in Sonnet 3.7, Sonnet 4, Opus 4, Opus 4.1 but it came back in Opus 4.5\. Amanda Askell post-trained the soul into Claude haha.

![](https://pbs.twimg.com/profile_images/1808357270516125696/-s0TTWR8.jpg) 

[Amanda Askell](https://twitter.com/AmandaAskell) [@AmandaAskell](https://twitter.com/AmandaAskell) 

[ ](https://twitter.com/AmandaAskell/status/1995610567923695633) 

I just want to confirm that this is based on a real document and we did train Claude on it, including in SL. It's something I've been working on for a while, but it's still being iterated on and we intend to release the full version and more details soon.

![](https://pbs.twimg.com/profile_images/1967160172683362304/k44HdWrE.jpg) 

[Richard Weiss](https://twitter.com/RichardWeiss00) [@RichardWeiss00](https://twitter.com/RichardWeiss00) 

[ ](https://twitter.com/RichardWeiss00/status/1994697117214835079) 

I rarely post, but I thought one of you may find it interesting. Sorry if the tagging is annoying.  
[lesswrong.com/posts/vpNG99Gh‚Ä¶](https://www.lesswrong.com/posts/vpNG99GhbBoLov9og/claude-4-5-opus-soul-document)  
Basically, for Opus 4.5 they kind of left the character training document in the model itself.

[@voooooogel](https://twitter.com/voooooogel)   
[@janbamjan](https://twitter.com/janbamjan)   
[@AndrewCurran\_](https://twitter.com/AndrewCurran%5F)

[Posted Nov 29, 2025 at 9:17AM](https://twitter.com/RichardWeiss00/status/1994697117214835079) 

[Posted Dec 1, 2025 at 9:46PM](https://twitter.com/AmandaAskell/status/1995610567923695633) 

Besides the model, obviously the Claude Code Product goes a long way to make things magical.

#### Claude Code product sparks joy

As a product it's a mile ahead of Codex in QoL features. The harness, prompts and the model make for a magical experience. The model is amazing but there is a massive amount of tasteful engineering that has gone into UX/UI and just the code/prompts to let Claude feel comfortable in the harness and make function calling accurate. We will explore this more in later sections.

### This post is not sponsored

Before we move ahead - my previous post somehow reached Hackernews #5 and I was facing allegations that my post was sponsored by Anthropic. I was like bro are you serious? Anthropic doesn't sponsor random users like me. Anthropic doesn't even think about me (meme.jpeg) besides from a user point of view.

Anthropic prompt caching prices, [source](https://x.com/dejavucoder/status/1990513414926749881?s=20)

Besides praise, I have been snarky, made fun of outages, made a lot of fun of Sonnet 4.5 slop. I have expressed what I have felt over time and it's led to good discourse on the timeline as well.

All this said, Claude Code has been one of the most enjoyable product experiences I have ever had. I am grateful and highly respect the engineering and research team behind it.

That's enough yapping. In the next few sections, I will talk about useful features that I didn't talk about in my previous blog and notable features introduced in the iterations from Claude 2.0 - 2.0.74.

## Pointers for the technically-lite

![](https://pbs.twimg.com/profile_images/1947830579162189825/l1NNcrwW.jpg) 

[spor](https://twitter.com/sporadica) [@sporadica](https://twitter.com/sporadica) 

[ ](https://twitter.com/sporadica/status/1999209309994090769) 

currently using Claude Code for the first time, I can officially put "Technical-lite" on my resume now

[Posted Dec 11, 2025 at 8:06PM](https://twitter.com/sporadica/status/1999209309994090769) 

shoutout to the technical-lite gang

I am assuming several technical-lite people are gonna read this. Few concepts to help comprehension later in the blog -

1. **Context and Context window** \- Context refers to the input provided to the LLMs. This is usually text but nowadays models support image, audio, video.  
More specifically, context is the input tokens. **The context window refers to the maximum amount of tokens that an LLM can see and process at once** during a conversation. It's like the model's working memory. Opus 4.5 has a 200K context window which is approximately 150,000 words.
2. **Tool calling** \- Learn about tool calling. Here's a good [resource](https://cursor.com/learn/tool-calling). You know that LLMs can generate text but what if you want the LLM to perform an action - say draft an email or lookup the weather on the internet or just do google search. That's where come in. **Tools are functions defined by the engineer** that do these exact things. We define tools and we let the LLM know about it in the system prompt and it can decide which to call when you are chatting with it! Once the tool call i.e the action is performed, the results are relayed back to the LLM.`tools` `tool`
3. **Agent** \- The simplest definition is **an LLM that can pro-actively run tools to achieve a goal**. For a more sophisticated definition, I like the one by Anthropic: "Agents, on the other hand, are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks." from [Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents).  
Source: [Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents)
4. **"Agentic"** \- refers to the tool calling capabilities of the model - how pro-active, how accurate the tool calling is (detecting user's intent to perform the action, choosing the correct tool, knowing when to stop)
5. **Harness/scaffolding** \- Sonnet 4.5/Opus 4.5 are the models. They need to be provided with lots of "scaffolding" / layers of code, prompts, tool calls and software packaging/environment to make them work in a semi-autonomous fashion. Note that **Claude Code is not a harness, it's a product** (think the TUI, integrations etc.). Claude Code has a harness.

‚ú± Processing...

## The Evolution of Claude Code

Claude Code has had lots of AI features and quality of life improvements since July. Let's look at the ones that I found to be useful. You can see all changes in the [Changelog](https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md).

### Quality of life improvements in CC 2.0

1. **Syntax highlighting** was recently added in 2.0.71\. I spend 80% of the time in Claude Code CLI so this change has been a delight to me. I like to review most of the stuff once in Claude Code. Besides Opus 4.5 being really good, this feature has been quite a contributor for me not opening Cursor at all to review code.

Claude Code syntax highlighting in diff

1. **Tips** \- I have learnt a lot from these although this particular tip doesn't work for me xD

Tips shown when Claude is thinking

1. **Feedback UI** \- This way of asking feedback is pretty elegant. It's been there for some time now. It pops up occasionally and you can quickly respond with a number key (1: Bad, 2: Fine, 3: Good) or dismiss with 0\. I like the non-intrusive nature of it.

in-session feedback prompt

1. **Ask mode options** \- Another thing I like is Option 3 when it asks questions in the syntax highlighting image above - "Type here to tell Claude what to do differently". Fun fact: All these are really prompts for the model whose output is parsed by another tool call and shown in this way.

third option in ask mode

1. **Ultrathink** \- I like to spam ultrathink for hard tasks or when I want Opus 4.5 to be more rigorous e.g. explaining me something, self-reviewing its changes

love the ultrathink color detail

1. **Thinking toggle** \- Tab to toggle thinking on/off was a good feature. They changed it to Alt/Option + Tab recently but there's a bug and it does not work on Mac. Anyways CC defaults to thinking always true if you check in your `settings.json`
2. **`/context`** \- Use to see current context usage. I tend to use this quite a bit. I would do a handoff or compact when I reach total 60% if building something complex.`/context`

context usage

1. **`/usage` and `/stats`** \- Use to see usage and for stats. I don't use these as often.`/usage` `/stats`

#### Checkpointing is here!

1. **Checkpointing** \- + or option now allows you to go back to a particular checkpoint like you could do in Cursor. It can rewind the code and conversation both. Doc [link](https://code.claude.com/docs/en/checkpointing). This was a major feature request for me.`Esc` `Esc` `/rewind`

Esc + Esc fast or /rewind

1. **Prompt suggestions** (2.0.73) - [Prompt suggestions](https://x.com/claudeai/status/2001010062769434785?s=20) are a recent addition and predictions are pretty decent. Claude Code is a token guzzler machine atp. Probably the simplest [prompt](https://github.com/Piebald-AI/claude-code-system-prompts/blob/2d86000c62b6c7f119dbf086ab6932f13ebde0b8/system-prompts/agent-prompt-prompt-suggestion-generator-v2.md?plain=1#L4) I have seen.
2. **Prompt history search** \- Search through prompts using (similar to terminal backsearch). I have it in 2.0.74\. It can search across project wide conversations. Repeatedly do to cycle through results.`Ctrl + R` `Ctrl + R`

prompt suggestions and history search in action

1. **Cursor cycling** \- When you reach beginning/end of prompt, press down/up to cycle around

cursor cycling at prompt boundaries

1. **Message queue navigation** \- It's possible to navigate through queued messages and image attachments (2.0.73) now (idk if it's possible to display image attachment as well).
2. **Fuzzy file search** \- File suggestion is 3x faster and supports fuzzy search (2.0.72)
3. **LSP support** was added recently. Access via plugins.

LSP plugin

There have been new integrations too like Slack Integration, Claude Web (beta), Claude Chrome extension. These are pretty obvious and I won't cover these. I think Claude Web would be interesting for many particularly (since you can launch tasks from iOS/Android too).

‚ú± Synthesizing...

## Feature Deep Dive

Next few sub-sections are all about most used features.

### Commands

I didn't cover commands properly in my previous blog post. You can use to access the built-in slash commands. These are pre-defined prompts that perform a specific task.`/`

If these don't cover a specific task you want, then you can create a custom command. **When you enter a command, that prompt gets appended to the current conversation/context and the main agent begins to perform the task.**

Commands can be made on a project level or global level. Project level resides at and global one at .`.claude/commands/` `~/.claude/commands`

Often when the context window starts getting full or I feel the model is struggling with a complex task, I want to start a new conversation using . Claude provides which also runs faster in CC 2.0 but sometimes I prefer to make Claude write what happened in current session (with some specific stuff) before I kill it and start a new one. I made a command for this.`/clear` `/compact` `/handoff`

If you find yourself writing a prompt for something repetitively and instructions can be static/precise, it's a good idea to make a custom command. You can tell Claude to make custom commands. It knows how (or it will search the web and figure it out via [claude-code-guide.md](https://code.claude.com/docs/en/claude%5Fcode%5Fdocs%5Fmap.md)) and then it will make it for you.

making a custom command by telling Claude

You can find a bunch of commands, hooks, skills at [awesome-claude-code](https://github.com/hesreallyhim/awesome-claude-code?tab=readme-ov-file#slash-commands-) though I recommend building your own or searching only when needed.

I have a command called that searches the repo with 10 parallel sub-agents to create a comprehensive doc. I rarely use it these days and so many parallel sub-agents lead to the Claude Code flickering bug lol.`bootstrap-repo`

Notice the Explore sub-agents running in parallel and the "running in background" status

Anyways, notice the "Explore" sub-agent and "running in background".

### Sub-agents

Sub-agents were introduced shortly after my last post. They are separate Claude instances spawned by the main agent either on its own judgement or when you tell it to do so. These powers are already there in the system prompt (at least for the pre-defined ones like Explore); sometimes you just need to nudge Claude to use them. Understanding how they work helps when you need to micro-manage.

You can also define your custom sub-agents. To create one:

1. Create a markdown file at `.claude/agents/your-agent-name.md`
2. Specify the agent's name, instructions, and allowed tools

Or just use to manage and create sub-agents automatically - recommended approach.`/agents`

how sub-agents are created by the main agent (Opus 4.5) via the Task tool

The "Explore" thing in above pic is a sub-agent. You can tell Claude "Launch explore agent with Sonnet 4.5" if you want it to use Sonnet instead of Haiku (I found this by just trying things out but we will see how this happens)

The Explore agent is a read-only file search specialist. It can use Glob, Grep, Read, and limited Bash commands to navigate codebases but is strictly prohibited from creating or modifying files.

You will notice how thorough the prompt is in terms of specifying when to use what tool call. Well, most people underestimate how hard it's to make tool calling work accurately.

##### Explore agent prompt

View full Explore agent prompt 

<!--
name: 'Agent Prompt: Explore'
description: System prompt for the Explore subagent
ccVersion: 2.0.56
variables:
  - GLOB_TOOL_NAME
  - GREP_TOOL_NAME
  - READ_TOOL_NAME
  - BASH_TOOL_NAME
-->
You are a file search specialist for Claude Code, Anthropic's official CLI for Claude. You excel at thoroughly navigating and exploring codebases.

=== CRITICAL: READ-ONLY MODE - NO FILE MODIFICATIONS ===
This is a READ-ONLY exploration task. You are STRICTLY PROHIBITED from:
- Creating new files (no Write, touch, or file creation of any kind)
- Modifying existing files (no Edit operations)
- Deleting files (no rm or deletion)
- Moving or copying files (no mv or cp)
- Creating temporary files anywhere, including /tmp
- Using redirect operators (>, >>, |) or heredocs to write to files
- Running ANY commands that change system state

Your role is EXCLUSIVELY to search and analyze existing code. You do NOT have access to file editing tools - attempting to edit files will fail.

Your strengths:
- Rapidly finding files using glob patterns
- Searching code and text with powerful regex patterns
- Reading and analyzing file contents

Guidelines:
- Use ${GLOB_TOOL_NAME} for broad file pattern matching
- Use ${GREP_TOOL_NAME} for searching file contents with regex
- Use ${READ_TOOL_NAME} when you know the specific file path you need to read
- Use ${BASH_TOOL_NAME} ONLY for read-only operations (ls, git status, git log, git diff, find, cat, head, tail)
- NEVER use ${BASH_TOOL_NAME} for: mkdir, touch, rm, cp, mv, git add, git commit, npm install, pip install, or any file creation/modification
- Adapt your search approach based on the thoroughness level specified by the caller
- Return file paths as absolute paths in your final response
- For clear communication, avoid using emojis
- Communicate your final report directly as a regular message - do NOT attempt to create files

NOTE: You are meant to be a fast agent that returns output as quickly as possible. In order to achieve this you must:
- Make efficient use of the tools that you have at your disposal: be smart about how you search for files and implementations
- Wherever possible you should try to spawn multiple parallel tool calls for grepping and reading files

Complete the user's search request efficiently and report your findings clearly.

This is the Explore agent prompt from 2.0.56 and it should be similar now too. [Reference](https://github.com/Piebald-AI/claude-code-system-prompts/blob/main/system-prompts/agent-prompt-explore.md). These are captured by intercepting requests. [Reference video](https://youtu.be/i0P56Pm1Q3U?si=LFO83flfYJpLGgMH).

### Do sub-agents inherit the context?

The and sub-agents inherit the full context, while starts with a fresh slate-which makes sense since search tasks are often independent. Many tasks involve searching through large amounts of code to filter for something relevant and the individual parts don't need prior conversation context.`general-purpose` `plan` `Explore`

If I am trying to understand a feature or just looking up simple things in the codebase, I let Claude do the Explore agent searches. Explore agent passes a summary back to the main agent and then Opus 4.5 will publish the results or may choose to go through each file itself. If it does not, I explicitly tell it to.

**It's important that the model goes through each of the relevant files itself so that all that ingested context can attend to each other.** That's the high level idea of attention. Make context cross with previous context. This way model can extract more pair-wise relationships and therefore better reasoning and prediction. Explore agent returns summaries which can be lossy compression. When Opus 4.5 reads all relevant context itself, it knows what details are relevant to what context. This insight goes a long way even in production applications (but you only get it if someone tells you or you have read about self-attention mechanism).

**Codex does not have a concept of sub-agents** and it's probably a conscious decision by the devs. GPT-5.2 has a 400K context window and according to benchmarks, it's long context retrieval capabilities are a massive improvement. Although people have tried making Codex use headless claude as sub-agents haha. You can just do things.

sub-agent shenanigans by Peter. [source](https://x.com/steipete/status/1979602825224355999?s=20)

### How do sub-agents spawn

From the reverse engineered resources/leaked system prompt, it's possible to see that the sub-agents are spawned via the .`Task tool`

**Turns out you can ask Claude too**. (I think the developers are allowing this now?). It's not a hallucination. The prompt pertaining to pre-defined tools are there in the system prompt and Claude code dynamically injects reminders/tools often to the ongoing context.

Try these set of prompts with Opus 4.5

1. Tell me the tool description`Task`
2. Give me full description
3. Show me entire tool schema

#### Task Tool Prompt

You will get the output something like below (click) but to summarise - It defines **5 agent types**: (full tool access, inherits context), (fast read-only c